<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>spring-boot启动流程</title>
    <url>/2020/05/24/01no/springboot/springboot02-start/</url>
    <content><![CDATA[<h1 id="spring-boot-启动"><a href="#spring-boot-启动" class="headerlink" title="spring-boot 启动"></a>spring-boot 启动</h1><ul>
<li>spingboot-start<ul>
<li>SpringApplication构造方法<ul>
<li>使用 SpringFactoriesLoader 在 classpath 中查找并加载所有可用的 ApplicationContextInitializer</li>
<li>使用 SpringFactoriesLoader 在 classpath 中查找并加载所有可用的 ApplicationListener</li>
<li>通过stackTrace里的main方法查找启动类</li>
</ul>
</li>
<li>SpringApplication.run()<ul>
<li>创建StopWatch计时器</li>
<li>通过 SpringFactoriesLoader 查找并加载 SpringApplicationRunListener 列表,调用 SpringApplicationRunListener.started() 方法</li>
<li>创建Environment<ul>
<li>configureEnvironment()</li>
<li>listeners.environmentPrepared(): 广播 ApplicationEnvironmentPreparedEvent 事件</li>
</ul>
</li>
<li>打印banner</li>
<li>createApplicationContext(): 创建applicationContext</li>
<li>prepareContext()<ul>
<li>context.setEnvironment()</li>
<li>postProcessApplicationContext()</li>
<li>applyInitializers():调用 initializers.initialize()</li>
<li>listeners.contextPrepared():广播 ApplicationContextInitializedEvent</li>
<li>load():加载 beanDefinitions</li>
<li>listeners.contextLoaded()<ul>
<li>1.若listener实现了 ApplicationContextAware 接口,调用 setApplicationContext()</li>
<li>2.广播ApplicationPreparedEvent事件</li>
</ul>
</li>
</ul>
</li>
<li>refreshContext():调用 spring 的 refresh()方法<ul>
<li>AbstractApplicationContext.refresh()逻辑</li>
</ul>
</li>
<li>afterRefresh():钩子,目前 do nothing</li>
<li>广播 ApplicationStartedEvent 事件</li>
<li>callRunners()<ul>
<li>调用ApplicationRunner和CommandLineRunner类型对象的run()方法</li>
</ul>
</li>
<li>若上面执行有异常,则handleRunFailure()</li>
<li>listeners.running():广播ApplicationReadyEvent事件</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title>idea搭建spring-boot环境</title>
    <url>/2020/05/19/01no/springboot/springboot01-build/</url>
    <content><![CDATA[<h1 id="idea搭建spring-boot环境"><a href="#idea搭建spring-boot环境" class="headerlink" title="idea搭建spring-boot环境"></a>idea搭建spring-boot环境</h1><h2 id="显示tag"><a href="#显示tag" class="headerlink" title="显示tag"></a>显示tag</h2><p>git tag</p>
<p>选择 v2.1.5.RELEASE 版本,这是我们项目里现在在用的版本,还比较新,最新的目前是 2.3.0.</p>
<h2 id="拉自己的分支"><a href="#拉自己的分支" class="headerlink" title="拉自己的分支"></a>拉自己的分支</h2><ol>
<li><p>建立我自己的分支,以后代码注释都写在这个分支上.<code>v2.1.5.RELEASE-zc</code></p>
<p> git checkout -b v2.1.5.RELEASE-zc v2.1.5.RELEASE</p>
<p> v2.1.5.RELEASE 这个版本是可以选择 maven 或 gradle 构建的,我这里选的maven.</p>
<p> 工程依赖的jar包很多,大概要下个半小时多.</p>
</li>
<li><p>将本地分支推到远程<br>git push origin v2.1.5.RELEASE-zc</p>
</li>
<li><p>建立关联<br>git push –set-upstream origin v2.1.5.RELEASE-zc</p>
</li>
</ol>
<h2 id="看看代码量"><a href="#看看代码量" class="headerlink" title="看看代码量"></a>看看代码量</h2><p>spring-boot 总共代码45w行,纯代码 27w 行.<br><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/2020-05-19-22-15-54.png" alt="代码量统计"></p>
<h2 id="idea-attach-source"><a href="#idea-attach-source" class="headerlink" title="idea attach source"></a>idea attach source</h2><p>idea 的配置最终都落到 .idea 下的 xml 里,搜索 springboot 的 maven 配置文件,修改里面的 sources.<br>Maven__org_springframework_boot_spring_boot_2_1_5_RELEASE.xml</p>
]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat处理请求流程</title>
    <url>/2019/12/26/01no/tomcat/tomcat06-request/</url>
    <content><![CDATA[<h1 id="tomcat处理请求"><a href="#tomcat处理请求" class="headerlink" title="tomcat处理请求"></a>tomcat处理请求</h1><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Server</span><br><span class="line">|-- Service</span><br><span class="line">|--|-- Connector</span><br><span class="line">|--|--|-- Prototal</span><br><span class="line">|--|--|--|-- Endpoint</span><br><span class="line">|--|--|--|--|-- Acceptor</span><br><span class="line">|--|--|--|--|-- Executor</span><br><span class="line">|--|--|--|-- Processor</span><br><span class="line">|--|--|-- Mapper</span><br><span class="line">|--|--|-- CoyteAdapter</span><br><span class="line">|--|-- Container</span><br><span class="line">|--|--|--|-- Host</span><br><span class="line">|--|--|--|-- Context</span><br><span class="line">|--|--|--|-- Wrapper</span><br><span class="line">|--|-- Executor</span><br></pre></td></tr></table></figure>
<h3 id="Http11NioProtocol"><a href="#Http11NioProtocol" class="headerlink" title="Http11NioProtocol"></a>Http11NioProtocol</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Http11NioProtocol</span><br><span class="line">|-- NioEndpoint</span><br><span class="line">|--|-- LimitLatch</span><br><span class="line">|--|-- Acceptor</span><br><span class="line">|--|-- Poller</span><br><span class="line">|--|-- Poller池</span><br><span class="line">|--|-- SocketProcessor</span><br><span class="line">|--|-- Executor</span><br><span class="line">|--|-- PollerEvent</span><br><span class="line">|--|-- KeyAttachment</span><br><span class="line">|--|-- NioBufferHandler</span><br><span class="line">|-- Http11ConnectionHandler</span><br><span class="line">|-- Http11NioProcessor</span><br></pre></td></tr></table></figure>
<h3 id="Connector"><a href="#Connector" class="headerlink" title="Connector"></a>Connector</h3><p>接收客户端连接并响应</p>
<h3 id="Protocol协议"><a href="#Protocol协议" class="headerlink" title="Protocol协议"></a>Protocol协议</h3><p>协议的抽象.<br>Protocol分类: Http11Protocol,Http11NioProtocol 等.</p>
<h3 id="Http11NioProtocol-1"><a href="#Http11NioProtocol-1" class="headerlink" title="Http11NioProtocol"></a>Http11NioProtocol</h3><p>包含 NioEndpoint 和 Http11NioProcessor</p>
<h3 id="NioEndpoint"><a href="#NioEndpoint" class="headerlink" title="NioEndpoint"></a>NioEndpoint</h3><h3 id="LimitLatch"><a href="#LimitLatch" class="headerlink" title="LimitLatch"></a>LimitLatch</h3><p>连接数控制,nio模式下默认是10000,达到这个阈值后,就会拒绝连接请求.使用AQS实现的一个共享锁.</p>
<h4 id="LimitLatch相关流程"><a href="#LimitLatch相关流程" class="headerlink" title="LimitLatch相关流程"></a>LimitLatch相关流程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 初始化最大连接数量</span><br><span class="line">    - endpoint.startInternal()</span><br><span class="line">        -  initializeConnectionLatch(); 初始化LimitLatch,用于控制连接的数量  </span><br><span class="line">            - connectionLimitLatch &#x3D; new LimitLatch(getMaxConnections()); 根据最大的连接数量来创建  </span><br><span class="line"></span><br><span class="line">- acceptor接收请求前,连接计数+1.若到达最大值则等待其他连接释放</span><br><span class="line">    - acceptor.run()</span><br><span class="line">        - countUpOrAwaitConnection();&#x2F;&#x2F; 增加连接计数,若connection数量已经达到了最大等待 socket &#x3D; serverSocket.accept();  然后再等待连接,若上一步阻塞则不会到此处</span><br><span class="line"></span><br><span class="line">- 连接计数-1</span><br><span class="line">    - (!setSocketOptions(socket)) &#123;  &#x2F;&#x2F;这里主要是将socket加入到poller对象上面去,而且还要设置参数     </span><br><span class="line">        countDownConnection();  &#x2F;&#x2F; 加入poller对象失败了的话,那么将LimitLatch的计数减1 </span><br><span class="line">      &#125;</span><br><span class="line">    - endpoint.cancelKey()</span><br><span class="line">        - countDownConnection();</span><br></pre></td></tr></table></figure>
<h3 id="Acceptor"><a href="#Acceptor" class="headerlink" title="Acceptor"></a>Acceptor</h3><p>接收socket连接<br>通过 serverSocket.accept() 获得 SocketChannel 对象,封装成 org.apache.tomcat.util.net.NioChannel.<br>再将 NioChannel 封装成 PollerEvent, 并将 PollerEvent 压入 events queue里,即<code>ConcurrentLinkedQueue&lt;PollerEvent&gt; events</code>里.</p>
<h3 id="Poller-轮询器"><a href="#Poller-轮询器" class="headerlink" title="Poller 轮询器"></a>Poller 轮询器</h3><p>轮询 events.由 Poller 将就绪的事件 生成 SocketProcessor,交由 Executor 处理.</p>
<h3 id="Poller池"><a href="#Poller池" class="headerlink" title="Poller池"></a>Poller池</h3><p>包含若干 Poller 组件</p>
<h3 id="SocketProcessor"><a href="#SocketProcessor" class="headerlink" title="SocketProcessor"></a>SocketProcessor</h3><p>具体的 http 请求头等解析操作全是 Http11NioProcessor 处理的, 但是是在 NioEndpoint.SocketProcessor 线程的run()方法里调用的.</p>
<ul>
<li>结构(属性)<ul>
<li>NioChannel socket</li>
<li>SocketStatus status</li>
</ul>
</li>
</ul>
<h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p>Executor 拿到 Poller 传过来的 socket 后,将 socket 封装在 SocketProcessor 对象中.<br>然后从 Http11ConnectionHandler 中取出 Http11NioProcessor 对象.</p>
<h3 id="PollerEvent"><a href="#PollerEvent" class="headerlink" title="PollerEvent"></a>PollerEvent</h3><p>对 NioChannel 的包装,用于注册到 Poller.event 队列中.</p>
<ul>
<li>属性<ul>
<li>NioChannel socket<ul>
<li>NioChannel是 非阻塞通道.负责将数据读到缓冲区中,或将数据从缓冲区中写入.</li>
</ul>
</li>
<li>int interestOps; // 感兴趣的事件,第一次是OP_REGISTER</li>
<li>KeyAttachment key;// KeyAttachment包装nioChannel</li>
</ul>
</li>
</ul>
<h3 id="KeyAttachment"><a href="#KeyAttachment" class="headerlink" title="KeyAttachment"></a>KeyAttachment</h3><ul>
<li>注册到SelectionKey上的附件,对 NioChannel 的包装类.</li>
</ul>
<h3 id="NioBufferHandler"><a href="#NioBufferHandler" class="headerlink" title="NioBufferHandler"></a>NioBufferHandler</h3><ul>
<li>分配nio的buffer的读写空间,内部包含ByteBuffer类型的readbuf和writebuf属性.在构建NioChannel时使用.</li>
</ul>
<h3 id="Http11ConnectionHandler"><a href="#Http11ConnectionHandler" class="headerlink" title="Http11ConnectionHandler"></a>Http11ConnectionHandler</h3><ul>
<li>结构(属性)<ul>
<li><code>protected final Map&lt;S,Processor&lt;S&gt;&gt; connections = new ConcurrentHashMap&lt;S,Processor&lt;S&gt;&gt;();</code><br>connections 这个 Map维护NioChannel(内部包含socket通道)与processor的关系(如Http11NioProcessor).<br>所以若processor一次不能读取到 所需的所有数据,就等下一次poller轮询时根据socket找到这个processor继续读取.</li>
</ul>
</li>
</ul>
<h3 id="Http11NioProcessor"><a href="#Http11NioProcessor" class="headerlink" title="Http11NioProcessor"></a>Http11NioProcessor</h3><p>nio方式解析请求头等.</p>
<ul>
<li>结构<ul>
<li>InternalNioInputBuffer</li>
<li>InternalNioOutputBuffer</li>
</ul>
</li>
</ul>
<h3 id="Nio涉及的其他类"><a href="#Nio涉及的其他类" class="headerlink" title="Nio涉及的其他类"></a>Nio涉及的其他类</h3><ul>
<li>NioChannel<ul>
<li>作用<ul>
<li>NioChannel是 非阻塞通道.负责将数据读到缓冲区中,或将数据从缓冲区中写入.</li>
</ul>
</li>
<li>结构<ul>
<li>Nio.SocketChannel</li>
<li>NioEndpoint.NioBufferHandler</li>
</ul>
</li>
</ul>
</li>
<li>SocketProperties<ul>
<li>从server.xml的Connector节点上获取参数值,设置nio的socket属性</li>
</ul>
</li>
</ul>
<h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><ul>
<li>路由</li>
</ul>
<h3 id="CoyoteAdapter"><a href="#CoyoteAdapter" class="headerlink" title="CoyoteAdapter"></a>CoyoteAdapter</h3><ul>
<li>将Connector和Engine适配起来.</li>
</ul>
<h3 id="处理请求"><a href="#处理请求" class="headerlink" title="处理请求"></a>处理请求</h3><h4 id="1-Acceptor线程"><a href="#1-Acceptor线程" class="headerlink" title="1. Acceptor线程"></a>1. Acceptor线程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 1.Acceptor线程操作 NioEndpoint中 acceptor.run()</span><br><span class="line">- 该acceptor线程一直循环,直到接收到关闭命令</span><br><span class="line">- countUpOrAwaitConnection(); 通过 LimitLatch 增加连接计数,若已经到达 最大连接数,则让该acceptor线程等待(直到其他线程释放连接),相当于拒绝掉客户端请求</span><br><span class="line">- socket &#x3D; serverSock.accept(); 接收新连接,返回SocketChannel客户端连接对象,这里用的是阻塞模式. 整个循环靠此处阻塞,直到接收到客户端请求才继续往下走</span><br><span class="line">- setSocketOptions(socket) 设置socket属性,这里面主要 将socketChannel包装到nioChannel里. 再将nioChannel包装到PollerEvent里,并放入轮询的事件队列events中</span><br><span class="line">    - socket.configureBlocking(false); 将socket连接通道设置为非阻塞模式</span><br><span class="line">    - Socket sock &#x3D; socket.socket(); 从nio.SocketChannel中获取java.net.Socket</span><br><span class="line">    - socketProperties.setProperties(sock); 设置socket的参数值(从server.xml的Connector节点上获取参数值), 如 socket发送,接收的大小.心跳检测,超时时长等</span><br><span class="line">    - NioChannel channel &#x3D; nioChannels.poll(); 构造NioChannel对象,从ConcurrentLinkedQueue (即NioChannel的缓存队列) 中取</span><br><span class="line">        - 附:ConcurrentLinkedQueue&lt;NioChannel&gt;类型的nioChannels对象的作用 将关闭通道的nioChannel放入Queue缓存起来,方便复用.复用时替换掉其内部的SocketChannel对象即可, NioChannel包含的其他属性只需做重置操作即可.当获取不到时再重新创建</span><br><span class="line">        - 取不到则新创建 channel &#x3D; new NioChannel(socket, bufhandler); 将socketChannel对象 封装到NioChannel对象中.非SSL的.  </span><br><span class="line">        1.socket参数: 进行读写操作的nio.SocketChannel对象.  </span><br><span class="line">        2.bufhandler参数: 为NioChannel.NioBufferHandler.这个类用于 根据xml配置 分配nio的buffer的读写空间. 是对nio.Buffer的封装. 提供用于操作 待写入SocketChannel缓存区 和  读取SocketChannel的缓冲区的方法.</span><br><span class="line">    - getPoller0().register(channel); 将新接收到的SocketChannel注册到event队列上 (将nioChannel包装成PollerEvent 注册到轮询线程events上)</span><br><span class="line">        - getPoller0() 轮询当前的Poller线程数组,从中取出一个Poller并返回</span><br><span class="line">        - Poller.register() 将新接收到的SocketChannel注册到event队列上(nioChannel包装成PollerEvent 注册到轮询线程) </span><br><span class="line">            1.创建KeyAttachment并与poller关联;  2.将channelSocket(nioChannel)包装成PollerEvent 注册到事件队列(events)中;  3.是否需要对selector wakeup的处理</span><br><span class="line">            - new KeyAttachment(socket) 创建或从缓存中取出KeyAttachment并重置. KeyAttachment是对NioChannel的一层包装</span><br><span class="line">            - ka.reset(this,socket,getSocketProperties().getSoTimeout()); 重置KeyAttachment对象中Poller,NioChannel等成员变量的引用</span><br><span class="line">            - ka.interestOps(SelectionKey.OP_READ); 设置keyAttachement 读操作(SelectionKey.OP_READ) 为感兴趣的操作</span><br><span class="line">            - PollerEvent r &#x3D; eventCache.poll(); 从通道缓存队列中取出一个PollerEvent. 取到则重置属性,取不到则新建</span><br><span class="line">                - 取不到则新建 r &#x3D; new PollerEvent(socket,ka,OP_REGISTER); 若取出为空,则新建.将nioChannel包装到PollerEvent对象中. 否则,重置PollerEvent中的属性. 并注册一个OP_REGISTER(对应)928行pollerEvent.run()里</span><br><span class="line">            - poller.addEvent(r); 将PollerEvent添加到轮询队列(poller.events)中. 相当于每个poller都维护了一个event队列,代表这个poller需要处理的事件列表</span><br><span class="line">                - events.offer(event); 将event添加到events队列中</span><br><span class="line">                - if ( wakeupCounter.incrementAndGet() &#x3D;&#x3D; 0 ) selector.wakeup(); </span><br><span class="line">                    使一个还未返回的 select() 方法立即返回.即若当前事件队列中 没有事件,则唤醒处于阻塞在selector.select()状态上的线程(会唤醒selector).与1208行对应</span><br><span class="line">                    - 附:Poller类中protected AtomicLong wakeupCounter &#x3D; new AtomicLong(0l);的作用 唤醒 多路复用器(即nio中的selector)的条件阈值.</span><br><span class="line">                    作用: 1.告诉Poller当前有多少个新连接,这样当Poller进行selector的操作时,可以选择是否需要阻塞来等待读写请求到达; </span><br><span class="line">                    2.标识Poller在进行select选择时,是否有连接到达.如果有,就让当前的阻塞调用立即返回</span><br></pre></td></tr></table></figure>
<h4 id="2-Poller线程"><a href="#2-Poller线程" class="headerlink" title="2. Poller线程"></a>2. Poller线程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 2.Poller线程操作 poller.run()</span><br><span class="line">- poller.events() 从events队列中取出pollerEvent对象并run(); 即处理轮询器的事件队列中的事件,若事件队列是空的则返回false,否则返回true. 每个poller都有一个events队列,poller会一直循环取出里面的event进行处理</span><br><span class="line">    - while ( (r &#x3D; events.poll()) !&#x3D; null ) 循环从events队列 中 逐个取出PollerEvent事件,运行每一个PollerEvent的处理逻辑</span><br><span class="line">    - r.run(); 运行每一个PollerEvent的处理逻辑.即PollerEvent.run(). 注意,此处还是在当前线程中完成.因为调用的是r.run()不是r.start(), 可以理解成只是一个普通方法,在当前而不是新起一个线程</span><br><span class="line">        - PollerEvent.run() 若这个pollerEvent中的interestOps是OP_REGISTER, 则将pollerEvent.nioChannel.socketChannel注册到poller.selector上</span><br><span class="line">            - if ( interestOps &#x3D;&#x3D; OP_REGISTER ) </span><br><span class="line">            &#x2F;&#x2F; PollerEvent最初的interestOps就是OP_REGISTER socket.getIOChannel().register(socket.getPoller().getSelector(), SelectionKey.OP_READ, key); </span><br><span class="line">            从nioChannel中获取socketChannel,从poller中获取selector. 则此时将socketChannel.register(selector, OP_READ, keyAttachment),即将socketChannel向selector注册读感兴趣事件.  </span><br><span class="line">    - 上一步r.run()执行完后 ((PollerEvent)r).reset(); eventCache.offer((PollerEvent)r); 只要从events中取出后,便重置PollerEvent并缓存到eventCache中, 方便复用PollerEvent对象</span><br><span class="line">- Iterator&lt;SelectionKey&gt; iterator &#x3D; keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; 根据向selector中注册的key遍历channel中已经就绪的SelectionKey,并处理这些key</span><br><span class="line">    - iterator遍历 SelectionKey sk &#x3D; iterator.next(); KeyAttachment attachment &#x3D; (KeyAttachment)sk.attachment(); 这里的attachment()返回的就是在register()中注册的KeyAttachement,该对象是对socket的包装类  attachment.access();更新 通道最近一次发生事件的事件,防止因超时没有事件发生而被剔除出selector iterator.remove();从迭代器中移除掉(因为下一步processKey就处理它)</span><br><span class="line">    - processKey(sk, attachment); 具体处理通道的逻辑,交由SocketProcessor处理 sk为SelectionKey</span><br><span class="line">        - NioChannel channel &#x3D; attachment.getChannel(); 从keyAttachment中获取nioChannel</span><br><span class="line">        - if (sk.isReadable() || sk.isWritable() ) &#123; SelectionKey处理通道(channel)发生的 读写事件 &#125;</span><br><span class="line">            - unreg(sk, attachment, sk.readyOps()); 在通道上 注销 对已经发生事件的关注, 防止通道对同一个事件不断select的问题</span><br><span class="line">            - 若sk.isReadable() 通道读事件的处理</span><br><span class="line">                - processSocket(channel, SocketStatus.OPEN_READ, true) 把SocketProcessor交给Excutor去执行.</span><br><span class="line">                    - 创建SocketProcessor实例 SocketProcessor sc &#x3D; processorCache.poll(); 从SocketProcessor缓存队列中取出一个来处理socket, 没有则新建.</span><br><span class="line">                    有则重置属性 new SocketProcessor(socket,status) socketProcessor内的socket属性为NioChannel类型</span><br><span class="line">                    - getExecutor().execute(sc); 将socketProccessor任务交由org.apache.tomcat.util.threads.ThreadPoolExecutor线程池处理, 则该线程池会调用socketProcessor.run() .</span><br><span class="line">                    即SocketProcessor实例是对NioChannel的封装.由Executor执行socketProcessor.run()方法</span><br></pre></td></tr></table></figure>
<h4 id="3-SocketProcessor线程"><a href="#3-SocketProcessor线程" class="headerlink" title="3. SocketProcessor线程"></a>3. SocketProcessor线程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 3.SocketProcessor线程操作 socketProcessor.run()</span><br><span class="line">- socketProcessor.run()总体逻辑 1.使用nio方式 读取套接字 并进行处理, 输出响应报文;2.连接计数器减1,腾出通道;3.关闭套接字</span><br><span class="line">- SelectionKey key &#x3D; socket.getIOChannel().keyFor(socket.getPoller().getSelector()); 从socket(SocketProcessor的成员变量NioChannel类型)中获取SelectionKey</span><br><span class="line">- ka &#x3D; (KeyAttachment)key.attachment(); 从SelectionKey中获取关联的keyAttachment</span><br><span class="line">- synchronized (socket) &#123;&#x2F;&#x2F; 对NioChannel加锁     doRun(selectionkey, keyAttachment); &#125;  socketProcessor的具体逻辑</span><br><span class="line">    - state &#x3D; handler.process(ka, status); 此处handler为Http11NioProtocol$Http11ConnectionHandler, 这个静态类虽然在Http11NioProtocol内部,但是它持有Http11NioProtocol对象</span><br><span class="line">        - 调用父类AbstractProtocol.AbstractConnectionHandler.process() 该内部类的主要逻辑是获取HttpProcessor,缓存取 或新建</span><br><span class="line">            - state &#x3D; processor.process(wrapper); 使用Http11NioProcessor处理socket请求. 此处processor为Http11NioProcessor对象</span><br><span class="line">                - 父类AbstractHttp11Processor.process() 其实后面操作全是Http11NioProcessor处理了, 但是是在Endpoint.SocketProcessor线程的run()方法里调用的</span><br><span class="line">                    - getInputBuffer().init(socketWrapper, endpoint); 初始化 输入流.将socket的输入流 赋值给InterInputBuffer的inputStream属性</span><br><span class="line">                        - InternalNioInputBuffer.init() 设置internalNioInputBuffer的成员变量.如socket,buf大小,SelectorPool</span><br><span class="line">                    - getOutputBuffer().init(socketWrapper, endpoint); 初始化 输出流</span><br><span class="line">                        - 设置selectorPool和socket</span><br><span class="line">                    - getInputBuffer().parseRequestLine(keptAlive))  解析请求行</span><br><span class="line">                        - 即InternalNioInputBuffer.parseRequestLine()</span><br><span class="line">                            - InternalNioInputBuffer.fill(true,false) 读取socket数据到buf字节数组中. timeout:是否有超时;  block:是否阻塞读</span><br><span class="line">                                - InternalNioInputBuffer.readSocket() </span><br><span class="line">                                    从socket中读取数据到buf字节数组中. 从底层socket读取数据.有阻塞式 和 非阻塞式 从 socket中读. </span><br><span class="line">                                    若采用nio,在处理http请求的requestLine和header时非阻塞.  </span><br><span class="line">                                    处理body时必须阻塞 (因为读取body部分的 代码一般是在servlet部分控制的即上层代码控制,已经超出tomcat控制范围). </span><br><span class="line">                                    - socket.getBufHandler().getReadBuffer().clear();  清空nio.ByteBuffer,方便下面将socket里读取的新数据写进去</span><br><span class="line">                                    - 由于block&#x3D;false,此处非阻塞读 即nRead &#x3D; socket.read(socket.getBufHandler().getReadBuffer());</span><br><span class="line">                                        - sc.read(dst); 其实就是socketChannel.read(buffer) &#x2F;&#x2F; read into buffer</span><br><span class="line">                                    - if (nRead &gt; 0) &#123;&#x2F;&#x2F; 若有数据读取出来     </span><br><span class="line">                                        socket.getBufHandler().getReadBuffer().flip();&#x2F;&#x2F; 调用ByteBuffer.flip()将buffer切换到读模式     </span><br><span class="line">                                        socket.getBufHandler().getReadBuffer().limit(nRead);&#x2F;&#x2F; 设置buffer.limit就是本次读取的长度     </span><br><span class="line">                                        expand(nRead + pos);&#x2F;&#x2F; 检查当前对象的buf字节数组容量是否够大,若不够则扩容     </span><br><span class="line">                                        socket.getBufHandler().getReadBuffer().get(buf, pos, nRead);&#x2F;&#x2F; 将socket读取的数据 转移到当前对象的buf数组中     </span><br><span class="line">                                        lastValid &#x3D; pos + nRead;&#x2F;&#x2F; 更新最后一个有效数据的下标     </span><br><span class="line">                                        return nRead; &#125;</span><br><span class="line">                    - getInputBuffer().parseHeaders() 解析请求头</span><br><span class="line">                    - adapter.service(request, response); 将socket封装成request,response,再交给adapter做后续处理</span><br><span class="line">                        - coyteAdapter.postParseRequest()</span><br><span class="line">                            - 匹配请求对应的Host,Context,Wrapper </span><br><span class="line">                            connector.getMapper().map(serverName, decodedURI, version, request.getMappingData()); </span><br><span class="line">                            request.setContext((Context) request.getMappingData().context); </span><br><span class="line">                            request.setWrapper((Wrapper) request.getMappingData().wrapper);</span><br><span class="line">                        - connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); 调用container.调用StandardEngine的pipeline 处理request和response</span><br><span class="line">                            - StandardEngineValve.invoke()中 host.getPipeline().getFirst().invoke(request, response);</span><br><span class="line">                                - AccessLogValve.invoke()中 getNext().invoke(request, response); 没做事,直接调下一个管道</span><br><span class="line">                                    - ErrorReportValve.invoke() tomcat错误输出页面</span><br><span class="line">                                        - StandardHostValve.invoke() context.getPipeline().getFirst().invoke(request, response);</span><br><span class="line">                                            - AuthenticatorBase.invoke() getNext().invoke(request, response);</span><br><span class="line">                                                - StandardContextValve.invoke() wrapper.getPipeline().getFirst().invoke(request, response); 调用wrapper的pipeline来处理请求,即StandardWrapperValve</span><br><span class="line">                                                    - StandardWrapperValve.invoke() filterChain.doFilter(request.getRequest(), response.getResponse()); 调用fiterChain来处理 request 和 response</span><br><span class="line">                                                        - ApplicationFilterChain.doFilter()中 internalDoFilter(request,response);</span><br><span class="line">                                                            - filter.doFilter(request, response, this); 调用具体filter.doFilter方法</span><br><span class="line">                                                                - WsFilter.doFilter()</span><br><span class="line">                                                                    - ApplicationFilterChain.internalDoFilter()中 servlet.service(request, response); 调用对应servlet.service()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat Session机制</title>
    <url>/2019/12/20/01no/tomcat/tomcat03-session/</url>
    <content><![CDATA[<h1 id="tomcat-session"><a href="#tomcat-session" class="headerlink" title="tomcat session"></a>tomcat session</h1><h2 id="相关类"><a href="#相关类" class="headerlink" title="相关类"></a>相关类</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.catalina.Manager</span><br><span class="line"></span><br><span class="line">StandardManager</span><br><span class="line"></span><br><span class="line">SessionIdGenerator</span><br></pre></td></tr></table></figure>
<h2 id="Manager实现类"><a href="#Manager实现类" class="headerlink" title="Manager实现类"></a>Manager实现类</h2><p>Manager 用于管理 session.默认实现是 StandardManager,基类 ManagerBase.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Manager</span><br><span class="line">    ClusterManager (org.apache.catalina.ha)</span><br><span class="line">        ClusterManagerBase (org.apache.catalina.ha.session)</span><br><span class="line">            BackupManager (org.apache.catalina.ha.session)</span><br><span class="line">            DeltaManager (org.apache.catalina.ha.session)</span><br><span class="line">    ManagerBase (org.apache.catalina.session)</span><br><span class="line">        PersistentManagerBase (org.apache.catalina.session)</span><br><span class="line">            PersistentManager (org.apache.catalina.session)</span><br><span class="line">        ClusterManagerBase (org.apache.catalina.ha.session)</span><br><span class="line">            BackupManager (org.apache.catalina.ha.session)</span><br><span class="line">            DeltaManager (org.apache.catalina.ha.session)</span><br><span class="line">        StandardManager (org.apache.catalina.session)</span><br></pre></td></tr></table></figure></p>
<h2 id="StandardManager的实现"><a href="#StandardManager的实现" class="headerlink" title="StandardManager的实现"></a>StandardManager的实现</h2><p>通过 SessionIdGenerator 为每个会话生成,分配一个唯一标识.若集群环境,可配置后面加上tomcat集群标识.</p>
<p>过期会话处理,在 backgroundProcess() 中.它不断循环判断所有会话中是否有过期的,一旦过期则移除.</p>
<p>StandContext 停止时,将该 web 应用的所有 session 持久化到磁盘中,文件名 SESSIONS.ser.</p>
<p>当 web 应用启动时,会加载这些持久化的会话,加载完成后,SESSIONS.ser 将会被删除.</p>
<h3 id="session获取和创建"><a href="#session获取和创建" class="headerlink" title="session获取和创建"></a>session获取和创建</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- request.getSession(true)获取session对象,true表示没有则创建session</span><br><span class="line">    - RequestFacade.getSession()</span><br><span class="line">        - connector.Request.getSession()</span><br><span class="line">            - doGetSession()</span><br><span class="line">            - 1.获取StandContext</span><br><span class="line">            - 2.若session不为null,则isValid()校验session是否失效,校验通过直接返回session</span><br><span class="line">            - 3.若上面没有获取到session,则尝试根据requestedSessionId通过manager.findSession()去查找session</span><br><span class="line">            - 4.manager.createSession(sessionId)创建session</span><br><span class="line">                - 1.超过最大允许创建的session数量则报错</span><br><span class="line">                - 2.createEmptySession()创建standardSession对象并设置session超时时间等参数</span><br><span class="line">                - 3.generateSessionId()通过sessionIdGenerator生成sessionId设置到session.id属性中</span><br><span class="line">            - 5.基于刚刚创建的session创建一个新的cookie,其实就是向响应头中添加Set-Cookie: JSESSIONID&#x3D;AA97BC74DD24D2423386C81DB98CED8B; Path&#x3D;&#x2F;books; HttpOnly</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/tomcat/chrome中查看生成的cookie.png" alt="chrome中查看生成的cookie"></p>
<p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/tomcat/请求头和响应头中的cookie相关信息.png" alt="请求头和响应头中的cookie相关信息"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- session.setAttribute(KEY, username)设置session属性</span><br><span class="line">    - StandardSessionFacade.setAttribute()</span><br><span class="line">        - StandSession.setAttribute()</span><br><span class="line">            - 保存key-value到protected ConcurrentMap&lt;String, Object&gt; attributes &#x3D; new ConcurrentHashMap&lt;String, Object&gt;();里</span><br></pre></td></tr></table></figure>
<h3 id="session清理"><a href="#session清理" class="headerlink" title="session清理"></a>session清理</h3><p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/tomcat/backgroundProcessor后台清理session线程调用栈.png" alt="backgroundProcessor后台清理session线程调用栈"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ConatinerBase$ContainerBackgroundProcessor.run()</span><br><span class="line">    - StandContext.backgroundProcess()</span><br><span class="line">        - 父类 ContainerBase 逻辑,判断 Manager 不为 null,调用 manager.backgroundProcess().</span><br><span class="line">            - manager.backgroundProcess()控制默认60s才执行一次清理.调用ManagerBase.processExpires()</span><br><span class="line">                - ManagerBase.processExpires()中</span><br><span class="line">                - 1.获取所有sessions</span><br><span class="line">                - 2.遍历每一个session,通过isValid()判断是否失效并处理失效</span><br><span class="line">                    - isValid()里通过当前时间戳,thisAccessedTime,maxInactiveInterval决定是否需要session失效,若失效调用expire()处理</span><br><span class="line">                        - expire()会调用相关sessionListeners,并从ManagerBase里sessions这个map中移除session</span><br></pre></td></tr></table></figure>
<p>session thisAccessedTime 更新时机.<br>在 StandardSession.thisAccessedTime 属性上 添加 field watchpoint<br>创建session 时默认 thisAccessedTime 值 就是 creationTime<br><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/tomcat/Request回收session调用栈.png" alt="Request回收session调用栈"></p>
<ol>
<li><p>tomcat 在处理完请求之后,会对 Request 对象进行回收,并且会回收 Session,此时会更新 thisAccessedTime</p>
</li>
<li><p>request.getSession()时,若创建 session,会在 StandardSession.setCreationTime()里更新 thisAccessedTime.若是获取session,会在 StandardSession.access() 里更新 thisAccessedTime 为 当前时间.</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat实现分布式session</title>
    <url>/2019/12/20/01no/tomcat/tomcat04-distribute-session/</url>
    <content><![CDATA[<h1 id="tomcat实现分布式session"><a href="#tomcat实现分布式session" class="headerlink" title="tomcat实现分布式session"></a>tomcat实现分布式session</h1><p>tomcat-redis-session-manager</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>Copy the following files into the TOMCAT_BASE/lib directory:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tomcat-redis-session-manager-VERSION.jar</span><br><span class="line">jedis-2.5.2.jar</span><br><span class="line">commons-pool2-2.2.jar</span><br></pre></td></tr></table></figure>
<p>配置 TOMCAT_HOME/conf/context.xml<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Valve</span> <span class="attr">className</span>=<span class="string">"com.radiadesign.catalina.session.RedisSessionHandlerValve"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Manager</span> <span class="attr">className</span>=<span class="string">"com.radiadesign.catalina.session.RedisSessionManager"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">host</span>=<span class="string">"localhost"</span>   </span></span><br><span class="line"><span class="tag">         <span class="attr">port</span>=<span class="string">"6379"</span> <span class="attr">database</span>=<span class="string">"0"</span> </span></span><br><span class="line"><span class="tag">         <span class="attr">maxInactiveInterval</span>=<span class="string">"30"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>mvn 里搜 Tomcat Redis Session Manager<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.bluejeans/tomcat-redis-session-manager --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.bluejeans<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tomcat-redis-session-manager<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="相关类"><a href="#相关类" class="headerlink" title="相关类"></a>相关类</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RedisSessionHandlerValve</span><br><span class="line"></span><br><span class="line">RedisSession</span><br><span class="line"></span><br><span class="line">RedisSessionManager</span><br><span class="line"></span><br><span class="line">JavaSerializer</span><br><span class="line"></span><br><span class="line">DeserializedSessionContainer</span><br><span class="line"></span><br><span class="line">Serializer</span><br><span class="line"></span><br><span class="line">SessionSerializationMetadata</span><br></pre></td></tr></table></figure>
<p>其中 RedisSessionHandlerValve 是在 context 层配置的 value.</p>
<p>RedisSessionManager 继承自 tomcat 的 ManagerBase,实现 Lifecycle 接口.</p>
<p>RedisSession 继承自 tomcat 的 StandardSession.</p>
<h2 id="RedisSessionHandlerValve-对-session-的处理"><a href="#RedisSessionHandlerValve-对-session-的处理" class="headerlink" title="RedisSessionHandlerValve 对 session 的处理"></a>RedisSessionHandlerValve 对 session 的处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- RedisSessionHandlerValve.invoke()</span><br><span class="line">- 1.调用后续value.invoke()</span><br><span class="line">- 2.RedisSessionManager.afterRequest()</span><br><span class="line">    - 1.从ThreadLocal中取出当前线程对应的redisSession</span><br><span class="line">    - 2.若有,则复用父类StandardSession.isValid()判断session是否失效</span><br><span class="line">    - 2.1.若未失效,则save()保存session到redis</span><br><span class="line">        - 若SessionPersistPolicy即session持久化策略为ALWAYS_SAVE_AFTER_REQUEST,则通过jedis获取连接,将redisSession序列化成sessionAttributesHash.</span><br><span class="line">        最终存入redis的key是sessionId,value是序列化后的updatedSerializationMetadata.</span><br><span class="line">        设置key的失效时间为session的最大失效时间 jedis.expire(binaryId, getMaxInactiveInterval())</span><br><span class="line">    - 2.2.若session失效,则从redis中remove()掉session</span><br><span class="line">        - 通过jedis.del(session.getId())删除session</span><br></pre></td></tr></table></figure>
<h2 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h2><p>getSession() 从 redis 中 获取, createSession() 存入 redis.</p>
<p>load() 和 unload() 都是 空逻辑,因为生命周期交给redis管理了.</p>
<p>session清理 也不需要做了,向redis中存入key的时候已经设置了key的失效时间.</p>
<h2 id="see"><a href="#see" class="headerlink" title="@see"></a>@see</h2><p><a href="https://github.com/jcoleman/tomcat-redis-session-manager.git" target="_blank" rel="noopener">tomcat-redis-session-manager github</a></p>
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat Lifecycle</title>
    <url>/2019/12/19/01no/tomcat/tomcat01-lifecycle/</url>
    <content><![CDATA[<h1 id="LifeCycle"><a href="#LifeCycle" class="headerlink" title="LifeCycle"></a>LifeCycle</h1><h2 id="LifeCycle-相关类"><a href="#LifeCycle-相关类" class="headerlink" title="LifeCycle 相关类"></a>LifeCycle 相关类</h2><p>LifeCycle 接口中的状态扭转注释,如下:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*            start()</span><br><span class="line">*  -----------------------------</span><br><span class="line">*  |                           |</span><br><span class="line">*  | init()                    |</span><br><span class="line">* NEW -»-- INITIALIZING        |</span><br><span class="line">* | |           |              |     ------------------«-----------------------</span><br><span class="line">* | |           |auto          |     |                                        |</span><br><span class="line">* | |          \|&#x2F;    start() \|&#x2F;   \|&#x2F;     auto          auto         stop() |</span><br><span class="line">* | |      INITIALIZED --»-- STARTING_PREP --»- STARTING --»- STARTED --»---  |</span><br><span class="line">* | |         |                                                            |  |</span><br><span class="line">* | |destroy()|                                                            |  |</span><br><span class="line">* | --»-----«--    ------------------------«--------------------------------  ^</span><br><span class="line">* |     |          |                                                          |</span><br><span class="line">* |     |         \|&#x2F;          auto                 auto              start() |</span><br><span class="line">* |     |     STOPPING_PREP ----»---- STOPPING ------»----- STOPPED -----»-----</span><br><span class="line">* |    \|&#x2F;                               ^                     |  ^</span><br><span class="line">* |     |               stop()           |                     |  |</span><br><span class="line">* |     |       --------------------------                     |  |</span><br><span class="line">* |     |       |                                              |  |</span><br><span class="line">* |     |       |    destroy()                       destroy() |  |</span><br><span class="line">* |     |    FAILED ----»------ DESTROYING ---«-----------------  |</span><br><span class="line">* |     |                        ^     |                          |</span><br><span class="line">* |     |     destroy()          |     |auto                      |</span><br><span class="line">* |     --------»-----------------    \|&#x2F;                         |</span><br><span class="line">* |                                 DESTROYED                     |</span><br><span class="line">* |                                                               |</span><br><span class="line">* |                            stop()                             |</span><br><span class="line">* ---»------------------------------»------------------------------</span><br></pre></td></tr></table></figure></p>
<p>LifeCycle 实现类,所有主要组件都实现了 LifeCycle 接口.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Container (org.apache.catalina)</span><br><span class="line">    Host (org.apache.catalina)</span><br><span class="line">        TesterHost (org.apache.tomcat.unittest)</span><br><span class="line">        StandardHost (org.apache.catalina.core)</span><br><span class="line">    ContainerBase (org.apache.catalina.core)</span><br><span class="line">        StandardEngine (org.apache.catalina.core)</span><br><span class="line">        StandardWrapper (org.apache.catalina.core)</span><br><span class="line">        StandardHost (org.apache.catalina.core)</span><br><span class="line">        StandardContext (org.apache.catalina.core)</span><br><span class="line">    Wrapper (org.apache.catalina)</span><br><span class="line">        StandardWrapper (org.apache.catalina.core)</span><br><span class="line">            ExistingStandardWrapper in Tomcat (org.apache.catalina.startup)</span><br><span class="line">    Context (org.apache.catalina)</span><br><span class="line">        TesterContext (org.apache.tomcat.unittest)</span><br><span class="line">        FailedContext (org.apache.catalina.startup)</span><br><span class="line">        StandardContext (org.apache.catalina.core)</span><br><span class="line">    Engine (org.apache.catalina)</span><br><span class="line">        StandardEngine (org.apache.catalina.core)</span><br><span class="line">Executor (org.apache.catalina)</span><br><span class="line">    StandardThreadExecutor (org.apache.catalina.core)</span><br><span class="line">LifecycleBase (org.apache.catalina.util)</span><br><span class="line">    StandardPipeline (org.apache.catalina.core)</span><br><span class="line">    LifecycleMBeanBase (org.apache.catalina.util)</span><br><span class="line">    StoreBase (org.apache.catalina.session)</span><br><span class="line">    SessionIdGeneratorBase (org.apache.catalina.util)</span><br><span class="line">WebappClassLoaderBase (org.apache.catalina.loader)</span><br><span class="line">    WebappClassLoader (org.apache.catalina.loader)</span><br><span class="line">    ParallelWebappClassLoader (org.apache.catalina.loader)</span><br><span class="line">Service (org.apache.catalina)</span><br><span class="line">    StandardService (org.apache.catalina.core)</span><br><span class="line">Server (org.apache.catalina)</span><br><span class="line">    StandardServer (org.apache.catalina.core)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Lifecycle接口</span><br><span class="line">    - 所有需要被生命周期管理的容器 都需要实现该接口</span><br><span class="line">    - 定义生命周期事件,如BEFORE_INIT_EVENT</span><br><span class="line">    - 定义生命周期方法,如init(),start(),stop()</span><br><span class="line">    - 定义监听器操作:添加监听器,查询所有监听器,移除监听器 如addLifecycleListener(),findLifecycleListeners(),removeLifecycleListener()</span><br><span class="line"></span><br><span class="line">- LifecycleBase类</span><br><span class="line">    - Lifecycle接口的基础实现.基本实现逻辑: 比如,当调用standardServer.init()</span><br><span class="line">        - 由于该容器类继承LifecycleBase类,且未重写init()方法, 所以会调用到LifecycleBase.init()方法</span><br><span class="line">            - LifecycleBase.init()方法中先调用 LifecycleBase.setStateInternal(LifecycleState.INITIALIZING, null, false) 变更生命周期状态为LifecycleState.INITIALIZING 这个变更会调用各个事件监听中的 初始化方法</span><br><span class="line">            - 模板方法,调用各个子类容器中的实现逻辑 即initInternal()方法,这个方法一般被子类覆盖,执行子类自己的逻辑 如StandServer.initInternal()</span><br><span class="line">            - 变更状态为初始化完成</span><br><span class="line"></span><br><span class="line">- 各个容器类</span><br><span class="line">    - 实现init()等生命周期方法,且自行调用子容器相应的生命周期方法, 如:standServer.init() 会调用 standardService.init()</span><br><span class="line"></span><br><span class="line">- LifecycleState 生命周期状态枚举类</span><br><span class="line">    - 涉及的状态,如</span><br><span class="line">        - NEW(false, null), INITIALIZING(false, Lifecycle.BEFORE_INIT_EVENT), INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT), STARTING_PREP(false, Lifecycle.BEFORE_START_EVENT), STARTING(true, Lifecycle.START_EVENT), STARTED(true, Lifecycle.AFTER_START_EVENT), STOPPING_PREP(true, Lifecycle.BEFORE_STOP_EVENT), STOPPING(false, Lifecycle.STOP_EVENT), STOPPED(false, Lifecycle.AFTER_STOP_EVENT), DESTROYING(false, Lifecycle.BEFORE_DESTROY_EVENT), DESTROYED(false, Lifecycle.AFTER_DESTROY_EVENT), FAILED(false, null)</span><br><span class="line">    - 生命周期状态转化</span><br><span class="line">        - 如一个容器调用init()后,状态转化为NEW-&gt;INITIALIZING-&gt;INITIALIZED</span><br><span class="line"></span><br><span class="line">- LifecycleSupport 辅助类</span><br><span class="line">    - 用于帮助管理该组件或容器上的监听器,里面维护了一个监听器数组,并提供了注册,移除,触发监听器等方法</span><br></pre></td></tr></table></figure>
<h2 id="LifeCycle-实现"><a href="#LifeCycle-实现" class="headerlink" title="LifeCycle 实现"></a>LifeCycle 实现</h2><p>简单的说,各个容器会在需要的时候注册不同的 LifecycleListener,在容器启动时会触发状态扭转,每到一个状态就会遍历已经注册到 LifecycleSupport 上的所有listener.如果这个listener实现了对应状态的方法,则会调用该方法的逻辑.</p>
<h3 id="注册监听流程"><a href="#注册监听流程" class="headerlink" title="注册监听流程"></a>注册监听流程</h3><p>比如 HostConfig, ContextConfig, MapperListener 就实现了 LifecycleListener 接口.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 注册监听 lifecycleBase.addLifecycleListener()</span><br><span class="line">    - lifecycleSupport.addLifecycleListener(listener);</span><br><span class="line">        - lifecycleSupport持有listener数组,和锁对象 </span><br><span class="line">        private LifecycleListener listeners[] &#x3D; new LifecycleListener[0]; </span><br><span class="line">        private final Object listenersLock &#x3D; new Object(); &#x2F;&#x2F; Lock object for changes to listeners </span><br><span class="line">        加锁并创建 lifecycleListener 对象 添加到 listeners 数组中</span><br></pre></td></tr></table></figure>
<p>LifecycleSupport.addLifecycleListener()方法<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addLifecycleListener</span><span class="params">(LifecycleListener listener)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">synchronized</span> (listenersLock) &#123;</span><br><span class="line">        LifecycleListener results[] =</span><br><span class="line">        <span class="keyword">new</span> LifecycleListener[listeners.length + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; listeners.length; i++)</span><br><span class="line">            results[i] = listeners[i];</span><br><span class="line">        results[listeners.length] = listener;</span><br><span class="line">        listeners = results;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="简要的init-流程"><a href="#简要的init-流程" class="headerlink" title="简要的init()流程"></a>简要的init()流程</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- LifecycleBase.init() 初始化,会触发初始化前和初始化后的监听 生命周期事件INITIALIZING-&gt;INITIALIZED</span><br><span class="line">    - 1.先判断状态是否为LifecycleState.NEW(默认是)</span><br><span class="line">    - LifecycleBase.setStateInternal(LifecycleState.INITIALIZING, null, false); 变更生命周期状态为LifecycleState.INITIALIZING 调用各个事件监听中的 初始化方法</span><br><span class="line">        - state.getLifecycleEvent(); 获取LifecycleState(生命周期状态)对应的生命周期方法.如INITIALIZING状态对应before_init()方法</span><br><span class="line">        - fireLifecycleEvent(lifecycleEvent, data) 触发生命周期事件.如状态为INITIALIZING对应before_init</span><br><span class="line">            - lifecycleSupport.fireLifecycleEvent() 其中LifecycleSupport对象是LifecycleBase中的成员变量,传入this如StandServer private LifecycleSupport lifecycle &#x3D; new LifecycleSupport(this);</span><br><span class="line">                - 遍历listeners数组,每一个listener都调用lifecycleEvent()</span><br><span class="line">    - 3.initInternal();这个方法一般被子类覆盖,执行子类自己的逻辑</span><br><span class="line">        - 如StandServer.initInternal()逻辑</span><br><span class="line">            - super.initInternal();</span><br><span class="line">    - 容器初始化完毕，LifecycleBase会将容器的状态更改为初始化完毕 setStateInternal(LifecycleState.INITIALIZED, null, false); 这样会导致调用所有listener中的lifecycleEvent()方法,各监听器会在 该方法中根据需要处理INITIALIZED事件</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat启动流程</title>
    <url>/2019/12/19/01no/tomcat/tomcat02-start/</url>
    <content><![CDATA[<h1 id="tomcat-启动"><a href="#tomcat-启动" class="headerlink" title="tomcat 启动"></a>tomcat 启动</h1><h2 id="启动流程"><a href="#启动流程" class="headerlink" title="启动流程"></a>启动流程</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Bootstrap.main()</span><br><span class="line">    - Bootstrap bootstrap &#x3D; new Bootstrap(); 实例化Bootstrap实例</span><br><span class="line">    - bootstrap.init(); 1.设置catalinaHome和catalinaBase 2.初始化类加载器,实例化**ClassLoaders</span><br><span class="line">        - setCatalinaHome(); 设置Catalina path,System.getProperty(&quot;catalina.home&quot;),值为tomcat根目录</span><br><span class="line">        - setCatalinaBase(); 值为D:\workspace-e3\.metadata\.plugins\org.eclipse.wst.server.core\tmp2</span><br><span class="line">        - initClassLoaders(); 实例化**ClassLoaders，创建URLClassLoader</span><br><span class="line">            - 初始化classloader,第二个参数为父classLoader commonLoader &#x3D; createClassLoader(&quot;common&quot;, null); catalinaLoader &#x3D; createClassLoader(&quot;server&quot;, commonLoader); sharedLoader &#x3D; createClassLoader(&quot;shared&quot;, commonLoader); 最终执行结果是,创建了commonLoader,catalinaLoader 和 sharedLoader,其中 catalinaLoader 和 sharedLoader 默认均使用 父classLoader: 即 commonLoader</span><br><span class="line">                - bootstrap.createClassLoader()</span><br><span class="line">                    - 读取配置文件中配置的仓库路径(需要加载的jar包的路径) CatalinaProperties.getProperty(name + &quot;.loader&quot;);</span><br><span class="line">                        - CatalinaProperties类中静态块中 static &#123;loadProperties();&#125; 后续从properties中取</span><br><span class="line">                            - loadProperties()方法, 读取catalina.base\\conf\\catalina.properties配置文件到prop属性中 D:\workspace-e3\.metadata\.plugins\org.eclipse.wst.server.core\tmp2\conf\catalina.properties</span><br><span class="line">                    - bootstrap.replace()将$&#123;catalina.home&#125;等替换成具体的路径</span><br><span class="line">                    - 根据逗号截取出每个资源路径</span><br><span class="line">                    - URL url &#x3D; new URL(repository); 先判断是不是网络资源,即先尝试使用URL加载,若它是网络资源则能加载成功, 否则捕获异常接着下面使用本地加载</span><br><span class="line">                    - 本地加载.根据路径结尾以*.jar,.jar或路径,创建不同类型的repository对象</span><br><span class="line">                        - RepositoryType枚举类分类</span><br><span class="line">                            - DIR,&#x2F;&#x2F; 表示整个目录下的资源,包括所有Class,Jar包以及其他类型资源</span><br><span class="line">                            - GLOB,&#x2F;&#x2F; 表示整个目录下所有的Jar包资源,仅仅是.jar后缀的资源</span><br><span class="line">                            - JAR,&#x2F;&#x2F; 表示单个Jar包资源</span><br><span class="line">                            - URL&#x2F;&#x2F; 表示从URL上获取的Jar包资源</span><br><span class="line">                    - 根据以上的repository列表创建classLoader. ClassLoaderFactory.createClassLoader(repositories, parent)</span><br><span class="line">                        - 遍历repositories,判断repositoryType.目的是将每种资源转换为new URL(),并添加到URL[]数组中 </span><br><span class="line">                        0.若是RepositoryType.URL类型的资源,直接new一个URL实例即可 </span><br><span class="line">                        1.若是DIR类型,则根据路径创建java.net.URL对象; </span><br><span class="line">                        2.若是GLOB(这里是E:\Java\apache-tomcat-7.0.82-01\lib),则遍历该目录下的jar包,创建文件,每个jar文件对应一个URL对象;</span><br><span class="line">                        - 最后根据以上所有的url,创建URLClassLoader并返回.该类构造器接收一个URL[]数组类型 return new URLClassLoader(array)</span><br><span class="line">        - Thread.currentThread().setContextClassLoader(catalinaLoader); 为当前线程设置classLoader为catalinaLoader</span><br><span class="line">        - 若启用了安全管理,则会在这里加载一些所需的包(默认不启用) SecurityClassLoad.securityClassLoad(catalinaLoader);</span><br><span class="line">        - 使用catalinaLoader加载catalina类 Class&lt;?&gt; startupClass &#x3D; catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;); Object startupInstance &#x3D; startupClass.newInstance();</span><br><span class="line">        - 设置catalina对象的parentClassLoader属性为sharedLoader, 由于前面sharedLoader默认使用的是父加载器commonLoader, 所以此处相当于设置为commonLoader org.apache.catalina.startup.Catalina.setParentClassLoader(sharedLoader);</span><br><span class="line">        - bootstrap对象 保存catalina的引用 catalinaDaemon &#x3D; startupInstance;</span><br><span class="line">    - 处理&quot;start&quot;命令</span><br><span class="line">        - 1.setAwait(true) 设置catalina.await&#x3D;true</span><br><span class="line">        - 2.daemon.load(args); 加载配置资源，通过反射调用catalina.load()方法 (1)创建digester实例,digester解析conf&#x2F;server.xml文件 (2)调用Server.init()级联初始化各个组件</span><br><span class="line">            - Catalina中 initDirs() 设置catalina.base和catalina.home和user.dir的property属性, 检查java.io.tmpdir属性是否存在</span><br><span class="line">            - initNaming() 设置java.naming.factory.url.pkgs和java.naming.factory.initia这两个System.setProperty</span><br><span class="line">            - 创建并执行digester,使用digester解析server.xml Digester digester &#x3D; createStartDigester(); Digester类按照预定的规则解析server.xml，将元素转化为对象， 包括构造对象，set属性到对象字段，同时维护相互关联关系</span><br><span class="line">                - new Digester() 创建digester对象</span><br><span class="line">                - digester.addObjectCreate() 1)添加对象创建规则ObjectCreateRule 2)SetPropertiesRule 3)SetNextRule 添加StandardServer等各级容器的关系和处理规则</span><br><span class="line">                - 创建Server实例,默认实现类是StandardServer, 可以通过server节点的className属性指定自己的实现,一般不需要</span><br><span class="line">                - 设置Server属性</span><br><span class="line">                - 调用setServer()将Server设置到Catalina对象中.可在本Catalina类中搜索setServer()方法</span><br><span class="line">                - 创建JNDI实例对象,GlobalNamingResources,并设置其属性.并调用standServer.setGlobalNamingResources()方法装配到server中</span><br><span class="line">                - 为Server添加生命周期监听</span><br><span class="line">                - 创建service实例,创建完成后,通过addService()添加到server中</span><br><span class="line">                - 为server添加生命周期监听器.默认未指定监听器,347行的null</span><br><span class="line">                - 为service添加Executor</span><br><span class="line">                - 为service添加Connector</span><br><span class="line">                - 设置属性时,将executor属性排除在外.因为Connector创建时,即ConnectorCreateRule类中, 会判断当前是否指定了executor属性.若是,则从Service中查找该名称的executor并设置到Connector中.</span><br><span class="line">                - 为Connector添加 生命周期监听器.默认未指定</span><br><span class="line">                - 添加子元素解析规则.这部分指定了Servlet容器相关的各级嵌套子节点的解析规则. 且每类嵌套子节点的解析封装为一个RuleSet类(跟进去看).包括GlobalNamingResources,Engine,Context,Cluster的解析</span><br><span class="line">            - 使用sax读取server.xml file &#x3D; configFile();</span><br><span class="line">            - digester.parse(inputSource); 使用digester解析读取的xml,在此过程中会初始化各个组件实例及其依赖关系. 最后会把server.xml文件中的内容解析到StandardServer中 (创建standServer对象并维护对象间关系)</span><br><span class="line">                - configure();</span><br><span class="line">                - getXMLReader().parse(input);</span><br><span class="line">                    - ......</span><br><span class="line">                        - 经过java里SAXPaser解析InputSource后,调用Digester.startElement()</span><br><span class="line">                            - 遍历rules rule.begin(namespaceURI, name, list); 分别创建StandardServer实例</span><br><span class="line">                                - new StandardServer()构造器</span><br><span class="line">                                    - new NamingResources()</span><br><span class="line">                                    - new NamingContextListener() addLifecycleListener(namingContextListener);</span><br><span class="line">                                - setPropertiesRule()</span><br><span class="line">                            - standardService.addConnector()</span><br><span class="line">                            - standardServer.addService() 向server中添加一个新的service. digester在xml解析时会注入这个关系</span><br><span class="line">                            - digester解析会做很多初始化操作,以后细化...</span><br><span class="line">                            - Connector con &#x3D; new Connector(attributes.getValue(&quot;protocol&quot;)); 创建Connector,会有多个Connector,和xml中配置的数量有关</span><br><span class="line">                                - Connector构造器</span><br><span class="line">                                    - setProtocol(protocol);</span><br><span class="line">                                        - 根据xml配置的协议类型,此处是Http11Protocol setProtocolHandlerClassName (&quot;org.apache.coyote.http11.Http11Protocol&quot;);</span><br><span class="line">                                    - 实例化Http11Protocol</span><br><span class="line">                                        - Http11Protocol构造器</span><br><span class="line">                                            - endpoint &#x3D; new JIoEndpoint();</span><br><span class="line">            - getServer().init(); 调用Server的init()方法,初始化各个组件. 它会调用各个service子容器的init()方法, 从而级联完成组件初始化 在调用init()时第3步,调用子类StandardService.initInternal(); 各个组件有个共同的父类: LifecycleBase,用于管理组件的生命周期和状态变化。 在走Server.init()前,先走父类LifecycleBase.init(),事件驱动当前组件状态的变化. 从StandardServer到StandardWrapper,都会调用initInternal(), 并伴随调用共有父类LifecycleBase.init()</span><br><span class="line">                - init()方法在父类LifecycleBase中, 调用父类LifecycleBase.init()</span><br><span class="line">                    - super.initInternal(); 即父类LifecycleBase.initInternal()</span><br><span class="line">                        - 1.先判断状态是否为LifecycleState.NEW(默认是)  </span><br><span class="line">                          2.LifecycleBase.setStateInternal(LifecycleState.INITIALIZING, null, false); 变更生命周期状态为LifecycleState.INITIALIZING 调用各个事件监听中的 初始化方法</span><br><span class="line">                        - 3.initInternal();这个方法一般被子类覆盖,执行子类自己的逻辑 此处为StandServer.initInternal()</span><br><span class="line">                            - StandServer.initInternal()中 super.initInternal(); 调用父类LifecycleMBeanBase.initInternal()</span><br><span class="line">                                - LifecycleMBeanBase.initInternal()中 将容器托管到JMX，便于运维管理</span><br><span class="line">                            - 遍历services调用service.init() services[i].init();</span><br><span class="line">                                - StandardService.init()中 init()方法在父类LifecycleBase中, 调用父类LifecycleBase.init()</span><br><span class="line">                                    - LifecycleBase.init()中 setStateInternal(LifecycleState.INITIALIZING, null, false); 变更生命周期状态为LifecycleState.INITIALIZING(通过事件变更)</span><br><span class="line">                                    - initInternal();&#x2F;&#x2F; 进入子类的initInternal()方法, 即调用StandardService.initInternal()</span><br><span class="line">                                        - StandardService.initInternal()中 container.init(); 此处container即为StandardEngine.init()  StandardEngine的子容器standardContext及其子容器没有init初始化逻辑</span><br><span class="line">                                            - StandardEngine.init()中,略去LifecycleBase中生命周期变更的重复逻辑 StandardEngine.initInternal()中 getRealm(); 创建realm</span><br><span class="line">                                            - super.initInternal(); 即为ContainerBase.initInternal() Engine,Host,Context,Wrapper容器都拥有共同父类ContainerBase</span><br><span class="line">                                                - ContainerBase.initInternal()中 startStopExecutor &#x3D; new ThreadPoolExecutor() 初始化startStopExecutor,用于管理启动和关闭的线程</span><br><span class="line">                                                - super.init()即LifecycleMBeanBase.initInternal()</span><br><span class="line">                                                    - ......略去各个StandardHost.init()</span><br><span class="line">                                                        - ...</span><br><span class="line">                                                            - lifecycleBase.init()</span><br><span class="line">                                                                - LifecycleBase.setStateInternal(LifecycleState.INITIALIZED, null, false);初始化完成 StandardContext父类LifecycleBase变更生命周期状态,调用各个事件监听中的 initializing</span><br><span class="line">                                                                - initInternal();&#x2F;&#x2F; 进入子类StandardContext.initInternal()方法</span><br><span class="line">                                                                    - super.initInternal(); StandardContext.initInternal()调用父类ContainerBase.initInternal() 它会创建startStopExecutor 并调用父类LifecycleMBeanBase.initInternal(); 这里会将容器托管到JMX</span><br><span class="line">                                                                    - this.addLifecycleListener(new TldConfig()); 添加TldConfig监听</span><br><span class="line">                                                                - setStateInternal(LifecycleState.INITIALIZED, null, false); &#x2F;&#x2F; 更新组件生命周期状态为LifecycleState.INITIALIZED</span><br><span class="line">                                                                    - ...</span><br><span class="line">                                                                        - contextConfig.lifecycleEvent() contextConfig AFTER_INIT_EVENT生命周期事件处理</span><br><span class="line">                                                                            - contextConfig.init(); context初始化阶段,context属性配置 tomcat提供的默认配置添加到context实例 完成对应的 每个web应用项目的配置解析(web.xml)</span><br><span class="line">                                                                                - createContextDigester()</span><br><span class="line">                                                                                - contextDigester.getParser();</span><br><span class="line">                                                                                - contextConfig(contextDigester);  解析config.xml配置 E:\Java\apache-tomcat-7.0.82-01\conf\context.xml</span><br><span class="line">                                                                                - createWebXmlDigester()</span><br><span class="line">                                                                            - beforeStart() Lifecycle.BEFORE_START_EVENT状态</span><br><span class="line">                                        - executor.init(); 初始化executors,即tomcat间可共享的线程池</span><br><span class="line">                                        - connector初始化</span><br><span class="line">                                            - connector.initInternal();</span><br><span class="line">                                                - adapter &#x3D; new CoyoteAdapter(this); 构建与指定连接器关联的新CoyoteAdapter</span><br><span class="line">                                                - protocolHandler.setAdapter(adapter); 给 协议处理器 添加 adapter</span><br><span class="line">                                                - protocolHandler.init(); 初始化具体协议类型，如Http11Protocol协议</span><br><span class="line">                                                    - AbstractHttp11JsseProtocol.init()</span><br><span class="line">                                                        - endpoint初始化之前,需要初始化ssl实现类 sslImplementation &#x3D; SSLImplementation.getInstance(sslImplementationName); return new org.apache.tomcat.util.net.jsse.JSSEImplementation();</span><br><span class="line">                                                        - super.init(),即AbstractProtocol.init() 1.注册组件JIoEndPoint;  2.endpoint.init() 设置work threads的数量，默认为200，并创建serverSocket对象</span><br><span class="line">                                                            - abstractProtocol.bind() 设置线程数,网络连接数</span><br><span class="line">                                                                - 初始化acceptor线程数量,默认1个; 初始化最大连接数,此值为server.xml的connector元素的属性MaxThreads值，(若不设置则)默认200</span><br><span class="line">                                                                - abstractEndpoint.getMaxThreadsWithExecutor() 返回成员变量maxThreads&#x3D;200</span><br><span class="line">                                                                - abstractEndpoint.setMaxConnections(getMaxThreadsWithExecutor()); 设置最大连接数</span><br><span class="line">                                                                    - initializeConnectionLatch(); 创建LimitLatch对象并初始化连接数 即 connectionLimitLatch &#x3D; new LimitLatch(getMaxConnections());</span><br><span class="line">                                                                - serverSocketFactory &#x3D; new DefaultServerSocketFactory(this); 创建ServerSocketFactory</span><br><span class="line">                                                                - serverSocket &#x3D; serverSocketFactory.createSocket(getPort(),getBacklog()); 创建serverSocket</span><br><span class="line">                                                - 初始化mapper listener mapperListener.init();</span><br><span class="line">                        - 容器初始化完毕，LifecycleBase会将容器的状态更改为初始化完毕 setStateInternal(LifecycleState.INITIALIZED, null, false);</span><br><span class="line">        - 3.daemon.start().即catalina.start() 运行各个组件,容器开始启动.</span><br><span class="line">            - getServer().start() 启动Server 即standardServer.start(),由于未重写该方法. 所以会先调用父类LifecycleBase.start()</span><br><span class="line">                - LifecycleBase.start()中 setStateInternal(LifecycleState.STARTING_PREP, null, false); &#x2F;&#x2F; 启动前将状态设置为LifecycleState.STARTING_PREP</span><br><span class="line">                - startInternal(); &#x2F;&#x2F; 模板方法调用子类逻辑</span><br><span class="line">                    - StandardServer.startInternal();中 1.发布configure_start事件 fireLifecycleEvent(CONFIGURE_START_EVENT, null);</span><br><span class="line">                    - 2.设置状态为starting setState(LifecycleState.STARTING);  3.globalNamingResources.start(); globalNamingResources.start();</span><br><span class="line">                    - 4.services[i].start(); 启动多个Service子容器. 略去LifecycleBase.start()的重复逻辑, 调用standardService.startInternal()</span><br><span class="line">                        - standardService.startInternal()中 container.start(): 启动container,此时container为StandardEngine</span><br><span class="line">                            - StandardEngine.startInternal()中 调用super.startInternal(), 即ContainerBase.startInternal()</span><br><span class="line">                                - ContainerBase.startInternal()中 若配置了loader,manager,cluster,realm等,则会启动这些下属组件.  在engine,host,context等容器的启动逻辑都会调用该父类(ContainerBase)的此方法用于加载启动子容器. containerBase.startInternal()会向线程池 提交启动子容器的任务,并阻塞等待子容器启动的返回结果判定是否启动成功</span><br><span class="line">                                    - ContainerBase.startInternal()中 getLoaderInternal()</span><br><span class="line">                                        - Lock readLock &#x3D; loaderLock.readLock(); readLock.lock(); try &#123;     return loader; &#125; finally &#123;     readLock.unlock(); &#125;</span><br><span class="line">                                    - 若配置了realm组件,则启动 Realm realm &#x3D; getRealmInternal();  if ((realm !&#x3D; null) &amp;&amp; (realm instanceof Lifecycle))      ((Lifecycle) realm).start();</span><br><span class="line">                                    - 若有子容器,则启动 Container children[] &#x3D; findChildren();</span><br><span class="line">                                    - results.add(startStopExecutor.submit(new StartChild(children[i]))); 提交启动子容器的任务,后续StandHost的操作会在新线程中完成</span><br><span class="line">                                        - StartChild.call() class StartChild implements Callable&lt;Void&gt; StartChild类实现Callable,会执行覆写的call()方法</span><br><span class="line">                                            - child.start(); 启动子容器,比如此处Engine的子容器就是Host 即调用standHost.start()</span><br><span class="line">                                                - StandardHost.start() 使用父类LifecycleBase中的start()方法</span><br><span class="line">                                                    - LifecycleBase.start()中</span><br><span class="line">                                                        - LifecycleBase.start()中 setStateInternal(LifecycleState.STARTING_PREP, null, false); 触发before_start事件,即Host容器发布before_start事件, 相关监听器会接收到通知,执行相应逻辑,如HostConfig监听器</span><br><span class="line">                                                            - HostConfig.lifecycleEvent() HostConfig实现LifecycleListener接口,在StandardHost启动时生命周期发生变化时, 会调用HostConfig的lifecycleEvent()对特定事件进行逻辑处理</span><br><span class="line">                                                                - 调用HostConfig.beforeStart() BEFORE_START_EVENT</span><br><span class="line">                                                                    - beforeStart() 会创建appBase和configBase路径所需的目录</span><br><span class="line">                                                                        - 判断host.getCreateDirs(),对appBase和configBase进行mkdirs()</span><br><span class="line">                                                        - lifecycleBase.startInternal(); 会调用子类StandardHost.startInternal()</span><br><span class="line">                                                            - StandardHost.startInternal()中 Valve[] valves &#x3D; getPipeline().getValves();</span><br><span class="line">                                                                - 获取错误阀的阀名,即org.apache.catalina.valves.ErrorReportValve getErrorReportValveClass()</span><br><span class="line">                                                                - 若有错误阀名,尝试遍历所有阀找出这个class类 StandardPipline.getValues() 通过value.getNext()循环遍历将所有Value成数组返回</span><br><span class="line">                                                                - 若没有找到,则反射创建实例,并添加到pipeline中</span><br><span class="line">                                                            - super.startInternal(); 调用ContainerBase.startInternal()新起线程启动子容器(即Host的Context子容器)</span><br><span class="line">                                                                - ContainerBase.startInternal()中 results.add(startStopExecutor.submit(new StartChild(children[i]))); 启动StandardContext!!!!!!后续子节点都是Context容器的操作</span><br><span class="line">                                                                    - 调用StandardContext.start(), 由于该类未重写start(), 所以实际上调用父类lifecycleBase.start()</span><br><span class="line">                                                                        - lifecycleBase.start()中 若是LifecycleState.NEW状态</span><br><span class="line">                                                                        - LifecycleBase.setStateInternal(LifecycleState.STARTING_PREP, null, false); 设置LifecycleState.STARTING_PREP状态,即before_start</span><br><span class="line">                                                                            - 调用ContextConfig.beforeStart(); &#x2F;&#x2F; 在context启动前触发,用于更新Context的docBase属性 和 解决web目录锁的问题</span><br><span class="line">                                                                        - LifecycleBase.startInternal();</span><br><span class="line">                                                                            - 调用子类StandardContext.startInternal() 完成对web应用的初始化工作</span><br><span class="line">                                                                                - StandardContext.startInternal()里经过一系列操作,将状态变更为CONFIGURE_START_EVENT standardContext.fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null); 发布CONFIGURE_START_EVENT事件,contextConfig监听以完成servlet创建</span><br><span class="line">                                                                                    - contextConfig.configureStart(); web应用初始化.解析web.xml文件, 创建wrapper,Filter,ServletContextListener等.</span><br><span class="line">                                                                                        - contextConfig.webConfig()</span><br><span class="line">                                                                                            - webXml.configureContext(context); 解析web.xml,将webXml对象设置给context</span><br><span class="line">                                                                                                - Lin1388 webXml.configureContext(context); 解析servlet,将Servlet包装成Wrapper</span><br><span class="line">                                                                                                    - context.createWrapper()</span><br><span class="line">                                                                                                    - wrapper.setServletClass(servlet.getServletClass()); 将wrapper与servlet绑定</span><br><span class="line">                                                                                                    - context.addChild(wrapper); 将wrapper添加到context中</span><br><span class="line">                                                                                                        - containerBase.addChildInternal(child);</span><br><span class="line">                                                                                                            - child.start(); 即standardWraper.start()</span><br><span class="line">                                                                                                                - Wrapper容器 StandardWrapper.start()</span><br><span class="line">                                                                        - LifecyclesetStateInternal(LifecycleState.STARTED, null, false); 设置LifecycleState.STARTED状态,即after_start</span><br><span class="line">                                                                            - 调用context.setDocBase(originalDocBase);</span><br><span class="line">                                                                        - containerBase.threadStart(); 启动Context层级的后台任务进程.Cluster后台任务(包括部署变更检测,心跳).Pipeline中Value的后台任务处理(如果有定时处理任务)</span><br><span class="line">                                                                - ContainerBase.startInternal()中 setState(LifecycleState.STARTING); 设置容器状态为STARTING,此时会触发START_EVENT生命周期事件.即start事件</span><br><span class="line">                                                                    - 调用HostConfig.start(); Host启动时触发,完成服务器启动过程中的 Web应用部署. 需要 Host的deployOnstartup&#x3D;&quot;true&quot;才会在服务器启动时部署web应用. </span><br><span class="line">                                    - 若有管道,则启动 if (pipeline instanceof Lifecycle)     ((Lifecycle) pipeline).start();</span><br><span class="line">                        - executor.start(); 启动service容器的多个线程池executors</span><br><span class="line">                        - connector.start(); 启动service组件的多个connector</span><br><span class="line">                            - connector.startInternal()</span><br><span class="line">                                - protocolHandler.start(); 启动 协议处理器</span><br><span class="line">                                    - endpoint.start();</span><br><span class="line">                                        - createExecutor(); 创建endpoint私有的线程池,即ThreadPoolExecutor线程池</span><br><span class="line">                                            - abstractEndpoint.createExecutor()</span><br><span class="line">                                                - new TaskQueue(); 用来运行线程池执行器的任务队列,该类extends LinkedBlockingQueue&lt;Runnable&gt;  new TaskThreadFactory()  implements ThreadFactory 线程工厂,用于创建并返回线程  executor &#x3D; new ThreadPoolExecutor() 根据前两者 创建线程池</span><br><span class="line">                                        - initializeConnectionLatch(); 创建LimitLatch对象,之前init时已经创建.此处直接返回</span><br><span class="line">                                        - startAcceptorThreads(); 创建多个Acceptors</span><br><span class="line">                                            - getAcceptorThreadCount(); 获取acceptor线程数量,默认1</span><br><span class="line">                                            - return new JIoEndpoint.Acceptor() implements Runnable; 创建JIoEndpoint</span><br><span class="line">                                            - Thread t &#x3D; new Thread(acceptors[i], threadName); 根据JIoEndpoint创建线程,且是守护线程</span><br><span class="line">                                - mapperListener.start(); 启动 mapperListener</span><br><span class="line">                                    - findDefaultHost(); 从engine中获取defaultHost并设置给mapper</span><br><span class="line">                                        - 从engine中获取defaultHost并设置给mapper mapper.setDefaultHostName(defaultHost);</span><br><span class="line">                                    - addListeners(engine);</span><br><span class="line">                                        - container.addContainerListener(this); container.addLifecycleListener(this); addListeners(child); 其中this为engine,child为host.即给engine注册监听</span><br><span class="line">                                    - registHost() 向mapper注册host及其下的context,wrapper</span><br><span class="line">                                        - mapper.addHost(host.getName(), aliases, host);</span><br><span class="line">                                        - registerContext((Context) container); 向mapper注册context</span><br><span class="line">                                            - prepareWrapperMappingInfo(context, (Wrapper) container, wrappers);</span><br></pre></td></tr></table></figure>
<h2 id="bootstrap-init"><a href="#bootstrap-init" class="headerlink" title="bootstrap.init()"></a>bootstrap.init()</h2><p>创建 commonClassLoader,和 两个子 类加载器 catalinaLoader 和 sharedLoader,当然都是 URLClassLoader 实例,加载 一些 Jar.</p>
<p>设置当前线程的上下文类加载器为 catalinaLoader</p>
<p>设置 Catalina 的 父类加载器为 sharedLoader</p>
<h2 id="处理-start-命令"><a href="#处理-start-命令" class="headerlink" title="处理 start 命令"></a>处理 start 命令</h2><p>分为 load 和 start 两步</p>
<h3 id="load"><a href="#load" class="headerlink" title="load"></a>load</h3><p>读取 conf/server.xml 配置,使用 digester 解析,组装对象.</p>
<p>server.init() 主要遍历 services,调用其 init() 方法<br>状态变更: LifecycleState.NEW -&gt; LifecycleState.INITIALIZING -&gt; initInternal() -&gt; LifecycleState.INITIALIZED</p>
<p>service.init()<br>调用 engine.init(),初始化executor,遍历初始化 connectors</p>
<p>Connector.init()<br>创建 CoyoteAdapter<br>protocolHandler 关联 adapter<br>protocolHandler.init(),这里面会初始化 endpoint<br>mapperListener.init()</p>
<p>StandEngine.init()<br>engine,host,context,wrapper 都继承自 ContainerBase,ContainerBase里会起 startStopExecutor 线程池,这个线程池用于子容器启动,父容器会等待子容器启动完成.</p>
<h3 id="start"><a href="#start" class="headerlink" title="start"></a>start</h3><p>Catalina.start()<br>调用 server.start()</p>
<p>StandardServer.start()<br>触发 CONFIGURE_START_EVENT 事件,设置自身的状态为 STARTING,遍历调用 services.start()</p>
<p>StandService.start()<br>设置状态为 STARTING,调用 engine.start(),excutors.start(),connector.start()</p>
<p>StandEngine.start()<br>会走父类 ContainerBase.startInternal(),在 ContainerBase 中,若配了 loader,manager, cluster, realm 则 启动.<br>然后就查找所有子容器,每个子容器都交由 startStopExecutor 线程池 执行 StartChild 的逻辑,调用 child.start().并通过 future.get() 阻塞等待所有子容器启动成功.<br>pipeline.start()<br>设置线程状态为 STARTING,触发 START_EVENT 生命周期事件.<br>启动一个 ContainerBackgroundProcessor 后台线程.</p>
<p>ContainerBase.startInternal()代码<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">startInternal</span><span class="params">()</span> <span class="keyword">throws</span> LifecycleException </span>&#123;</span><br><span class="line">    <span class="comment">// Start our subordinate components, if any.启动下属组件</span></span><br><span class="line">    Loader loader = getLoaderInternal();</span><br><span class="line">    <span class="keyword">if</span> ((loader != <span class="keyword">null</span>) &amp;&amp; (loader <span class="keyword">instanceof</span> Lifecycle))<span class="comment">// 若配置了loader则启动</span></span><br><span class="line">        ((Lifecycle) loader).start();</span><br><span class="line">    logger = <span class="keyword">null</span>;</span><br><span class="line">    getLogger();</span><br><span class="line">    Manager manager = getManagerInternal();</span><br><span class="line">    <span class="keyword">if</span> ((manager != <span class="keyword">null</span>) &amp;&amp; (manager <span class="keyword">instanceof</span> Lifecycle))</span><br><span class="line">        ((Lifecycle) manager).start();</span><br><span class="line">    Cluster cluster = getClusterInternal();</span><br><span class="line">    <span class="keyword">if</span> ((cluster != <span class="keyword">null</span>) &amp;&amp; (cluster <span class="keyword">instanceof</span> Lifecycle))<span class="comment">// 若配置了集群,则启动</span></span><br><span class="line">        ((Lifecycle) cluster).start();</span><br><span class="line">    Realm realm = getRealmInternal();</span><br><span class="line">    <span class="keyword">if</span> ((realm != <span class="keyword">null</span>) &amp;&amp; (realm <span class="keyword">instanceof</span> Lifecycle))<span class="comment">// 若配置了安全组件Realm,则启动</span></span><br><span class="line">        ((Lifecycle) realm).start();</span><br><span class="line">    DirContext resources = getResourcesInternal();</span><br><span class="line">    <span class="keyword">if</span> ((resources != <span class="keyword">null</span>) &amp;&amp; (resources <span class="keyword">instanceof</span> Lifecycle))</span><br><span class="line">        ((Lifecycle) resources).start();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start our child containers, if any.启动子容器,如果有的话.</span></span><br><span class="line">    Container children[] = findChildren();</span><br><span class="line">    List&lt;Future&lt;Void&gt;&gt; results = <span class="keyword">new</span> ArrayList&lt;Future&lt;Void&gt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; children.length; i++) &#123; <span class="comment">// 提交 启动子容器的任务.并阻塞当前线程等待执行结果</span></span><br><span class="line">        results.add(startStopExecutor.submit(<span class="keyword">new</span> StartChild(children[i]))); <span class="comment">// 子容器使用 startStopExecutor 调用新线程来启动</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> fail = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">for</span> (Future&lt;Void&gt; result : results) &#123; <span class="comment">// 启动 多个子容器的执行结果</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            result.get(); <span class="comment">// 阻塞直到所有子容器启动完毕</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(sm.getString(<span class="string">"containerBase.threadedStartFailed"</span>), e);</span><br><span class="line">            fail = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (fail) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> LifecycleException(</span><br><span class="line">                sm.getString(<span class="string">"containerBase.threadedStartFailed"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start the Valves in our pipeline (including the basic), if any.启动容器持有的Pipeline组件的Value.若有管道,则启动</span></span><br><span class="line">    <span class="keyword">if</span> (pipeline <span class="keyword">instanceof</span> Lifecycle)</span><br><span class="line">        ((Lifecycle) pipeline).start();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置容器状态为STARTING,此时会触发START_EVENT生命周期事件.</span></span><br><span class="line">    setState(LifecycleState.STARTING);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start our thread. 启动该层级的后台定时任务进程(不同容器调用,则启动不同容器的后台线程).用于处理如 Cluster 后台任务(包括部署变更检测,心跳).Realm 后台任务处理.Pipeline 中 Value 的后台任务处理(如果有定时处理任务)</span></span><br><span class="line">    threadStart();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>StandardHost.startInternal()<br>不存在errorValve则创建,调用 ContainerBase.startInternal() 启动子容器.子容器是在 HostConfig.deployXxx里通过<code>host.addChild(context)</code>添加进来的.</p>
<p>StandContext.startInternal()<br>创建 WebappLoader 并启动<br>触发 CONFIGURE_START_EVENT 事件,contextConfig 监听以完成 servlet 创建<br>遍历启动子容器<br>启动pipline<br>触发listener的各种事件<br>初始化filter<br>初始化servlets,调用 load-on-startup 的 servlet 的 init() 方法<br>遍历 wraper,调用 wrapper.load() 加载 wrapper</p>
<p>StandWrapper.startInternal()<br>没什么重要逻辑</p>
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>布隆过滤器</title>
    <url>/2019/12/18/01no/struct/BloomFilter/</url>
    <content><![CDATA[<h1 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h1><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><p>布隆过滤器(Bloom Filter).是一个很长的 二进制向量 和 一系列随机映射 函数.</p>
<p>之所以叫 filter,是在缓存之前,把不存在的 key 给拦截掉.</p>
<p>本质是 一个位数组: 位数组 就是 数组 的 每个元素 都只占用 1 bit,并且每个元素只能是 0 或 1.</p>
<p><code>用于判断: 某个元素 一定不存在 或者 可能存在 于 一个集合中.</code></p>
<p>布隆过滤器除了一个位数组,还有 K 个哈希函数.</p>
<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>一个元素加入布隆过滤器:<br>使用 K 个 哈希函数 对元素值 进行 K 次计算,得到 K 个哈希值.<br>根据得到的哈希值,在 位数组中 把对应下标的值置为 1.</p>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>当查询 w 是否存在时,可以再通过这 k 个 哈希函数,如果算出来所在的位置均为1,则表示 w 可能存在(注意是可能存在),否则一定不存在.</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>1.优点<br>空间效率 和 查询时间 都远远超过一般的算法.</p>
<p>2.缺点<br>有一定的 误识别率 和 删除困难</p>
<p>数组的容量即使再大,也是有限的.</p>
<p>随着元素的增加,插入的元素就会越多,位数组中被置为 1 的位置因此也越多.</p>
<p>这就会造成一种情况:<br>当一个不在布隆过滤器中的元素,经过同样规则的哈希计算之后,得到的值在位数组中查询,有可能这些位置因为之前其它元素的操作先被置为 1 了.</p>
<p><code>有可能一个不存在 布隆过滤器 中的 会被误判成 在布隆过滤器中.</code></p>
<p><code>布隆过滤器说某个元素在,可能会被误判.</code><br><code>布隆过滤器说某个元素不在,那么一定不在.</code></p>
<h2 id="Guava-BloomFilter"><a href="#Guava-BloomFilter" class="headerlink" title="Guava BloomFilter"></a>Guava BloomFilter</h2><p>使用api</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化 BloomFilter</span></span><br><span class="line">BloomFilter&lt;String&gt; bloomFilter = BloomFilter.create(Funnels.unencodedCharsFunnel(), SIZE);</span><br><span class="line"><span class="comment">// 存入数据到 BloomFilter</span></span><br><span class="line">bloomFilter.put(data);</span><br><span class="line"><span class="comment">// 查询s是否在 BloomFilter 中</span></span><br><span class="line">bloomFilter.mightContain(s)</span><br></pre></td></tr></table></figure>
<h2 id="Redis-BloomFilter"><a href="#Redis-BloomFilter" class="headerlink" title="Redis BloomFilter"></a>Redis BloomFilter</h2><p>redis 布隆过滤器的插件 rebloom</p>
<p>BF.ADD 向布隆过滤器中插入数据的命令,插入成功返回 true</p>
<p>BF.EXISTS 判断布隆过滤器中是否存在该数据命令,存在返回true</p>
<h3 id="Redis-引入-BloomFilter-的原因"><a href="#Redis-引入-BloomFilter-的原因" class="headerlink" title="Redis 引入 BloomFilter 的原因"></a>Redis 引入 BloomFilter 的原因</h3><p>数据量较大时,解决缓存穿透</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/yudiandemingzi/spring-boot-redis-lua" target="_blank" rel="noopener">redis bloomFilter demo</a></p>
<p><a href="https://github.com/topics/bloom-filter" target="_blank" rel="noopener">bloom filter topic</a></p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis实现分布式锁</title>
    <url>/2019/12/17/01no/redis/redis10-lock/</url>
    <content><![CDATA[<h1 id="Redis实现分布式锁"><a href="#Redis实现分布式锁" class="headerlink" title="Redis实现分布式锁"></a>Redis实现分布式锁</h1><h2 id="要考虑的点"><a href="#要考虑的点" class="headerlink" title="要考虑的点"></a>要考虑的点</h2><ol>
<li>互斥(独占,只能有一个客户端获取锁)</li>
<li>不能死锁</li>
<li>容错(只要大部分 redis 节点创建了这把锁就认为成功获取到锁)</li>
<li>支持重入,超时获取锁等特性</li>
</ol>
<h2 id="redis实现分布式锁"><a href="#redis实现分布式锁" class="headerlink" title="redis实现分布式锁"></a>redis实现分布式锁</h2><h3 id="1-使用set"><a href="#1-使用set" class="headerlink" title="1.使用set"></a>1.使用set</h3><h4 id="1-1-加锁"><a href="#1-1-加锁" class="headerlink" title="1.1.加锁"></a>1.1.加锁</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET key randomValue NX PX 30000</span><br></pre></td></tr></table></figure>
<p>NX: (not exists)表示只有 key 不存在的时候才会设置成功.(如果此时 redis 中存在这个 key,那么设置失败,返回 nil)<br>PX 30000: 30s 后 key 失效,意味着 30s 后锁自动释放.</p>
<p>随机数 randomValue 可以使用 时间戳 + 客户端编号 的方式 生成随机数.</p>
<h4 id="1-2-释放锁"><a href="#1-2-释放锁" class="headerlink" title="1.2.释放锁"></a>1.2.释放锁</h4><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 删除锁的时候,找到 key 对应的 value,跟自己传过去的 value 做比较,如果是一样的才删除.保证解的是自己加的锁</span></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>, KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>如果 key 对应的 value 一致,则删除这个 key.</p>
<p>通过这个方式释放锁是为了避免 Client 释放了其他 Client 申请的锁.</p>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>这种加的是单机的 redis 锁,会有单点故障问题.</p>
<p>1.单点故障<br>如果是 redis 单实例,那就是单点故障.</p>
<p>如果是 redis 主从架构,即使有 redis 主从异步复制.如果 master 节点挂了(key 就没有了),key 还没同步到 slave 节点,此时 slave 节点 切换为 master 节点,别人就可以 set key,从而拿到锁.</p>
<p>2.超时释放锁的问题<br>1.client A 获得锁成功<br>2.client B 等待 A 释放锁<br>3.client A 超时没释放锁(比如 full gc)<br>4.redis 删除掉 key,释放锁<br>5.client B 获得锁成功<br>6.client B 做修改操作<br>7.client A 恢复做修改操作,覆盖了 client B 的修改</p>
<h4 id="在上面基础上-加-乐观锁"><a href="#在上面基础上-加-乐观锁" class="headerlink" title="在上面基础上 加 乐观锁"></a>在上面基础上 加 乐观锁</h4><p>在lua脚本中,获取锁成功的同时,使用<code>redis.call(&quot;INCRBY&quot;, key, &quot;1&quot;)</code>返回一个单调递增的version.<br>这样假设 A 超时锁被 redis server 释放掉,此时 B 获得锁更新数据成功.A试图更新数据时判断A的版本号低于现在数据的版本号,则不允许A更改.</p>
<h3 id="2-RedLock-实现"><a href="#2-RedLock-实现" class="headerlink" title="2.RedLock 实现"></a>2.RedLock 实现</h3><h4 id="RedLock-原理"><a href="#RedLock-原理" class="headerlink" title="RedLock 原理"></a>RedLock 原理</h4><p>假设有 N 个 Redis master 节点,不考虑主从复制.<br>像在 Redis 单实例上一样获取 和 释放锁.<br>假设有 5 台 Redis 实例,这样同时宕机的概率很低.</p>
<p>获取锁流程:<br>1.获取当前时间</p>
<p>2.依次尝试从 5 个实例上,使用相同的 key 和 唯一的value 获取锁.<br>client 设置一个 网络连接 和 超时响应时间,远小于锁的失效时间.(这能避免 Redis 实例挂了,client 一直等待获得锁的响应).<br>若 server 没有在规定时间内响应,client 应立即尝试去另外一个 Redis 实例上 请求获取锁.</p>
<p>3.client 使用 当前时间 减去 开始获取锁的时间(1中的时间),得到的就是 获取锁使用的时间.<code>当 过半 Redis 节点都获取到锁,且 使用的时间 小于 锁失效时间,锁才算获取成功.</code></p>
<p>4.若成功获取锁,key的失效时间 等于 有效时间 减去 获取锁使用的时间(3中得到的时间).</p>
<p>5.若获得锁失败(比如 没能在过半Redis实例上获得到锁 或 获得锁的时间已经超过了 有效时间),client需要在所有Redis实例上解锁(不管是否加锁了都解锁).</p>
<h4 id="Redisson-对-RedLock-的实现"><a href="#Redisson-对-RedLock-的实现" class="headerlink" title="Redisson 对 RedLock 的实现"></a>Redisson 对 RedLock 的实现</h4><ol>
<li><p>使用api</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RLock redLock = redissonClient.getLock(<span class="string">"REDLOCK_KEY"</span>);</span><br><span class="line"><span class="comment">// 加锁.500ms获取不到锁则认为获取锁失败.锁的失效时间是 10s</span></span><br><span class="line"><span class="keyword">boolean</span> isLock = redLock.tryLock(<span class="number">500</span>, <span class="number">10000</span>, TimeUnit.MILLISECONDS);</span><br><span class="line"><span class="comment">// 解锁</span></span><br><span class="line">redLock.unlock();</span><br></pre></td></tr></table></figure>
</li>
<li><p>加锁时的lua逻辑</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// RedissonLock.tryLockInnerAsync()方法</span></span><br><span class="line">&lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">    internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,</span><br><span class="line">                <span class="comment">// 1.若 加锁的key(hash)不存在</span></span><br><span class="line">                <span class="string">"if (redis.call('exists', KEYS[1]) == 0) then "</span> +</span><br><span class="line">                    <span class="comment">// 通过 hset key uuid+threadId 1 来加锁</span></span><br><span class="line">                    <span class="string">"redis.call('hset', KEYS[1], ARGV[2], 1); "</span> +</span><br><span class="line">                    <span class="comment">// 设置锁(hash)失效时间</span></span><br><span class="line">                    <span class="string">"redis.call('pexpire', KEYS[1], ARGV[1]); "</span> +</span><br><span class="line">                    <span class="string">"return nil; "</span> +</span><br><span class="line">                <span class="string">"end; "</span> +</span><br><span class="line">                <span class="comment">// 2.若 加锁的key(hash)存在 且 uuid+threadId 也存在</span></span><br><span class="line">                <span class="string">"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then "</span> +</span><br><span class="line">                    <span class="comment">// 重入计数加1</span></span><br><span class="line">                    <span class="string">"redis.call('hincrby', KEYS[1], ARGV[2], 1); "</span> +</span><br><span class="line">                    <span class="comment">// 重新设置(hash)失效时间</span></span><br><span class="line">                    <span class="string">"redis.call('pexpire', KEYS[1], ARGV[1]); "</span> +</span><br><span class="line">                    <span class="string">"return nil; "</span> +</span><br><span class="line">                <span class="string">"end; "</span> +</span><br><span class="line">                <span class="comment">// 3.返回锁(hash)的失效时间</span></span><br><span class="line">                <span class="string">"return redis.call('pttl', KEYS[1]);"</span>,</span><br><span class="line">                <span class="comment">// KEYS[1]锁key, ARGV[1]锁失效时间, ARGV[2] uuid+threadId</span></span><br><span class="line">                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>1.加锁的hash不存在.创建hash,通过给 hash 的 key(uuid+threadId) 设置 value 为1.返回 nil表示加锁成功.<br>2.加锁的hash存在 且 key 也存在,表示当前线程重入的情况,重入计数加1.<br>3.走到这表示获取锁失败,返回锁的失效时间.</p>
<ol start="3">
<li>解锁时的lua逻辑</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">unlockInnerAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">            <span class="comment">// 若锁key不存在,说明锁已释放.直接执行 publish 命令 发布释放锁消息 并返回 1</span></span><br><span class="line">            <span class="string">"if (redis.call('exists', KEYS[1]) == 0) then "</span> +</span><br><span class="line">                <span class="comment">// 向channel(即redisson_lock__channel:&#123;lockName&#125;)发送一条消息</span></span><br><span class="line">                <span class="string">"redis.call('publish', KEYS[2], ARGV[1]); "</span> +</span><br><span class="line">                <span class="string">"return 1; "</span> +</span><br><span class="line">            <span class="string">"end;"</span> +</span><br><span class="line">            <span class="comment">// 下面都是锁key存在的情况</span></span><br><span class="line">            <span class="comment">// 锁key存在但是 field(id+threadId) 不匹配,说明不是当前线程加的锁,不管,返回 nil</span></span><br><span class="line">            <span class="string">"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then "</span> +</span><br><span class="line">                <span class="string">"return nil;"</span> +</span><br><span class="line">            <span class="string">"end; "</span> +</span><br><span class="line">            <span class="comment">// 若锁key存在 且 field(id+threadId) 匹配,说明就是当前线程加的锁,重入计数减 1</span></span><br><span class="line">            <span class="string">"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); "</span> +</span><br><span class="line">            <span class="comment">// 重入计数减1后count&gt;0,说明没完全释放掉锁.重新设置失效时间,返回0</span></span><br><span class="line">            <span class="string">"if (counter &gt; 0) then "</span> +</span><br><span class="line">                <span class="string">"redis.call('pexpire', KEYS[1], ARGV[2]); "</span> +</span><br><span class="line">                <span class="string">"return 0; "</span> +</span><br><span class="line">            <span class="comment">// 重入计数减为0的情况,完全释放锁,删除key解锁,publish解锁消息,返回1</span></span><br><span class="line">            <span class="string">"else "</span> +</span><br><span class="line">                <span class="string">"redis.call('del', KEYS[1]); "</span> +</span><br><span class="line">                <span class="string">"redis.call('publish', KEYS[2], ARGV[1]); "</span> +</span><br><span class="line">                <span class="string">"return 1; "</span>+</span><br><span class="line">            <span class="string">"end; "</span> +</span><br><span class="line">            <span class="string">"return nil;"</span>,</span><br><span class="line">            <span class="comment">// KEYS[1]锁key, KEYS[2] channelName, ARGV[1]解锁消息 值为0, ARGV[2]锁失效时间, ARGV[3] id+threadId</span></span><br><span class="line">            Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>1.若锁key不存在,说明锁已释放.直接执行 publish 命令 发布释放锁消息 并返回 1<br>2.锁key存在但是 field(id+threadId) 不匹配,说明不是当前线程加的锁,不管,返回 nil<br>3.若锁key存在 且 field(id+threadId) 匹配,说明就是当前线程加的锁,重入计数减 1<br>3.1.重入计数减1后count&gt;0,说明没完全释放掉锁.重新设置失效时间,返回0<br>3.2.重入计数减为0的情况,完全释放锁,删除key解锁,publish解锁消息,返回1</p>
<h1 id="see"><a href="#see" class="headerlink" title="@see"></a>@see</h1><p><a href="https://github.com/redisson/redisson/wiki/Redisson%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">Redisson项目官方介绍wiki</a></p>
<p><a href="http://www.redis.cn/topics/distlock.html" target="_blank" rel="noopener">Redis实现分布式锁官网</a></p>
<p><a href="https://github.com/redisson/redisson/wiki/8.-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%92%8C%E5%90%8C%E6%AD%A5%E5%99%A8#81-%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81reentrant-lock" target="_blank" rel="noopener">Redisson实现分布式锁官方wiki</a></p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo心跳机制</title>
    <url>/2019/12/15/01no/dubbo/dubbo07-heartbeat/</url>
    <content><![CDATA[<h1 id="Dubbo心跳机制"><a href="#Dubbo心跳机制" class="headerlink" title="Dubbo心跳机制"></a>Dubbo心跳机制</h1><p>Dubbo 默认客户端和服务端都会发送心跳报文,用来保持 TCP 长连接状态.</p>
<p>在客户端和服务端,Dubbo 都会开启一个线程 循环扫描 并 检测连接是否超时.</p>
<p>在服务端发现超时则会主动关闭客户端连接.</p>
<p>在客户端发现超时则会主动重新创建连接.</p>
<p>默认心跳检测时间是 60 秒.</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>provider 心跳默认是在 heartbeat(一分钟)内如果没有读消息或写消息,就会发送心跳请求消息,如果连着3次(180s)没有读消息,provider会关闭channel.</p>
<p>consumer 端的心跳默认是在 一分钟 内如果没有读消息或写消息,就会发送心跳请求消息,如果连着3次(三分钟)没有读消息,consumer会进行重连.</p>
<h2 id="开启定时任务"><a href="#开启定时任务" class="headerlink" title="开启定时任务"></a>开启定时任务</h2><p>provider 在启动 netty时,在 HeaderExchangeServer 的构造方法中,会通过 startHeatbeatTimer() 启动心跳定时任务.<br>consumer 在 HeaderExchangeClient 的构造方法里,同样通过 startHeatbeatTimer() 启动心跳定时任务.<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startHeatbeatTimer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 停止原有定时任务</span></span><br><span class="line">    stopHeartbeatTimer();</span><br><span class="line">    <span class="comment">// 发起新的定时任务</span></span><br><span class="line">    <span class="keyword">if</span> (heartbeat &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        heatbeatTimer = scheduled.scheduleWithFixedDelay(</span><br><span class="line">                <span class="keyword">new</span> HeartBeatTask(<span class="keyword">new</span> HeartBeatTask.ChannelProvider() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Collection&lt;Channel&gt; <span class="title">getChannels</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> Collections.unmodifiableCollection(HeaderExchangeServer.<span class="keyword">this</span>.getChannels());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, heartbeat, heartbeatTimeout),</span><br><span class="line">                heartbeat, heartbeat, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>HeartbeatHandler 会被串在请求和响应的处理链上.每当 received()收到消息时,会更新 ReadTimestamp,当 sent() 时 会更新 writeTimestamp.</p>
<h2 id="HeartBeatTask-逻辑"><a href="#HeartBeatTask-逻辑" class="headerlink" title="HeartBeatTask 逻辑"></a>HeartBeatTask 逻辑</h2><p>1.遍历所有Channel.在服务端遍历的是所有客户端连接,客户端遍历的是所有服务端连接.<br>2.已经 closed 的 channel 不管.<br>3.最后读写的时间,只要有一个超过心跳间隔(默认 heartbeat 是一分钟),就创建并发送心跳 request.<br>4.检测 最后读的时间,若超过心跳超时时间(默认 heartbeatTimeout 是三分钟).若是 client 侧会 reconnect 重连,若是 server 侧会关闭客户端连接.</p>
]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper Watcher机制</title>
    <url>/2019/12/14/01no/zk/zk08_watcher/</url>
    <content><![CDATA[<h1 id="watcher流程"><a href="#watcher流程" class="headerlink" title="watcher流程"></a>watcher流程</h1><p>三个过程:<br>client 注册 Watcher<br>server 处理 Watcher<br>client 回调 Watcher</p>
<h2 id="client-注册-Watcher"><a href="#client-注册-Watcher" class="headerlink" title="client 注册 Watcher"></a>client 注册 Watcher</h2><p>zk client 可以通过 new ZooKeeper(),getData(),getChildren(), exist() 传入 watcher对象 来 注册 Watcher.</p>
<p>比如对于 <code>getData()时注册watcher的操作</code>.实际上 client 就是把 watcher 对象 存到 DataWatchRegistration 里,再创建 Packet,存入 outgoingQueue,等待 SendThread 线程取出来发给 server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 1.创建ZooKeeper对象时注册Watcher</span><br><span class="line">- new ZooKeeper()传入Watcher,会回调Watcher.process()方法</span><br><span class="line">    - ZooKeeper中会创建ZKWatchManager</span><br><span class="line">    - watchManager.defaultWatcher &#x3D; watcher;初始化默认Watcher</span><br><span class="line">    - 解析connectString创建hostProvider</span><br><span class="line">    - 创建客户端连接管理类ClientCnxn</span><br><span class="line">    - 启动ClientCnxn线程</span><br><span class="line">        - ClientCnxn构造方法中创建sendThread和eventThread</span><br><span class="line">            EventThread负责处理Server返回的WatchedEvent,回调注册的客户端事件接口处理函数</span><br><span class="line">            SendThread为outgoing(传出)请求队列提供服务并生成心跳.它还会产生ReadThread</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 2.setData()</span><br><span class="line">- zk.setData(path, data, version);</span><br><span class="line">    - 创建RequestHeader,调用cnxn.submitRequest(h, request, response, null);</span><br><span class="line">        - clientCnxn.submitRequest()中:将Request等信息封装成packet,放入outgoingQueue队列中</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; sendThread逻辑</span><br><span class="line">- ClientCnxn.SendThread中</span><br><span class="line">    - run()逻辑</span><br><span class="line">        - 建立与server的连接</span><br><span class="line">        - 定时发送ping</span><br><span class="line">        - 委托给 clientCnxnSocket.doTransport()进行底层的nio传输</span><br><span class="line">            - ClientCnxnSocketNIO.doIO()中</span><br><span class="line">                从outgoingQueue取出packet</span><br><span class="line">            - p.createBB();&#x2F;&#x2F; 序列化</span><br><span class="line">            - sock.write(p.bb);&#x2F;&#x2F; 发送</span><br><span class="line">            - 从outgoingQueue队列中移除该发送的包</span><br><span class="line">            - pendingQueue.add(p);&#x2F;&#x2F; 将packet加入到pendingQueue队列</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 3.getData()时注册watcher</span><br><span class="line">- zk.getData(zooDataPath, watcher, stat);getData()时注册watcher</span><br><span class="line">    - wcb &#x3D; new DataWatchRegistration(watcher, clientPath); &#x2F;&#x2F; 注册 watcher到DataWatchRegistration中</span><br><span class="line">        - packet &#x3D; new Packet(h, r, request, response, watchRegistration);通过watchRegistration创建packet,存入outgoingQueue,等待发送</span><br></pre></td></tr></table></figure>
<h2 id="server-处理-Watcher"><a href="#server-处理-Watcher" class="headerlink" title="server 处理 Watcher"></a>server 处理 Watcher</h2><p>比如对于 getData()时注册watcher的处理:其实 server端就是在 FinalRequestProcessor 中将 Watcher(其实是NIOServerCnxn对象) 添加到 WatchManager 对象的 watchTable 和 watch2Paths 属性中.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 2.Server处理Watcher</span><br><span class="line">    - 处理客户端发来的zk.getData()注册watcher的请求</span><br><span class="line">        - NIOServerCnxnFactory.run()有读写事件</span><br><span class="line">            - NIOServerCnxn.doIO()</span><br><span class="line">                - NIOServerCnxn.readPayload();&#x2F;&#x2F; 读取内容</span><br><span class="line">                    - NIOServerCnxn.readRequest()</span><br><span class="line">                        - ZooKeeperServer.processPacket()</span><br><span class="line">                            - ZooKeeperServer.submitRequest(si);&#x2F;&#x2F; 提交请求</span><br><span class="line">                                - touch(si.cnxn);&#x2F;&#x2F; 判断session是否存在或者已经超时</span><br><span class="line">                                - firstProcessor.processRequest(si);&#x2F;&#x2F; 处理请求</span><br><span class="line">                                    - Processor链处理...</span><br><span class="line">                                        - FinalRequestProcessor.processRequest()中</span><br><span class="line">                                            - case OpCode.getData:&#x2F;&#x2F; 对于获取数据请求,若有watch会注册</span><br><span class="line">                                                - dataWatches.addWatch(path, watcher);&#x2F;&#x2F; 若有watcher的话则注册watcher,此时watcher为NIOServerCnxn.将Watcher添加到WatchManager对象的watchTable和watch2Paths属性中</span><br></pre></td></tr></table></figure></p>
<p>当server端收到了client端的setData()请求,由于引起了数据变更,会触发  getData()时注册watcher. 其实就是从上面 getData() 时存入的 watchTable 里查出来 watchers 并移除(只触发一次),调用 watcher.process()方法,也就是 NIOServerCnxn.process() 发送给 客户端 Watcher事件.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 3.Server触发Watcher</span><br><span class="line">    - 处理client发来的zk.setData()请求</span><br><span class="line">        - FinalRequestProcessor.processRequest()中</span><br><span class="line">            - rc &#x3D; zks.processTxn(hdr, txn);&#x2F;&#x2F; 处理事务,应用到 dataTree上</span><br><span class="line">                - DataTree.setData()中,有watcher时会触发watcher</span><br><span class="line">                    - dataWatches.triggerWatch(path, EventType.NodeDataChanged); &#x2F;&#x2F; setData()时会导致数据变更,若有watcher会触发watcher</span><br><span class="line">                        - watchers &#x3D; watchTable.remove(path); &#x2F;&#x2F; 获取该path对应的watchers,watchers只触发一次就移除</span><br><span class="line">                        - w.process(e);&#x2F;&#x2F; 进行watcher事件处理,传入WatchedEvent,此时的w是NioServerCnxn对象</span><br><span class="line">                            - NIOServerCnxn.process()中,创建响应头,xid&#x3D;-1代表watcher事件.将WatchedEvent对象转换为WatcherEvent,用于网络传输,响应客户端</span><br></pre></td></tr></table></figure></p>
<h2 id="client-回调-Watcher"><a href="#client-回调-Watcher" class="headerlink" title="client 回调 Watcher"></a>client 回调 Watcher</h2><p>client端 通过 SendThread.readResponse() 接收服务端响应.</p>
<p>根据 replyHdr.xid 判断是 Watcher事件.</p>
<p>将 来自服务端的响应,反序列成 WatcherEvent 对象,WatcherEvent 的信息里只包含 type,state,path 信息.<br><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/zk/client收到的watcher信息.png" alt="client端收到的server端的watcher信息"></p>
<p>然后再将 WatcherEvent 对象 转成 WatchedEvent 对象.<br><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/zk/client通过watcher创建WatchedEvent对象.png" alt="根据watcher信息创建的WatchedEvent对象"></p>
<p>从 ZKWatchManager.dataWatches 中 取出 path 对应的 watcher 并移除(只触发一次),连同 WatchedEvent 创建WatcherSetEventPair 对象.入 waitingEvents 队列,交给 eventThread 线程处理.</p>
<p>eventThread线程 从 waitingEvents 队列里取出对应的 watcher,调用 watcher.process() 处理.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 4.Client回调Watcher</span><br><span class="line">    - SendThread.readResponse()接收服务端响应</span><br><span class="line">        - 根据replyHdr.getXid() &#x3D;&#x3D; -1 判断是Watcher通知,反序列化出WatcherEvent对象</span><br><span class="line">        - eventThread.queueEvent(we);&#x2F;&#x2F; 将Watcher事件 入事件队列,交给EventThread处理</span><br><span class="line">            - watcher.materialize()根据watcher的事件类型进行不同的处理</span><br><span class="line">                - 比如NodeDataChanged和NodeCreated事件</span><br><span class="line">                - 1.从 ZKWatchManager.dataWatches 中移除 clientPath 对应的 watchers(相当于只能触发一次),并将这些移除的 watchers 添加到 result 中返回</span><br><span class="line">            - 通过watcher和event创建WatcherSetEventPair</span><br><span class="line">            - waitingEvents.add(pair);&#x2F;&#x2F; 将WatcherSetEventPair对象入waitingEvents这个LinkedBlockingQueue中(保证watcher顺序)</span><br><span class="line">    - EventThread.run()中</span><br><span class="line">        - 从waitingEvents中取出event,调processEvent(event)</span><br><span class="line">            - processEvent(event)中</span><br><span class="line">                - event中包含实际的watcher对象,直接回调watcher.process()即可</span><br></pre></td></tr></table></figure>
<h1 id="相关类"><a href="#相关类" class="headerlink" title="相关类"></a>相关类</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Watcher</span><br><span class="line">WatchedEvent</span><br><span class="line"></span><br><span class="line">ZooKeeper</span><br><span class="line">ZKWatchManager</span><br><span class="line"></span><br><span class="line">ClientWatchManager</span><br><span class="line"></span><br><span class="line">WatchRegistration</span><br><span class="line">    ChildWatchRegistration</span><br><span class="line">    DataWatchRegistration</span><br><span class="line">    ExistsWatchRegistration</span><br><span class="line"></span><br><span class="line">ClientCnxn</span><br><span class="line">Packet</span><br></pre></td></tr></table></figure>
<h2 id="Watcher接口"><a href="#Watcher接口" class="headerlink" title="Watcher接口"></a>Watcher接口</h2><p>Watcher 接口中包含:<br>1.Event 接口,用于定义<code>事件所代表的状态</code><br>Event 接口中包含 KeeperState(<code>事件发生时zk的状态</code>) 和 EventType(事件类型)两个枚举类<br>2.process() 抽象方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.zookeeper;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Watcher</span> </span>&#123;</span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">    * 表示事件</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Event</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/** </span></span><br><span class="line"><span class="comment">        * 事件发生时Zookeeper的状态</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">enum</span> KeeperState &#123;</span><br><span class="line">            <span class="meta">@Deprecated</span></span><br><span class="line">            Unknown(-<span class="number">1</span>),<span class="comment">// 未知状态.不再使用,服务器不会产生此状态</span></span><br><span class="line"></span><br><span class="line">            Disconnected(<span class="number">0</span>),<span class="comment">// 断开</span></span><br><span class="line"></span><br><span class="line">            <span class="meta">@Deprecated</span></span><br><span class="line">            NoSyncConnected(<span class="number">1</span>),<span class="comment">// 未同步连接.不再使用,服务器不会产生此状态</span></span><br><span class="line"></span><br><span class="line">            SyncConnected(<span class="number">3</span>),<span class="comment">// 同步连接状态</span></span><br><span class="line"></span><br><span class="line">            AuthFailed(<span class="number">4</span>),<span class="comment">// 认证失败状态</span></span><br><span class="line"></span><br><span class="line">            ConnectedReadOnly(<span class="number">5</span>),<span class="comment">// 只读连接状态</span></span><br><span class="line"></span><br><span class="line">            SaslAuthenticated(<span class="number">6</span>),<span class="comment">// SASL认证通过状态</span></span><br><span class="line"></span><br><span class="line">            Expired(-<span class="number">112</span>);<span class="comment">// 过期状态</span></span><br><span class="line">            <span class="comment">// ...</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/** </span></span><br><span class="line"><span class="comment">        * 事件类型</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">enum</span> EventType &#123;</span><br><span class="line">            None(-<span class="number">1</span>),<span class="comment">// 无</span></span><br><span class="line">            NodeCreated(<span class="number">1</span>),<span class="comment">// 节点创建</span></span><br><span class="line">            NodeDeleted(<span class="number">2</span>),<span class="comment">// 节点删除</span></span><br><span class="line">            NodeDataChanged(<span class="number">3</span>),<span class="comment">// 节点数据变化</span></span><br><span class="line">            NodeChildrenChanged(<span class="number">4</span>);<span class="comment">// 节点的子节点变化</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process()方法</span></span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="回调方法-process"><a href="#回调方法-process" class="headerlink" title="回调方法 process()"></a>回调方法 process()</h2><p>zk server 向 client 发送一个 watcher 通知时,会回调对应的 process() 方法.<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">abstract</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span></span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="WatchedEvent"><a href="#WatchedEvent" class="headerlink" title="WatchedEvent"></a>WatchedEvent</h2><p>process()方法的参数 WatchedEvent,zk server会将watcher事件通过 WatchedEvent 对象 传递给 client,WatchedEvent 包含了事件的一些属性:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">WatchedEvent属性</span><br><span class="line">-keeperState: KeeperState <span class="comment">// 通知状态</span></span><br><span class="line">-eventType: EventType <span class="comment">// 事件类型</span></span><br><span class="line">-path: String <span class="comment">// 对应的path</span></span><br></pre></td></tr></table></figure></p>
<h2 id="WatcherEvent"><a href="#WatcherEvent" class="headerlink" title="WatcherEvent"></a>WatcherEvent</h2><p>WatcherEvent 用于网络传输.</p>
<p>zk server 在生成 WatchedEvent 事件后,通过 getwrapper() 将 WatchedEvent 包装成 可序列化的 WatcherEvent事件,用于网络传输.</p>
<p>zk client 接收到 server 的 WatcherEvent 对象后,会将 WatcherEvent 反序列化成 WatchedEvent 事件,传给 process() 方法.</p>
<h2 id="ServerCnxn"><a href="#ServerCnxn" class="headerlink" title="ServerCnxn"></a>ServerCnxn</h2><p>ServerCnxn 实现了 Watcher 接口</p>
<h2 id="WatchManager"><a href="#WatchManager" class="headerlink" title="WatchManager"></a>WatchManager</h2><p>WatchManager 是 ZooKeeper 服务端 Watcher 的管理者,包含 watchTable 和 watch2Paths.</p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Hotspot编译</title>
    <url>/2019/12/12/01no/hotspot/hotspot01-compile/</url>
    <content><![CDATA[<h1 id="hotspot8编译"><a href="#hotspot8编译" class="headerlink" title="hotspot8编译"></a>hotspot8编译</h1><p><a href="https://www.cnblogs.com/simoncook/p/11198117.html" target="_blank" rel="noopener">参照xiaguang的博客</a>,帮我踩了很多坑,虽然编译过程中还是遇到了一点小问题.</p>
<h2 id="修改-ubuntu18-adp-源"><a href="#修改-ubuntu18-adp-源" class="headerlink" title="修改 ubuntu18 adp 源"></a>修改 ubuntu18 adp 源</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vi &#x2F;etc&#x2F;apt&#x2F;sources.list</span><br></pre></td></tr></table></figure>
<p>最好搜索一下最新的国内源<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic main restricted universe multiverse</span><br><span class="line">deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiverse</span><br><span class="line">deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-backports main restricted universe multiverse</span><br><span class="line">deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-backports main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse</span><br><span class="line">deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-proposed main restricted universe multiverse</span><br><span class="line">deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-proposed main restricted universe multiverse</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get update</span><br></pre></td></tr></table></figure>
<h2 id="安装相关依赖"><a href="#安装相关依赖" class="headerlink" title="安装相关依赖"></a>安装相关依赖</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install gcc-4.8</span><br><span class="line">sudo apt-get install g++-4.8</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install  libxext-dev libxrender-dev libxtst-dev libxt-dev</span><br><span class="line">sudo apt-get install libcups2-dev</span><br><span class="line">sudo apt-get install libfreetype6-dev</span><br><span class="line">sudo apt-get install libasound2-dev</span><br></pre></td></tr></table></figure>
<h2 id="clone-hostspot-代码"><a href="#clone-hostspot-代码" class="headerlink" title="clone hostspot 代码"></a>clone hostspot 代码</h2><p>原文是通过 <code>hg clone http://hg.openjdk.java.net/jdk8/jdk8</code> 下载,但是官网速度太慢了.fan了也很慢.</p>
<p>后来找了个github上的镜像,总是下载一半就出问题:<br><a href="https://github.com/unofficial-openjdk/openjdk" target="_blank" rel="noopener">https://github.com/unofficial-openjdk/openjdk</a></p>
<p>最后用gitee里的这个镜像,速度很快,tag 也比较全<br><a href="https://gitee.com/solie/openjdk.git" target="_blank" rel="noopener">https://gitee.com/solie/openjdk.git</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; clone</span><br><span class="line">git clone https:&#x2F;&#x2F;gitee.com&#x2F;solie&#x2F;openjdk.git</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 切分支</span><br><span class="line">git checkout jdk8-b120 </span><br><span class="line"></span><br><span class="line">git checkout -b jdk8-b120-zc jdk8-b120</span><br></pre></td></tr></table></figure>
<p>代码路径<br>/home/flyingzc/java/workspace/01opensource/openjdk</p>
<h2 id="下载并编译-make-3-82"><a href="#下载并编译-make-3-82" class="headerlink" title="下载并编译 make 3.82"></a>下载并编译 make 3.82</h2><p>1.下载地址: <a href="ftp://ftp.gnu.org/gnu/make/make-3.82.tar.gz">ftp://ftp.gnu.org/gnu/make/make-3.82.tar.gz</a></p>
<p>2.解压<br>flyingzc@ubuntu:~/java/downloads$ tar -zxvf make-3.82.tar.gz -C .</p>
<p>3.vim glob/glob.c</p>
<p>将 第 211行, 232行 注释掉,注释后如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#&#x2F;&#x2F; #if !defined __alloca &amp;&amp; !defined __GNU_LIBRARY__</span><br><span class="line">#&#x2F;&#x2F; #endif</span><br></pre></td></tr></table></figure></p>
<h2 id="准备编译-make3-82"><a href="#准备编译-make3-82" class="headerlink" title="准备编译 make3.82"></a>准备编译 make3.82</h2><p>chmod +x configure<br>./configure<br>make<br>./make –version<br><img src="../../assets/hotspot/001make-success.png" alt="make编译成功"></p>
<h2 id="将系统的默认-make-链接成-3-82-版本"><a href="#将系统的默认-make-链接成-3-82-版本" class="headerlink" title="将系统的默认 make 链接成 3.82 版本"></a>将系统的默认 make 链接成 3.82 版本</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;bin&#x2F;</span><br><span class="line"></span><br><span class="line">sudo ln -s  &#x2F;home&#x2F;flyingzc&#x2F;java&#x2F;soft&#x2F;make-3.82&#x2F;make make-3.82</span><br><span class="line"></span><br><span class="line">sudo rm make</span><br><span class="line"></span><br><span class="line">sudo ln -s make-3.82 make</span><br><span class="line"></span><br><span class="line">make --version</span><br><span class="line">输出: GNU Make 3.82</span><br></pre></td></tr></table></figure>
<h2 id="确认-gcc-和-g-是4-8版本"><a href="#确认-gcc-和-g-是4-8版本" class="headerlink" title="确认 gcc 和 g++ 是4.8版本"></a>确认 gcc 和 g++ 是4.8版本</h2><h3 id="gcc"><a href="#gcc" class="headerlink" title="gcc"></a>gcc</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;bin</span><br><span class="line">sudo rm gcc</span><br><span class="line">sudo ln -s gcc-4.8 gcc</span><br></pre></td></tr></table></figure>
<h3 id="g"><a href="#g" class="headerlink" title="g++"></a>g++</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;bin</span><br><span class="line">sudo rm g++</span><br><span class="line">sudo ln -s g++-4.8 g++</span><br></pre></td></tr></table></figure>
<p>输出<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">flyingzc@ubuntu:&#x2F;usr&#x2F;bin$ gcc --version</span><br><span class="line">gcc (Ubuntu 4.8.5-4ubuntu8) 4.8.5</span><br><span class="line">Copyright (C) 2015 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the source for copying conditions.  There is NO</span><br><span class="line">warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br><span class="line"></span><br><span class="line">flyingzc@ubuntu:&#x2F;usr&#x2F;bin$ g++ --version</span><br><span class="line">g++ (Ubuntu 4.8.5-4ubuntu8) 4.8.5</span><br><span class="line">Copyright (C) 2015 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the source for copying conditions.  There is NO</span><br></pre></td></tr></table></figure></p>
<h2 id="修改支持的os版本检查"><a href="#修改支持的os版本检查" class="headerlink" title="修改支持的os版本检查"></a>修改支持的os版本检查</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看内核版本</span><br><span class="line">uname -a</span><br><span class="line">Linux ubuntu 5.0.0-37-generic #40~18.04.1-Ubuntu SMP Thu Nov 14 12:06:39 UTC 2019 x86_64 x86_64 x86_64 GNU&#x2F;Linux</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hotspot&#x2F;make&#x2F;linux&#x2F;Makefile</span><br><span class="line">修改 SUPPORTED_OS_VERSION &#x3D;... 加上4%,不然4.x的内核不支持.我的ubuntu内核是5.x,需要加上 5%</span><br></pre></td></tr></table></figure>
<h2 id="如果存在build目录则删除"><a href="#如果存在build目录则删除" class="headerlink" title="如果存在build目录则删除"></a>如果存在build目录则删除</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf build&#x2F;</span><br><span class="line"></span><br><span class="line">chmod +x configure</span><br><span class="line"></span><br><span class="line">.&#x2F;configure --with-debug-level&#x3D;slowdebug</span><br></pre></td></tr></table></figure>
<h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup make all &amp; tail -f nohup.out</span><br></pre></td></tr></table></figure>
<h2 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Running nasgen</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.VerifyError: class jdk.nashorn.internal.objects.ScriptFunctionImpl overrides final method setPrototype.(Ljava&#x2F;lang&#x2F;Object;)V</span><br><span class="line">	at java.lang.ClassLoader.defineClass1(Native Method)</span><br><span class="line">	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)</span><br><span class="line">	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)</span><br><span class="line">	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)</span><br><span class="line">	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)</span><br><span class="line">	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)</span><br><span class="line">	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.StringConstants.&lt;clinit&gt;(StringConstants.java:85)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.MemberInfo.verify(MemberInfo.java:250)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.ScriptClassInfo.verify(ScriptClassInfo.java:227)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.Main.process(Main.java:108)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.Main.processAll(Main.java:88)</span><br><span class="line">	at jdk.nashorn.internal.tools.nasgen.Main.main(Main.java:62)</span><br><span class="line">make[1]: *** [&#x2F;home&#x2F;flyingzc&#x2F;java&#x2F;workspace&#x2F;01opensource&#x2F;openjdk&#x2F;build&#x2F;linux-x86_64-normal-server-slowdebug&#x2F;nashorn&#x2F;classes&#x2F;_the.nasgen.run] Error 1</span><br><span class="line">make: *** [nashorn-only] Error 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">修改：vim nashorn&#x2F;make&#x2F;BuildNashorn.gmk</span><br><span class="line">第80行 -cp &quot;$(NASHORN_OUTPUTDIR)&#x2F;nasgen_classes$(PATH_SEP) </span><br><span class="line">第80行将原来的 -cp 修改为 -Xbootclasspath&#x2F;p:</span><br></pre></td></tr></table></figure>
<p><a href="https://juejin.im/entry/5a6c36af6fb9a01cb64f05b8" target="_blank" rel="noopener">问题的解决方案来自这里</a></p>
<h2 id="编译成功输出的信息"><a href="#编译成功输出的信息" class="headerlink" title="编译成功输出的信息"></a>编译成功输出的信息</h2><p><img src="../../assets/hotspot/002compile-success.png" alt="编译成功"></p>
<h1 id="解压调试符号包"><a href="#解压调试符号包" class="headerlink" title="解压调试符号包"></a>解压调试符号包</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openjdk&#x2F;build&#x2F;linux-x86_64-normal-server-slowdebug&#x2F;jdk&#x2F;lib&#x2F;amd64&#x2F;server 目录下</span><br><span class="line">unzip libjvm.diz</span><br></pre></td></tr></table></figure>
<p>解压出来的是 libjvm.debuginfo 调试信息文件</p>
]]></content>
      <categories>
        <category>Hotspot</category>
      </categories>
      <tags>
        <tag>Hotspot</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper实现分布式锁</title>
    <url>/2019/12/12/01no/zk/zk20-lock/</url>
    <content><![CDATA[<h1 id="zk实现分布式锁"><a href="#zk实现分布式锁" class="headerlink" title="zk实现分布式锁"></a>zk实现分布式锁</h1><h2 id="zk实现分布式锁的两种方式"><a href="#zk实现分布式锁的两种方式" class="headerlink" title="zk实现分布式锁的两种方式"></a>zk实现分布式锁的两种方式</h2><p>如果要自己通过 zookeeper 的原生 api 实现一个分布式独占锁的话,有两种方式:</p>
<h3 id="方式1-创建临时节点-创建失败的client注册watcher"><a href="#方式1-创建临时节点-创建失败的client注册watcher" class="headerlink" title="方式1: 创建临时节点,创建失败的client注册watcher"></a>方式1: 创建临时节点,创建失败的client注册watcher</h3><p>所有需要获取锁的 client 都尝试到 zk 上创建同一个临时节点.创建成功则表示成功获取锁;若创建失败,则对这个节点注册 watcher.</p>
<p>若获得锁的 client 释放锁(自己 delete 掉节点) 或 宕机(zk 会自动移除掉该临时节点),</p>
<p>其他 client 会收到 watcher 通知,再尝试去抢锁.</p>
<p>这种方式的问题: 很明显竞争很大.在节点失效瞬间,如果争锁的 client 较多,会有大量 client 接收 watcher 通知.</p>
<h3 id="方式2-基于临时顺序节点"><a href="#方式2-基于临时顺序节点" class="headerlink" title="方式2: 基于临时顺序节点"></a>方式2: 基于临时顺序节点</h3><p>创建锁<br>1.每个 client 都在 zk 同一个父节点上创建一个 临时顺序节点<br>2.然后每个 client 获取到父节点下的所有节点并排序,判断自己是否是顺序最小的那个节点<br>2.1.如果是,加锁成功<br>2.2.如果不是,加锁失败.注册 watcher,只用监听自己之前的那个节点即可.</p>
<p>释放锁<br>1.client1 删除自己的临时顺序节点<br>2.后面一个 client2 通过 watcher 感知到节点已经删除,自己是当前最小的那个节点,则获取锁.<br>这种方式,明显 watcher 压力会小很多.不会出现大量竞争.</p>
<h2 id="curator-实现的分布式锁"><a href="#curator-实现的分布式锁" class="headerlink" title="curator 实现的分布式锁"></a>curator 实现的分布式锁</h2><p>很明显之前的思路只是简单的实现.有很多其他的东西没有考虑,比如: 可重入.<br>看一下 curator 实现的时候,对 zookeeper 分布式锁做了哪些处理.</p>
<p>主要看 InterProcessMutex: 分布式可重入排它锁 的实现.</p>
<p>首先 curator 就是使用上面的方式2: 基于临时顺序节点 实现的分布式锁.</p>
<p>curator创建分布式锁的代码如下:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">InterProcessMutex lock = <span class="keyword">new</span> InterProcessMutex(client, lock_path);</span><br><span class="line">lock.acquire(); <span class="comment">// 获取锁</span></span><br><span class="line">lock.release(); <span class="comment">// 释放锁</span></span><br></pre></td></tr></table></figure></p>
<h3 id="获取锁流程"><a href="#获取锁流程" class="headerlink" title="获取锁流程"></a>获取锁流程</h3><p>简单来说就是获取锁时,先处理是否需要重入.然后创建临时顺序节点.然后获取父节点的所有子节点并排序.若当前节点排在最前面获取锁,否则对前一个节点注册watcher并wait()等待被唤醒,如果传入超时时间,就wait(millisToWait).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 获取锁</span><br><span class="line">    - lock.acquire()一直阻塞直到获取到锁,支持重入.</span><br><span class="line">        - InterProcessMutex.internalLock(-1, null)</span><br><span class="line">        - 1.获取当前线程对象</span><br><span class="line">        - 2.ConcurrentMap&lt;Thread, LockData&gt;类型的threadData对象,key是线程对象.value是LockData类型的对象.lockData.lockCount属性用于保存当前线程的重入计数.如果是当前线程重入,则计数加1</span><br><span class="line">        - 3.尝试加锁internals.attemptLock(time, unit, getLockNodeBytes())</span><br><span class="line">            - LockInternals.attemptLock()中</span><br><span class="line">            - 1.循环</span><br><span class="line">            - 1.1.driver.createsTheLock()用这个&#x2F;curator_recipes_lock_path&#x2F;lock-前缀创建临时顺序节点</span><br><span class="line">            - 1.2.hasTheLock &#x3D; internalLockLoop(startMillis, millisToWait, ourPath);</span><br><span class="line">                - internalLockLoop()中</span><br><span class="line">                - 1.只要没获取到锁,循环</span><br><span class="line">                - 1.1.getSortedChildren()比如_c_62f35524-d650-4efc-a121-ea6611b47285-lock-0000000066按照lock-后面的数字排序</span><br><span class="line">                - 1.2.predicateResults &#x3D; driver.getsTheLock()返回是否能拿到锁还是注册watcher</span><br><span class="line">                    - driver.getsTheLock()逻辑</span><br><span class="line">                    - 1.获取当前临时节点在childern里的index并校验</span><br><span class="line">                    - 2.如果是第0个节点getsTheLock设为true表示能获取锁.否则获取当前临时节点的前一个节点设置到pathToWatch里,表示要注册watcher.</span><br><span class="line">                    - 3.封装成PredicateResults结果返回</span><br><span class="line">                - 1.3.若1.2中返回能拿到锁,haveTheLock置为true标识拿到锁,跳出循环.否则加锁,对前一个节点注册watcher并wait()等待被唤醒.</span><br></pre></td></tr></table></figure></p>
<h3 id="释放锁流程"><a href="#释放锁流程" class="headerlink" title="释放锁流程"></a>释放锁流程</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 释放锁</span><br><span class="line">    - lock.release();</span><br><span class="line">    - 1.从threadData中获取当前线程的lockData.lockCount重入计数并减1</span><br><span class="line">    - 2.当1中重入计数减少到0则internals.releaseLock(lockData.lockPath)释放锁</span><br><span class="line">        - 删除节点deleteOurPath(lockPath)</span><br><span class="line">    - 3.从threadData中,删除当前线程的缓存threadData.remove(currentThread)</span><br></pre></td></tr></table></figure>
<h3 id="watcher唤醒"><a href="#watcher唤醒" class="headerlink" title="watcher唤醒"></a>watcher唤醒</h3><p>watcher在 获取锁流程 时候注册上去的.在锁释放的时候,会触发watcher逻辑,唤醒wait的线程.<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注册watcher</span></span><br><span class="line">client.getData().usingWatcher(watcher).forPath(previousSequencePath);</span><br><span class="line"></span><br><span class="line"><span class="comment">// watcher实例如下</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Watcher watcher = <span class="keyword">new</span> Watcher()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 此处会唤醒wait()的线程</span></span><br><span class="line">        notifyFromWatcher();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo Provider处理请求</title>
    <url>/2019/12/05/01no/dubbo/dubbo06-provider/</url>
    <content><![CDATA[<h1 id="服务端接收并响应请求流程"><a href="#服务端接收并响应请求流程" class="headerlink" title="服务端接收并响应请求流程"></a>服务端接收并响应请求流程</h1><h2 id="provider处理请求流程"><a href="#provider处理请求流程" class="headerlink" title="provider处理请求流程"></a>provider处理请求流程</h2><p><img src="../../assets/2019-12-15-16-19-04.png" alt="provider decode"></p>
<p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/dubbo/provider接收线程.png" alt="provider接收线程"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- NettyServerWorker线程接收请求</span><br><span class="line">    - ByteToMessageDecoder.channelRead()</span><br><span class="line">        - ByteToMessageDecoder.callDecode()</span><br><span class="line">            - NettyCodecAdapter.InternalDecoder.decode()</span><br><span class="line">                - DubboCountCodec.decode()解码</span><br><span class="line">        - fireChannelRead(ctx, out, size)</span><br><span class="line">            - NettyServerHandler.channelRead()</span><br><span class="line">                - AbstractPeer.received()</span><br><span class="line">                    - MultiMessageHandler.received()</span><br><span class="line">                        - HeartbeatHandler.received()</span><br><span class="line">                            - AllChannelHandler.received()</span><br><span class="line">                                - cexecutor.execute(new ChannelEventRunnable())&#x2F;&#x2F; 请求派发到线程池处理,逻辑在ChannelEventRunnable.run()里</span><br></pre></td></tr></table></figure>
<p>AllChannelHandler.received()方法中:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">cexecutor.execute(<span class="keyword">new</span> ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));</span><br></pre></td></tr></table></figure><br>会将请求交给 ChannelEventRunnable 进行处理,后续在 DubboServerHandler 线程池里的调用逻辑:</p>
<p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/dubbo/provider处理请求流程调用链.png" alt="provider处理请求流程调用链"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- provider处理请求流程</span><br><span class="line">- ChannelEventRunnable.run()通道事件,判断RECEIVED事件进行处理</span><br><span class="line">    - DecodeHandler.received()解码处理器</span><br><span class="line">        - HeaderExchangeHandler.received()基于消息头的处理</span><br><span class="line">            - 1.HeaderExchangeHandler.handleRequest()处理请求</span><br><span class="line">                - DubboProtocol.requestHandler.reply()</span><br><span class="line">                - 1.从exporterMap(服务暴露时创建的)中获取对应的invoker对象</span><br><span class="line">                - 2.invoker.invoke()</span><br><span class="line">                    - 经过各个filter.invoke()</span><br><span class="line">                    - InvokerWrapper.invoke()</span><br><span class="line">                        - AbstractProxyInvoker.invoke()中</span><br><span class="line">                        - 1.doInvoke(methodName,paramType, arguments)</span><br><span class="line">                            - JavassistProxyFactory.doInvoke()</span><br><span class="line">                                - com.alibaba.dubbo.demo.provider.DemoServiceImpl.sayHello()</span><br><span class="line">                                    - DemoServiceImpl.sayHello()</span><br><span class="line">                        - 2.new RpcResult()上一步的返回结果包装成RpcResult返回,后续处理原路返回</span><br><span class="line">            - 2.channel.send(response)响应请求</span><br><span class="line">            - &#x2F;&#x2F; 参见 provider响应请求流程</span><br></pre></td></tr></table></figure>
<h2 id="provider请求响应流程"><a href="#provider请求响应流程" class="headerlink" title="provider请求响应流程"></a>provider请求响应流程</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- provider响应请求流程</span><br><span class="line">    - 各个filter的后续处理</span><br><span class="line">        - HeaderExchangeHandler.received()中处理请求时走handleRequest(),请求处理完后通过channel.send(response)响应</span><br><span class="line">            - AbstractPeer.send()</span><br><span class="line">                - netty4&#x2F;NettyChannel.send()</span><br><span class="line">                </span><br><span class="line">- 响应线程NettyServerWorker-3-1</span><br><span class="line">    - Thread.run()</span><br><span class="line">        - DefaultThreadFactory$DefaultRunnableDecorator.run()</span><br><span class="line">            - SingleThreadEventExecutor.run()</span><br><span class="line">                - NioEventLoop.run()</span><br><span class="line">                    - SingleThreadEventExecutor.runAllTasks()</span><br><span class="line">                    - &#x2F;&#x2F; ...</span><br><span class="line">                        - AbstractChannelHandlerContext$WriteAndFlushTask.write()</span><br><span class="line">                            - NettyServerHandler.write()</span><br><span class="line">                                - AbstractPeer.sent()</span><br><span class="line">                                    - AbstractChannelHandlerDelegate.sent()</span><br><span class="line">                                        - HeartbeatHandler.sent()设置最后的写时间</span><br><span class="line">                                            - WrappedChannelHandler.sent()</span><br><span class="line">                                                - AbstractChannelHandlerDelegate.sent()</span><br><span class="line">                                                    - HeaderExchangeHandler.sent()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo Cluster</title>
    <url>/2019/12/04/01no/dubbo/dubbo05-cluster/</url>
    <content><![CDATA[<h1 id="cluster"><a href="#cluster" class="headerlink" title="cluster"></a>cluster</h1><p>Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker,对上层透明,伪装过程包含了容错逻辑,调用失败后,重试另一个.</p>
<p>集群模块处于服务提供者和消费者之间,对于服务消费者来说,集群可向其屏蔽服务提供者集群的情况,使其能够专心进行远程调用.</p>
<p>cluster 继承结构<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Cluster(com.alibaba.dubbo.rpc.cluster)</span><br><span class="line">    MergeableCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    FailfastCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    MockClusterWrapper(com.alibaba.dubbo.rpc.cluster.support.wrapper)</span><br><span class="line">    FailsafeCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    ForkingCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    AvailableCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    FailbackCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    FailoverCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    BroadcastCluster(com.alibaba.dubbo.rpc.cluster.support)</span><br></pre></td></tr></table></figure></p>
<p>这些 Cluster 实现类里均实现了 join() 方法,用于创建其对应的 ClusterInvoker.</p>
<h1 id="Invoker接口"><a href="#Invoker接口" class="headerlink" title="Invoker接口"></a>Invoker接口</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Invoker(com.alibaba.dubbo.rpc)</span><br><span class="line">    ProviderInvokerWrapper(com.alibaba.dubbo.registry.support)</span><br><span class="line">    MockClusterInvoker(com.alibaba.dubbo.rpc.cluster.support.wrapper)</span><br><span class="line">    AbstractProxyInvoker(com.alibaba.dubbo.rpc.proxy)</span><br><span class="line">    ListenerInvokerWrapper(com.alibaba.dubbo.rpc.listener)</span><br><span class="line">    DelegateInvoker(com.alibaba.dubbo.rpc.support)</span><br><span class="line">    InvokerWrapper(com.alibaba.dubbo.rpc.protocol)</span><br><span class="line">    AbstractClusterInvoker(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    MergeableClusterInvoker(com.alibaba.dubbo.rpc.cluster.support)</span><br><span class="line">    AbstractInvoker(com.alibaba.dubbo.rpc.protocol)</span><br></pre></td></tr></table></figure>
<p>这些 Invoker实现类的父类 AbstractClusterInvoker.invoke() 中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(<span class="keyword">final</span> Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="comment">// 校验是否销毁</span></span><br><span class="line">    checkWhetherDestroyed();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过 directory 获得所有服务提供者 Invoker 集合</span></span><br><span class="line">    List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得 LoadBalance 对象</span></span><br><span class="line">    LoadBalance loadbalance;</span><br><span class="line">    <span class="keyword">if</span> (invokers != <span class="keyword">null</span> &amp;&amp; !invokers.isEmpty()) &#123;</span><br><span class="line">        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance<span class="class">.<span class="keyword">class</span>).<span class="title">getExtension</span>(<span class="title">invokers</span>.<span class="title">get</span>(0).<span class="title">getUrl</span>()</span></span><br><span class="line"><span class="class">                .<span class="title">getMethodParameter</span>(<span class="title">invocation</span>.<span class="title">getMethodName</span>(), <span class="title">Constants</span>.<span class="title">LOADBALANCE_KEY</span>, <span class="title">Constants</span>.<span class="title">DEFAULT_LOADBALANCE</span>))</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance<span class="class">.<span class="keyword">class</span>).<span class="title">getExtension</span>(<span class="title">Constants</span>.<span class="title">DEFAULT_LOADBALANCE</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置调用编号,若是异步调用</span></span><br><span class="line">    RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行调用</span></span><br><span class="line">    <span class="keyword">return</span> doInvoke(invocation, invokers, loadbalance);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="FailoverClusterInvoker"><a href="#FailoverClusterInvoker" class="headerlink" title="FailoverClusterInvoker"></a>FailoverClusterInvoker</h2><p>FailoverClusterInvoker 的 doInvoke() 方法首先是获取重试次数,然后根据重试次数进行循环调用,失败后进行重试.</p>
<p>在 for 循环内,首先是通过 loadBalance 选择一个 Invoker,然后再通过这个 Invoker.invoke() 方法进行远程调用.如果失败了,记录下异常,并进行重试.重试时会再次调用父类的 list() 方法列举 Invoker.</p>
<h2 id="FailbackClusterInvoker"><a href="#FailbackClusterInvoker" class="headerlink" title="FailbackClusterInvoker"></a>FailbackClusterInvoker</h2><p>FailbackClusterInvoker 会在调用失败后,返回一个空结果给服务消费者.</p>
<p>并通过定时任务对失败的调用进行重传,适合执行消息通知等操作.</p>
<p>doInvoke() 逻辑:<br>1.先检查 可用的 invoker 集合是否为空,若为空,则抛出异常.<br>2.调用select()通过loadbalance选择一个invoker,并发起rpc调用.<br>3.若调用失败,则添加到 failed 这个map中,并延迟初始化定时任务每隔5秒遍历一次 failed 里的 invoker,发起调用,若调用成功则从中移除.</p>
<h2 id="FailfastClusterInvoker"><a href="#FailfastClusterInvoker" class="headerlink" title="FailfastClusterInvoker"></a>FailfastClusterInvoker</h2><p>FailfastClusterInvoker 只会进行一次调用,失败后立即抛出异常.适用于幂等操作,比如新增记录.</p>
<p>doInvoke() 逻辑:<br>1.先检查 可用的 invoker 集合是否为空,若为空,则抛出异常.<br>2.调用select()通过loadbalance选择一个invoker,并发起rpc调用.<br>3.若调用失败,则先判断异常类型 若是 RpcException 或 业务异常,直接抛出.否则包装一层 RpcException 并抛出.</p>
<h2 id="FailsafeClusterInvoker"><a href="#FailsafeClusterInvoker" class="headerlink" title="FailsafeClusterInvoker"></a>FailsafeClusterInvoker</h2><p>FailsafeClusterInvoker 是一种失败安全的 Cluster Invoker.</p>
<p>所谓的失败安全是指,当调用过程中出现异常时,FailsafeClusterInvoker 仅会打印异常,而不会抛出异常.适用于写入审计日志等操作.</p>
<p>doInvoke() 逻辑:<br>没啥好说的,调用抛异常,捕获 Throwable 异常,打印异常日志,创建 RpcResult 对象返回.</p>
<h2 id="ForkingClusterInvoker"><a href="#ForkingClusterInvoker" class="headerlink" title="ForkingClusterInvoker"></a>ForkingClusterInvoker</h2><p>ForkingClusterInvoker 会在运行时通过线程池创建多个线程,并发调用多个服务提供者.</p>
<p>只要有一个服务提供者成功返回了结果,doInvoke 方法就会立即结束运行.</p>
<p>ForkingClusterInvoker 的应用场景是在一些对实时性要求比较高读操作(注意是读操作,并行写操作可能不安全)下使用,但这将会耗费更多的资源.</p>
<p>doInvoke() 逻辑:<br>1.先检查 可用的 invoker 集合是否为空,若为空,则抛出异常.<br>2.获取并发数 forks,调用 forks 次 select()方法获得 invokers 列表<br>3.遍历 invokers, 并发调用每个 invoker.invoke(),返回结果添加到 LinkedBlockingQueue 中<br>4.main线程阻塞在 ref.poll(timeout, TimeUnit.MILLISECONDS) 上等待第一个返回结果</p>
<h2 id="BroadcastClusterInvoker"><a href="#BroadcastClusterInvoker" class="headerlink" title="BroadcastClusterInvoker"></a>BroadcastClusterInvoker</h2><p>BroadcastClusterInvoker 会逐个调用每个服务提供者,如果其中一台报错,在循环调用结束后,BroadcastClusterInvoker 会抛出异常.</p>
<p>该类通常用于通知所有提供者更新缓存或日志等本地资源信息.<br>doInvoke() 逻辑:<br>没啥好说的,循环调用 invokers,调用失败记录 exception.最后有异常就抛出.</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html" target="_blank" rel="noopener">官网cluster部分</a></p>
<h1 id="directory"><a href="#directory" class="headerlink" title="directory"></a>directory</h1><p>主要看 RegistryDirectory 的实现.</p>
<h2 id="RegistryDirectory"><a href="#RegistryDirectory" class="headerlink" title="RegistryDirectory"></a>RegistryDirectory</h2><p>RegistryDirectory 实现了 NotifyListener 接口,当注册中心节点信息发生变化后,RegistryDirectory 可以通过此接口方法得到变更信息.</p>
<p>收到变更通知后,RegistryDirectory 可根据配置变更信息刷新 Invoker 列表.</p>
<p>RegistryDirectory 中有几个比较重要的逻辑:<br>1.Invoker.doList() 逻辑<br>2.接收服务配置变更的逻辑<br>3.Invoker 列表的刷新逻辑</p>
<p>doList()逻辑:<br>没啥好说的,就是从 methodInvokerMap(即 methodInvokerMap) 缓存中获取 methodName 对应的 invokers</p>
<p>接收服务变更通知<br>RegistryDirectory 是一个动态服务目录,会随注册中心配置的变化进行动态调整.因此 RegistryDirectory 实现了 NotifyListener 接口,通过这个接口获取注册中心变更通知.</p>
<p>1.ZookeeperRegistry.doSubscribe() 订阅时会创建一个 ChildListener,当发生 childChanged 事件时,会回调它的 childChanged() 方法<br>2.调用ZookeeperRegistry.this.notify(),由于 RegistryDirectory 实现了 NotifyListener 接口,会调用 RegistryDirectory.notify()<br>3.RegistryDirectory.notify() 调用 refreshInvoker(invokerUrls);<br>将 url 转成 Invoker,得到 <code>&lt;url, Invoker&gt;</code> 的映射关系.然后进一步进行转换,得到 <code>&lt;methodName, InvokerList&gt;</code> 映射关系.之后进行多组 Invoker 合并操作,并将合并结果赋值给 methodInvokerMap.methodInvokerMap 变量在 doList 方法中会被用到,doList 会对该变量进行读操作,在这里是写操作.当新的 Invoker 列表生成后,还要一个重要的工作要做,就是销毁无用的 Invoker,避免服务消费者调用已下线的服务的服务.</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/directory.html" target="_blank" rel="noopener">官网directory部分</a></p>
<h1 id="router"><a href="#router" class="headerlink" title="router"></a>router</h1><p>服务路由包含一条路由规则,路由规则决定了服务消费者的调用目标,即<code>规定了服务消费者可调用哪些服务提供者</code>.<br>比如条件路由 ConditionRouter</p>
<p>rule格式 [服务消费者匹配条件] =&gt; [服务提供者匹配条件],比如 rule = “host = 2.2.2.2,1.1.1.1,3.3.3.3 =&gt; host = 1.2.3.4”</p>
<p>ConditionRouter 构造方法里 先是对路由规则做预处理.处理结果存入 MatchPair.matches 和 MatchPair.mismatches,分别对应 匹配 和 不匹配的条件.最后 whenCondition 保存 消费者匹配条件,thenCondition 保存 提供者地址列表的过滤条件.</p>
<p>ConditionRouter.router(): 服务路由的逻辑.<br>1.调用 matchWhen 对服务消费者进行匹配,如果匹配失败,直接返回 Invoker 列表<br>2.如果匹配成功,再对服务提供者进行匹配</p>
<p>ConditionRouterTest</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/router.html" target="_blank" rel="noopener">官网router部分</a></p>
<h1 id="loadBalance"><a href="#loadBalance" class="headerlink" title="loadBalance"></a>loadBalance</h1><p><a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/loadbalance.html" target="_blank" rel="noopener">官网loadBalance部分</a><br>loadBalance 类的继承结构<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AbstractLoadBalance (com.alibaba.dubbo.rpc.cluster.loadbalance)</span><br><span class="line">    RoundRobinLoadBalance (com.alibaba.dubbo.rpc.cluster.loadbalance)</span><br><span class="line">    LeastActiveLoadBalance (com.alibaba.dubbo.rpc.cluster.loadbalance)</span><br><span class="line">    RandomLoadBalance (com.alibaba.dubbo.rpc.cluster.loadbalance)</span><br><span class="line">    ConsistentHashLoadBalance (com.alibaba.dubbo.rpc.cluster.loadbalance)</span><br></pre></td></tr></table></figure></p>
<h2 id="RandomLoadBalance"><a href="#RandomLoadBalance" class="headerlink" title="RandomLoadBalance"></a>RandomLoadBalance</h2><p>按权重设置随机概率.如果所有invoker权重都相等,则随机取一个.不相等,则按照权重的比例随机取.</p>
<h2 id="LeastActiveLoadBalance"><a href="#LeastActiveLoadBalance" class="headerlink" title="LeastActiveLoadBalance"></a>LeastActiveLoadBalance</h2><p>最小活跃数负载均衡。活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求。此时应优先将请求分配给该服务提供者。</p>
<p>初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求、这就是最小活跃数负载均衡算法的基本思想。</p>
<h2 id="ConsistentHashLoadBalance"><a href="#ConsistentHashLoadBalance" class="headerlink" title="ConsistentHashLoadBalance"></a>ConsistentHashLoadBalance</h2><p>一致性 Hash，相同参数的请求总是发到同一提供者。</p>
<p>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。</p>
<h2 id="RoundRobinLoadBalance"><a href="#RoundRobinLoadBalance" class="headerlink" title="RoundRobinLoadBalance"></a>RoundRobinLoadBalance</h2>]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>synchronized 和 lock 性能比较</title>
    <url>/2019/12/03/01no/concurrent/concurrent10-sync-vs-lock/</url>
    <content><![CDATA[<h1 id="synchronized-与-Lock-性能比较"><a href="#synchronized-与-Lock-性能比较" class="headerlink" title="synchronized 与 Lock 性能比较"></a>synchronized 与 Lock 性能比较</h1><h2 id="JDK1-8"><a href="#JDK1-8" class="headerlink" title="JDK1.8"></a>JDK1.8</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">D:\soft\Java\jdk1.8.0_172\bin\java.exe &quot;-javaagent:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\idea_rt.jar&#x3D;57167:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\bin&quot; -Dfile.encoding&#x3D;UTF-8 -classpath &quot;D:\soft\Java\jdk1.8.0_172\jre\lib\charsets.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\deploy.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\access-bridge-64.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\cldrdata.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\dnsns.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\jaccess.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\jfxrt.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\localedata.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\nashorn.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\sunec.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\sunjce_provider.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\sunmscapi.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\sunpkcs11.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\ext\zipfs.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\javaws.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\jce.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\jfr.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\jfxswt.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\jsse.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\management-agent.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\plugin.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\resources.jar;D:\soft\Java\jdk1.8.0_172\jre\lib\rt.jar;D:\myworkspace\03mygithub\MyThread\bin;D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\junit-4.12.jar;D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\hamcrest-core-1.3.jar&quot; com.zc.concurrent.issue.ReentrantLockVsSynchronizedTest</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1,每个线程循环 100000 次</span><br><span class="line">3789172(elapse), testLongAdder: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">6642633(elapse), testReentrantLockUnfair: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">6841152(elapse), testReentrantLockFair: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">8382098(elapse), testSynchronized: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">44980066(elapse), testAtomicInteger: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数2,每个线程循环 100000 次</span><br><span class="line">2647611(elapse), testLongAdder: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">3772457(elapse), testAtomicInteger: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">5013131(elapse), testSynchronized: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">5831547(elapse), testReentrantLockFair: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">9820412(elapse), testReentrantLockUnfair: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数4,每个线程循环 100000 次</span><br><span class="line">2838213(elapse), testSynchronized: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">3695923(elapse), testAtomicInteger: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">12967987(elapse), testLongAdder: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">13843291(elapse), testReentrantLockUnfair: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">1132170308(elapse), testReentrantLockFair: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数6,每个线程循环 100000 次</span><br><span class="line">2340008(elapse), testLongAdder: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">5598133(elapse), testSynchronized: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">11595358(elapse), testAtomicInteger: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">17305800(elapse), testReentrantLockUnfair: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">1706668497(elapse), testReentrantLockFair: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数8,每个线程循环 100000 次</span><br><span class="line">2604212(elapse), testLongAdder: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">7267222(elapse), testSynchronized: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">15585101(elapse), testAtomicInteger: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">20813467(elapse), testReentrantLockUnfair: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">2392860159(elapse), testReentrantLockFair: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数10,每个线程循环 100000 次</span><br><span class="line">6970763(elapse), testLongAdder: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">9930961(elapse), testSynchronized: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">20397367(elapse), testAtomicInteger: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">25850936(elapse), testReentrantLockUnfair: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">2794116491(elapse), testReentrantLockFair: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数50,每个线程循环 100000 次</span><br><span class="line">14844099(elapse), testLongAdder: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">47918859(elapse), testSynchronized: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">98661562(elapse), testAtomicInteger: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">126939598(elapse), testReentrantLockUnfair: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">14410074177(elapse), testReentrantLockFair: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数100,每个线程循环 100000 次</span><br><span class="line">29294384(elapse), testLongAdder: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">90143110(elapse), testSynchronized: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">193961488(elapse), testAtomicInteger: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">244101889(elapse), testReentrantLockUnfair: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">31166365222(elapse), testReentrantLockFair: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数200,每个线程循环 100000 次</span><br><span class="line">69702637(elapse), testLongAdder: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">170973104(elapse), testSynchronized: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">341206964(elapse), testAtomicInteger: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">489087584(elapse), testReentrantLockUnfair: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">63709112896(elapse), testReentrantLockFair: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100000 次</span><br><span class="line">133355267(elapse), testLongAdder: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">465237384(elapse), testSynchronized: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">982221507(elapse), testAtomicInteger: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">1246923387(elapse), testReentrantLockUnfair: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">163173197284(elapse), testReentrantLockFair: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10000 次</span><br><span class="line">46909254(elapse), testSynchronized: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">53434593(elapse), testLongAdder: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">76151149(elapse), testAtomicInteger: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">115951527(elapse), testReentrantLockUnfair: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">16067416290(elapse), testReentrantLockFair: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1000 次</span><br><span class="line">21785245(elapse), testLongAdder: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">22926219(elapse), testSynchronized: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">23726455(elapse), testAtomicInteger: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">23893305(elapse), testReentrantLockUnfair: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">1583798403(elapse), testReentrantLockFair: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100 次</span><br><span class="line">21886704(elapse), testSynchronized: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">22070561(elapse), testReentrantLockUnfair: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">22847925(elapse), testLongAdder: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">24225539(elapse), testAtomicInteger: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">133848487(elapse), testReentrantLockFair: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10 次</span><br><span class="line">20742504(elapse), testSynchronized: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">21348326(elapse), testLongAdder: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">21286160(elapse), testReentrantLockUnfair: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">21943591(elapse), testAtomicInteger: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">22087863(elapse), testReentrantLockFair: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1 次</span><br><span class="line">20936918(elapse), testReentrantLockUnfair: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">21259769(elapse), testAtomicInteger: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">21328093(elapse), testLongAdder: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">22007810(elapse), testSynchronized: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">23318273(elapse), testReentrantLockFair: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1000,每个线程循环 1 次</span><br><span class="line">53460398(elapse), testLongAdder: result&#x3D;1500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">58974079(elapse), testAtomicInteger: result&#x3D;1500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">82545706(elapse), testSynchronized: result&#x3D;1500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">130621152(elapse), testReentrantLockFair: result&#x3D;1500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">200410000(elapse), testReentrantLockUnfair: result&#x3D;1500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1500,每个线程循环 1 次</span><br><span class="line">84837038(elapse), testSynchronized: result&#x3D;3000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">104347079(elapse), testAtomicInteger: result&#x3D;3000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">109697722(elapse), testReentrantLockUnfair: result&#x3D;3000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">138776874(elapse), testReentrantLockFair: result&#x3D;3000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">212777150(elapse), testLongAdder: result&#x3D;3000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>从上面的测试数据能看出来,在JDK1.8下<code>synchronized 比 ReentrantLock 性能要好很多</code>,从上面数据来看正常能快个3~5倍这样.</p>
<p>ReentrantLock 公平模式性能很差,并发竞争大的情况下,从数据看 正常比 非公平模式能慢两个数量级.</p>
<p>AtomicInteger 和 LongAdder 在这种场景下性能还是比 ReentrantLock 要好一些的.</p>
<h2 id="JDK1-7"><a href="#JDK1-7" class="headerlink" title="JDK1.7"></a>JDK1.7</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">D:\soft\Java\JDK1.7\bin\java.exe &quot;-javaagent:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\idea_rt.jar&#x3D;60620:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\bin&quot; -Dfile.encoding&#x3D;UTF-8 -classpath D:\soft\Java\JDK1.7\jre\lib\charsets.jar;D:\soft\Java\JDK1.7\jre\lib\deploy.jar;D:\soft\Java\JDK1.7\jre\lib\ext\access-bridge-64.jar;D:\soft\Java\JDK1.7\jre\lib\ext\dnsns.jar;D:\soft\Java\JDK1.7\jre\lib\ext\jaccess.jar;D:\soft\Java\JDK1.7\jre\lib\ext\localedata.jar;D:\soft\Java\JDK1.7\jre\lib\ext\sunec.jar;D:\soft\Java\JDK1.7\jre\lib\ext\sunjce_provider.jar;D:\soft\Java\JDK1.7\jre\lib\ext\sunmscapi.jar;D:\soft\Java\JDK1.7\jre\lib\ext\zipfs.jar;D:\soft\Java\JDK1.7\jre\lib\javaws.jar;D:\soft\Java\JDK1.7\jre\lib\jce.jar;D:\soft\Java\JDK1.7\jre\lib\jfr.jar;D:\soft\Java\JDK1.7\jre\lib\jfxrt.jar;D:\soft\Java\JDK1.7\jre\lib\jsse.jar;D:\soft\Java\JDK1.7\jre\lib\management-agent.jar;D:\soft\Java\JDK1.7\jre\lib\plugin.jar;D:\soft\Java\JDK1.7\jre\lib\resources.jar;D:\soft\Java\JDK1.7\jre\lib\rt.jar;D:\myworkspace\02localdemo\T03TomLoader\target\classes com.zc.test.ReentrantLockVsSynchronizedTest</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1,每个线程循环 100000 次</span><br><span class="line">22840888(elapse), testSynchronized: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">26080245(elapse), testAtomicInteger: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">8243398(elapse), testReentrantLockUnfair: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数2,每个线程循环 100000 次</span><br><span class="line">5484065(elapse), testSynchronized: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">5490809(elapse), testAtomicInteger: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">11825254(elapse), testReentrantLockUnfair: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数4,每个线程循环 100000 次</span><br><span class="line">11477771(elapse), testSynchronized: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">15624982(elapse), testReentrantLockUnfair: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">29080910(elapse), testAtomicInteger: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数6,每个线程循环 100000 次</span><br><span class="line">15473673(elapse), testSynchronized: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">32343434(elapse), testAtomicInteger: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">35170504(elapse), testReentrantLockUnfair: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数8,每个线程循环 100000 次</span><br><span class="line">18780768(elapse), testSynchronized: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">19249649(elapse), testReentrantLockUnfair: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">51532676(elapse), testAtomicInteger: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数10,每个线程循环 100000 次</span><br><span class="line">22142404(elapse), testReentrantLockUnfair: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">28116170(elapse), testSynchronized: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">46799583(elapse), testAtomicInteger: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数50,每个线程循环 100000 次</span><br><span class="line">154866338(elapse), testReentrantLockUnfair: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">164094417(elapse), testSynchronized: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">190372008(elapse), testAtomicInteger: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数100,每个线程循环 100000 次</span><br><span class="line">320082668(elapse), testSynchronized: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">399773154(elapse), testAtomicInteger: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">669262375(elapse), testReentrantLockUnfair: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数200,每个线程循环 100000 次</span><br><span class="line">557621097(elapse), testReentrantLockUnfair: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">650982745(elapse), testSynchronized: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">1287148955(elapse), testAtomicInteger: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100000 次</span><br><span class="line">1319411162(elapse), testReentrantLockUnfair: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">1496867673(elapse), testSynchronized: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">2878890484(elapse), testAtomicInteger: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10000 次</span><br><span class="line">134509730(elapse), testReentrantLockUnfair: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">170702742(elapse), testSynchronized: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">250160106(elapse), testAtomicInteger: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1000 次</span><br><span class="line">27824108(elapse), testReentrantLockUnfair: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">40523787(elapse), testSynchronized: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">40963344(elapse), testAtomicInteger: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100 次</span><br><span class="line">24163960(elapse), testSynchronized: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">24996452(elapse), testAtomicInteger: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">35085760(elapse), testReentrantLockUnfair: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10 次</span><br><span class="line">40494463(elapse), testReentrantLockUnfair: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">51199269(elapse), testSynchronized: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">52468973(elapse), testAtomicInteger: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1 次</span><br><span class="line">44156664(elapse), testAtomicInteger: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">46565583(elapse), testSynchronized: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">144862068(elapse), testReentrantLockUnfair: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1000,每个线程循环 1 次</span><br><span class="line">111706963(elapse), testReentrantLockUnfair: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">156553607(elapse), testAtomicInteger: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">182228017(elapse), testSynchronized: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1500,每个线程循环 1 次</span><br><span class="line">176627244(elapse), testSynchronized: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">202298721(elapse), testAtomicInteger: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">69693840(elapse), testReentrantLockUnfair: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>从数据上看,正常情况下还是 synchronized 稍微快一点的.有比 ReentrantLock(非公平)慢的时候,最多也就慢一倍这样.</p>
<h2 id="JDK1-6"><a href="#JDK1-6" class="headerlink" title="JDK1.6"></a>JDK1.6</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">D:\soft\Java\jdk1.6.0_45\bin\java.exe &quot;-javaagent:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\idea_rt.jar&#x3D;61893:D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\bin&quot; -Dfile.encoding&#x3D;UTF-8 -classpath D:\soft\Java\jdk1.6.0_45\jre\lib\charsets.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\deploy.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\ext\dnsns.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\ext\localedata.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\ext\sunjce_provider.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\ext\sunmscapi.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\javaws.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\jce.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\jsse.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\management-agent.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\plugin.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\resources.jar;D:\soft\Java\jdk1.6.0_45\jre\lib\rt.jar;D:\myworkspace\02localdemo\T03TomLoader\target\classes com.zc.test.ReentrantLockVsSynchronizedTest</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1,每个线程循环 100000 次</span><br><span class="line">4767108(elapse), testAtomicInteger: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">5231298(elapse), testSynchronized: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">11269281(elapse), testReentrantLockUnfair: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数2,每个线程循环 100000 次</span><br><span class="line">2265820(elapse), testAtomicInteger: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">5181154(elapse), testSynchronized: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">9388771(elapse), testReentrantLockUnfair: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数4,每个线程循环 100000 次</span><br><span class="line">10028901(elapse), testSynchronized: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">28028493(elapse), testAtomicInteger: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">9190838(elapse), testReentrantLockUnfair: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数6,每个线程循环 100000 次</span><br><span class="line">15937569(elapse), testReentrantLockUnfair: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">17108746(elapse), testSynchronized: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">21985524(elapse), testAtomicInteger: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数8,每个线程循环 100000 次</span><br><span class="line">20291510(elapse), testReentrantLockUnfair: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">20961550(elapse), testSynchronized: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">36662479(elapse), testAtomicInteger: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数10,每个线程循环 100000 次</span><br><span class="line">21589658(elapse), testAtomicInteger: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">23756071(elapse), testReentrantLockUnfair: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">27164038(elapse), testSynchronized: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数50,每个线程循环 100000 次</span><br><span class="line">126872447(elapse), testReentrantLockUnfair: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">149717147(elapse), testSynchronized: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">296352695(elapse), testAtomicInteger: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数100,每个线程循环 100000 次</span><br><span class="line">240213603(elapse), testSynchronized: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">246687627(elapse), testReentrantLockUnfair: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">324364767(elapse), testAtomicInteger: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数200,每个线程循环 100000 次</span><br><span class="line">522835023(elapse), testReentrantLockUnfair: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">749915548(elapse), testSynchronized: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">1348022018(elapse), testAtomicInteger: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100000 次</span><br><span class="line">1252515069(elapse), testReentrantLockUnfair: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">1796960863(elapse), testSynchronized: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">3533896401(elapse), testAtomicInteger: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10000 次</span><br><span class="line">120825372(elapse), testReentrantLockUnfair: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">173094359(elapse), testSynchronized: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">327061935(elapse), testAtomicInteger: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1000 次</span><br><span class="line">25813109(elapse), testReentrantLockUnfair: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">26570239(elapse), testSynchronized: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">28246953(elapse), testAtomicInteger: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100 次</span><br><span class="line">25892576(elapse), testReentrantLockUnfair: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">26211908(elapse), testAtomicInteger: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">32821991(elapse), testSynchronized: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10 次</span><br><span class="line">24638120(elapse), testAtomicInteger: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">28614668(elapse), testSynchronized: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">28632262(elapse), testReentrantLockUnfair: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1 次</span><br><span class="line">28014418(elapse), testAtomicInteger: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">30410727(elapse), testSynchronized: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">37675310(elapse), testReentrantLockUnfair: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1000,每个线程循环 1 次</span><br><span class="line">49730166(elapse), testAtomicInteger: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">54536567(elapse), testSynchronized: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">55911835(elapse), testReentrantLockUnfair: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1500,每个线程循环 1 次</span><br><span class="line">77436982(elapse), testReentrantLockUnfair: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">80245284(elapse), testSynchronized: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">82252179(elapse), testAtomicInteger: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>从上面数据看,线程数大于等于6后 ReentrantLockUnfair 快于 synchronized,线程数小的时候 synchronized 快一些.</p>
<h2 id="JDK11"><a href="#JDK11" class="headerlink" title="JDK11"></a>JDK11</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">D:\soft\Java\jdk-11.0.4\bin\java.exe -Didea.launcher.port&#x3D;62514 &quot;-Didea.launcher.bin.path&#x3D;D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\bin&quot; -Dfile.encoding&#x3D;UTF-8 -classpath &quot;D:\myworkspace\02localdemo\T03TomLoader\target\classes;D:\soft\JetBrains\IntelliJ IDEA 2018.1.6\lib\idea_rt.jar&quot; com.intellij.rt.execution.application.AppMainV2 com.zc.test.ReentrantLockVsSynchronizedTest</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1,每个线程循环 100000 次</span><br><span class="line">4207617(elapse), testAtomicInteger: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">7003311(elapse), testSynchronized: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">12754512(elapse), testReentrantLockUnfair: result&#x3D;100000, threadCount&#x3D;1, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数2,每个线程循环 100000 次</span><br><span class="line">4266557(elapse), testAtomicInteger: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">6544986(elapse), testSynchronized: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">10791310(elapse), testReentrantLockUnfair: result&#x3D;300000, threadCount&#x3D;2, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数4,每个线程循环 100000 次</span><br><span class="line">7923773(elapse), testAtomicInteger: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">9049499(elapse), testReentrantLockUnfair: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">10100450(elapse), testSynchronized: result&#x3D;700000, threadCount&#x3D;4, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数6,每个线程循环 100000 次</span><br><span class="line">13618380(elapse), testAtomicInteger: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">14245901(elapse), testReentrantLockUnfair: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">15905607(elapse), testSynchronized: result&#x3D;1300000, threadCount&#x3D;6, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数8,每个线程循环 100000 次</span><br><span class="line">14097525(elapse), testAtomicInteger: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">14484007(elapse), testSynchronized: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">20932226(elapse), testReentrantLockUnfair: result&#x3D;2100000, threadCount&#x3D;8, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数10,每个线程循环 100000 次</span><br><span class="line">9905157(elapse), testAtomicInteger: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">28208539(elapse), testSynchronized: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">40982698(elapse), testReentrantLockUnfair: result&#x3D;3100000, threadCount&#x3D;10, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数50,每个线程循环 100000 次</span><br><span class="line">67569652(elapse), testAtomicInteger: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">119220208(elapse), testReentrantLockUnfair: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">127837187(elapse), testSynchronized: result&#x3D;8100000, threadCount&#x3D;50, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数100,每个线程循环 100000 次</span><br><span class="line">155161331(elapse), testAtomicInteger: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">214199043(elapse), testSynchronized: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">271890809(elapse), testReentrantLockUnfair: result&#x3D;18100000, threadCount&#x3D;100, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数200,每个线程循环 100000 次</span><br><span class="line">346384305(elapse), testAtomicInteger: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">465400423(elapse), testReentrantLockUnfair: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">658154372(elapse), testSynchronized: result&#x3D;38100000, threadCount&#x3D;200, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100000 次</span><br><span class="line">930565965(elapse), testAtomicInteger: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">1305456443(elapse), testReentrantLockUnfair: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">1745141403(elapse), testSynchronized: result&#x3D;88100000, threadCount&#x3D;500, loopCount&#x3D;100000</span><br><span class="line">-------------------------------------</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10000 次</span><br><span class="line">88273743(elapse), testAtomicInteger: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">132994002(elapse), testReentrantLockUnfair: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">165907776(elapse), testSynchronized: result&#x3D;93100000, threadCount&#x3D;500, loopCount&#x3D;10000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1000 次</span><br><span class="line">32739299(elapse), testAtomicInteger: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">34829766(elapse), testSynchronized: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">37466527(elapse), testReentrantLockUnfair: result&#x3D;93600000, threadCount&#x3D;500, loopCount&#x3D;1000</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 100 次</span><br><span class="line">34564096(elapse), testReentrantLockUnfair: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">35123587(elapse), testAtomicInteger: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">40711163(elapse), testSynchronized: result&#x3D;93650000, threadCount&#x3D;500, loopCount&#x3D;100</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 10 次</span><br><span class="line">33697882(elapse), testAtomicInteger: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">34600750(elapse), testSynchronized: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">36510584(elapse), testReentrantLockUnfair: result&#x3D;93655000, threadCount&#x3D;500, loopCount&#x3D;10</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数500,每个线程循环 1 次</span><br><span class="line">35484557(elapse), testAtomicInteger: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">35623551(elapse), testReentrantLockUnfair: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">36133778(elapse), testSynchronized: result&#x3D;93655500, threadCount&#x3D;500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1000,每个线程循环 1 次</span><br><span class="line">66762085(elapse), testAtomicInteger: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">67941473(elapse), testReentrantLockUnfair: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">74041623(elapse), testSynchronized: result&#x3D;93656500, threadCount&#x3D;1000, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line">&#x2F;&#x2F; 线程数1500,每个线程循环 1 次</span><br><span class="line">98764781(elapse), testReentrantLockUnfair: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">100622126(elapse), testSynchronized: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">102833697(elapse), testAtomicInteger: result&#x3D;93658000, threadCount&#x3D;1500, loopCount&#x3D;1</span><br><span class="line">-------------------------------------</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>线程数少的时候还是 synchronized 快,线程数多的时候二者基本持平.</p>
<h2 id="测试使用的代码"><a href="#测试使用的代码" class="headerlink" title="测试使用的代码"></a>测试使用的代码</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zc.concurrent.issue;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"><span class="comment">// import java.util.concurrent.atomic.LongAdder;</span></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.LongAdder;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReentrantLockVsSynchronizedTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AtomicInteger a = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// JDK8 才有</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> LongAdder b = <span class="keyword">new</span> LongAdder();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> c = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> d = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> e = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ReentrantLock fairLock = <span class="keyword">new</span> ReentrantLock(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ReentrantLock unfairLock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">1</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">2</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">4</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">6</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">8</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">10</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">50</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">100</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">200</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">100000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">10000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">100</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">500</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">1000</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">        testAll(<span class="number">1500</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"-------------------------------------"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testAll</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        testAtomicInteger(threadCount, loopCount);</span><br><span class="line"></span><br><span class="line">        testLongAdder(threadCount, loopCount);</span><br><span class="line"></span><br><span class="line">        testSynchronized(threadCount, loopCount);</span><br><span class="line"></span><br><span class="line">        testReentrantLockUnfair(threadCount, loopCount);</span><br><span class="line"></span><br><span class="line">        testReentrantLockFair(threadCount, loopCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testAtomicInteger</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line"></span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(threadCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadCount; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; loopCount; j++) &#123;</span><br><span class="line">                    a.incrementAndGet();</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println((System.nanoTime() - start) + <span class="string">"(elapse), "</span> + <span class="string">"testAtomicInteger: result="</span> + a.get() + <span class="string">", threadCount="</span> + threadCount + <span class="string">", loopCount="</span> + loopCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testLongAdder</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line"></span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(threadCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadCount; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; loopCount; j++) &#123;</span><br><span class="line">                    b.increment();</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println((System.nanoTime() - start) + <span class="string">"(elapse), "</span> + <span class="string">"testLongAdder: result="</span> + b.sum() + <span class="string">", threadCount="</span> + threadCount + <span class="string">", loopCount="</span> + loopCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testReentrantLockFair</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line"></span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(threadCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadCount; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; loopCount; j++) &#123;</span><br><span class="line">                    fairLock.lock();</span><br><span class="line">                    c++;</span><br><span class="line">                    fairLock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println((System.nanoTime() - start) + <span class="string">"(elapse), "</span> + <span class="string">"testReentrantLockFair: result="</span> + c + <span class="string">", threadCount="</span> + threadCount + <span class="string">", loopCount="</span> + loopCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testReentrantLockUnfair</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line"></span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(threadCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadCount; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; loopCount; j++) &#123;</span><br><span class="line">                    unfairLock.lock();</span><br><span class="line">                    d++;</span><br><span class="line">                    unfairLock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println((System.nanoTime() - start) + <span class="string">"(elapse), "</span> + <span class="string">"testReentrantLockUnfair: result="</span> + d + <span class="string">", threadCount="</span> + threadCount + <span class="string">", loopCount="</span> + loopCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testSynchronized</span><span class="params">(<span class="keyword">int</span> threadCount, <span class="keyword">int</span> loopCount)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line"></span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(threadCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadCount; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; loopCount; j++) &#123;</span><br><span class="line">                    <span class="keyword">synchronized</span> (ReentrantLockVsSynchronizedTest<span class="class">.<span class="keyword">class</span>) </span>&#123;</span><br><span class="line">                        e++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println((System.nanoTime() - start) + <span class="string">"(elapse), "</span> + <span class="string">"testSynchronized: result="</span> + e + <span class="string">", threadCount="</span> + threadCount + <span class="string">", loopCount="</span> + loopCount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo 服务暴露</title>
    <url>/2019/11/29/01no/dubbo/dubbo03-export/</url>
    <content><![CDATA[<h1 id="Dubbo-与-Spring-的结合"><a href="#Dubbo-与-Spring-的结合" class="headerlink" title="Dubbo 与 Spring 的结合"></a>Dubbo 与 Spring 的结合</h1><p>代码在 dubbo-config 下的 dubbo-config-spring 模块中</p>
<p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/dubbo/Dubbo-Config类图.png" alt="Dubbo Config整体类图"></p>
<h2 id="META-INF-dubbo-xsd"><a href="#META-INF-dubbo-xsd" class="headerlink" title="META-INF/dubbo.xsd"></a>META-INF/dubbo.xsd</h2><p>dubbo.xsd 定义了 dubbo 自定义标签</p>
<h2 id="META-INF-spring-schemas"><a href="#META-INF-spring-schemas" class="headerlink" title="META-INF/spring.schemas"></a>META-INF/spring.schemas</h2><p>spring.schemas 指定了 dubbo.xsd 文件的位置.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http\:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&#x3D;META-INF&#x2F;dubbo.xsd</span><br></pre></td></tr></table></figure></p>
<h2 id="META-INF-spring-handlers"><a href="#META-INF-spring-handlers" class="headerlink" title="META-INF/spring.handlers"></a>META-INF/spring.handlers</h2><p>关联 DubboNamespaceHandler 命名空间处理器和 dubbo.xsd 中的 targetNamespace,即 <code>http://code.alibabatech.com/schema/dubbo</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http\:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x3D;com.alibaba.dubbo.config.spring.schema.DubboNamespaceHand</span><br></pre></td></tr></table></figure></p>
<h2 id="DubboNamespaceHandler-init"><a href="#DubboNamespaceHandler-init" class="headerlink" title="DubboNamespaceHandler.init()"></a>DubboNamespaceHandler.init()</h2><p>DubboNamespaceHandler.init(): 注册各个自定义元素的解析器,所有元素都是交给 DubboBeanDefinitionParser 处理的,传入不同的 Class 对象<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; <span class="comment">// 注册BeanDefinitionParser用来解析dubbo定义的那些xml元素节点</span></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"application"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ApplicationConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;<span class="comment">// &lt;dubbo:application name="dubbo-admin" /&gt;</span></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"module"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ModuleConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;<span class="comment">// &lt;dubbo:registry address="$&#123;dubbo.registry.address&#125;" check="false" file="false" /&gt;</span></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"registry"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(RegistryConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;<span class="comment">// &lt;dubbo:reference id="registryService" interface="com.alibaba.dubbo.registry.RegistryService" check="false" /&gt;</span></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"monitor"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(MonitorConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;</span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"provider"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ProviderConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;</span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"consumer"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ConsumerConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;</span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"protocol"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ProtocolConfig<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;</span><br><span class="line">    <span class="comment">//  &lt;dubbo:service  interface="com.alibaba.dubbo.demo.DemoService" group="g1" ref="demoService" filter="demo" deprecated="false" callbacks="1000" timeout="200000" accesslog="true"&gt; 解析成 ServiceBean</span></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"service"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ServiceBean<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>))</span>;</span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"reference"</span>, <span class="keyword">new</span> DubboBeanDefinitionParser(ReferenceBean<span class="class">.<span class="keyword">class</span>, <span class="title">false</span>))</span>;</span><br><span class="line"></span><br><span class="line">    registerBeanDefinitionParser(<span class="string">"annotation"</span>, <span class="keyword">new</span> AnnotationBeanDefinitionParser()); <span class="comment">// 废弃</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="DubboBeanDefinitionParser"><a href="#DubboBeanDefinitionParser" class="headerlink" title="DubboBeanDefinitionParser"></a>DubboBeanDefinitionParser</h2><p>DubboBeanDefinitionParser.parse()中<br>根据 beanClass 创建 RootBeanDefinition,设置为非懒加载.<br>若未配置 id 属性,则会根据 name 或 interface 属性生成,并通过判断 BeanRegistry 中是否存在该 id 的 bean,用 则增序列解决重复问题.<br>通过id注册到BeanRegistry中,并设置 beanDefinition 的 id 属性.<br>下面就是对 ServiceBean 等元素的各自的属性配置的处理.</p>
<p>在Spring应用上下文启动过程中,加载XML配置文件(比如提供者配置和消费者配置文件)为 Resource 对象,并通过 XmlBeanDefinitionReader 调用BeanDefinitionParser 解析 XML 标签为 BeanDefinition,并注册到 BeanDefinitionRegistry 中.</p>
<h1 id="ServiceBean"><a href="#ServiceBean" class="headerlink" title="ServiceBean"></a>ServiceBean</h1><p>ServiceBean 实现了 InitializingBean, DisposableBean, ApplicationContextAware, <code>ApplicationListener&lt;ContextRefreshedEvent&gt;</code>, BeanNameAware 这几个接口.</p>
<ol>
<li><p>实现的 ApplicationContextAware 接口的 setApplicationContext() 方法中,会:<br>保存 applicationContext 引用.<br>applicationContext 引用 保存到 SpringExtensionFactory 中.</p>
</li>
<li><p>实现的 InitializingBean 接口的 afterPropertiesSet() 方法中,会: 设置相关属性.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- ServiceBean.afterPropertiesSet()</span><br><span class="line">    - 从BeanFactory中获取ProviderConfig,ProtocolConfig等,这些bean是之前在Spring bean解析时加载进来的.将这些配置对象赋值到ServiceBean中,当然也有可能在其父类中.</span><br></pre></td></tr></table></figure>
</li>
<li><p>实现的 <code>ApplicationListener&lt;ContextRefreshedEvent&gt;</code> 接口的 onApplicationEvent(ContextRefreshedEvent event) 方法中,有服务暴露的相关逻辑.</p>
</li>
</ol>
<h2 id="服务本地暴露"><a href="#服务本地暴露" class="headerlink" title="服务本地暴露"></a>服务本地暴露</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ServiceBean.onApplicationEvent()</span><br><span class="line">    监听spring容器初始化完成时触发</span><br><span class="line">    - ServiceConfig.doExport()根据配置选择立即暴露或延迟暴露</span><br><span class="line">        - 暴露服务doExportUrls()</span><br><span class="line">            - loadRegistries(true)加载注册中心 URL 数组</span><br><span class="line">                - 将xml中配置的&lt;dubbo:registry&gt;解析成url对象(如registry:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService?application&#x3D;demo-provider&amp;dubbo&#x3D;2.0.0&amp;logger&#x3D;jcl&amp;pid&#x3D;52008&amp;qos.port&#x3D;22222&amp;registry&#x3D;zookeeper&amp;timestamp&#x3D;1574666370052)</span><br><span class="line">            - doExportUrlsFor1Protocol(protocolConfig, registryURLs)根据不同的协议把服务export到不同的注册中心(如zk)上去</span><br><span class="line">                - ServiceConfig.exportLocal()中:服务本地暴露</span><br><span class="line">                    - 1.通过传入的协议url构造本地injvm协议的url</span><br><span class="line">                    - 2.通过proxyFactory.getInvoker()获取Invoker</span><br><span class="line">                        - ProxyFactory$Adaptive.getInvoker()方法</span><br><span class="line">                        - 1.ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(&quot;javassist&quot;)获取StubProxyFactoryWrapper 对象</span><br><span class="line">                        - 2.extension.getInvoker(arg0, arg1, arg2)通过ProxyFactory获取Invoker对象</span><br><span class="line">                            - StubProxyFactoryWrapper.getInvoker()直接调用内部的JavassistProxyFactory.getInvoker()</span><br><span class="line">                                - JavassistProxyFactory.getInvoker()方法中</span><br><span class="line">                                - 1.根据proxy对象创建Wrapper</span><br><span class="line">                                - 2.根据proxy, type, url创建AbstractProxyInvoker对象,它的doInvoke()方法会调用wrapper类的invokeMethod()方法</span><br><span class="line">                    - 3.protocol.export()将Invoker转为Exporter</span><br><span class="line">                        - Protocol$Adaptive.export()生成的代理类</span><br><span class="line">                            - 1.通过ExtensionLoader获取name为injvm的Protocol拓展对象.吐出的是ProtocolListenerWrapper的实例,包裹了InjvmProtocol</span><br><span class="line">                            - 2.extension.export(invoker)</span><br><span class="line">                                - ProtocolFilterWrapper.export()中</span><br><span class="line">                                    - 1.buildInvokerChain()建立带有 Filter 过滤链的 Invoker,再暴露服务</span><br><span class="line">                                    - 2.protocol.export()</span><br><span class="line">                                        - ProtocolListenerWrapper.export()中</span><br><span class="line">                                        - 1.通过InjvmProtocol.export()把invoker暴露为exporter</span><br><span class="line">                                            - InjvmProtocol.export()中</span><br><span class="line">                                            - 1.创建InjvmExporter对象</span><br><span class="line">                                        - 2.获取ExporterListener拓展对象列表</span><br><span class="line">                                        - 3.创建ListenerExporterWrapper对象作为exporter返回</span><br></pre></td></tr></table></figure>
<p>ServiceConfig.exportLocal()中:服务本地暴露<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">exportLocal</span><span class="params">(URL url)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; <span class="comment">// 协议不以injvm开头</span></span><br><span class="line">        <span class="comment">// 1.创建本地 injvm URL</span></span><br><span class="line">        URL local = URL.valueOf(url.toFullString())</span><br><span class="line">                .setProtocol(Constants.LOCAL_PROTOCOL) <span class="comment">// injvm</span></span><br><span class="line">                .setHost(LOCALHOST) <span class="comment">// 本地</span></span><br><span class="line">                .setPort(<span class="number">0</span>); <span class="comment">// 端口=0</span></span><br><span class="line">        ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref));</span><br><span class="line">        <span class="comment">// 2.使用 ProxyFactory 创建 Invoker 对象</span></span><br><span class="line">        <span class="comment">// 3.使用 Protocol 暴露 Invoker 对象,将 Invoker 转成 exporter</span></span><br><span class="line">        Exporter&lt;?&gt; exporter = protocol.export(proxyFactory.getInvoker(ref, (Class) interfaceClass, local));</span><br><span class="line">        <span class="comment">// 添加到 `exporters`</span></span><br><span class="line">        exporters.add(exporter);</span><br><span class="line">        logger.info(<span class="string">"Export dubbo service "</span> + interfaceClass.getName() + <span class="string">" to local registry"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这个 proxyFactory 是 ProxyFactory$Adaptive 对象,会根据传入的参数创建具体的 proxyFactory 对象.<br>proxyFactory.getInvoker(ref, (Class) interfaceClass, local)传入的参数分别是 服务具体实现类对象ref,服务接口DemoService,本地暴露的URL对象</p>
<p>ProxyFactory$Adaptive.getInvoker()方法<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> com.alibaba.dubbo.rpc.<span class="function">Invoker <span class="title">getInvoker</span><span class="params">(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2)</span> <span class="keyword">throws</span> com.alibaba.dubbo.rpc.RpcException </span>&#123;<span class="comment">// 获取Invoker.参数 arg0 为 ref 对象, arg1 为 服务接口(如 DemoService), args 为 服务暴露的 URL</span></span><br><span class="line">    <span class="keyword">if</span> (arg2 == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"url == null"</span>);</span><br><span class="line">    com.alibaba.dubbo.common.URL url = arg2;</span><br><span class="line">    String extName = url.getParameter(<span class="string">"proxy"</span>, <span class="string">"javassist"</span>);<span class="comment">// 从url参数中获取 ProxyFactory 拓展使用的方式,默认是javassist</span></span><br><span class="line">    <span class="keyword">if</span>(extName == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url("</span> + url.toString() + <span class="string">") use keys([proxy])"</span>);</span><br><span class="line">    com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory<span class="class">.<span class="keyword">class</span>).<span class="title">getExtension</span>(<span class="title">extName</span>)</span>; <span class="comment">// 获取 ProxyFactory 接口 的拓展实现(默认使用的实现类为 JavassistProxyFactory)</span></span><br><span class="line">    <span class="keyword">return</span> extension.getInvoker(arg0, arg1, arg2);<span class="comment">// extension为StubProxyFactoryWrapper实例,包裹了JavassistProxyFactory对象</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>通过 <code>ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(&quot;javassist&quot;)</code> 获取的是 JavassistProxyFactory 对象,同时 ProxyFactory 有个 Wrapper 实现类 StubProxyFactoryWrapper,会被 SPI AOP 包装到 JavassistProxyFactory 对象 外层,所以最后吐出的是 StubProxyFactoryWrapper 对象.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Invoker&lt;T&gt; <span class="title">getInvoker</span><span class="params">(T proxy, Class&lt;T&gt; type, URL url)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1.根据传入的 proxy 对象的类信息创建对它的包装对象 Wrapper</span></span><br><span class="line">    <span class="keyword">final</span> Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(<span class="string">'$'</span>) &lt; <span class="number">0</span> ? proxy.getClass() : type);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123;<span class="comment">// 2.返回Invoker对象实例,这个invoker对象invoke()方法可以根据传入的invocation对象中包含的方法名,方法参数来调用proxy对象 返回调用结果</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> Object <span class="title">doInvoke</span><span class="params">(T proxy, String methodName,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    Class&lt;?&gt;[] parameterTypes,</span></span></span><br><span class="line"><span class="function"><span class="params">                                    Object[] arguments)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Invoker -&gt; Exporter</p>
<p>ProtocolFilterWrapper.export()方法中<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="comment">// 注册中心</span></span><br><span class="line">    <span class="keyword">if</span> (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123;</span><br><span class="line">        <span class="keyword">return</span> protocol.export(invoker); <span class="comment">// 向注册中心发布服务的时候并不会组装 filter 调用链</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 建立带有 Filter 过滤链的 Invoker,再暴露服务</span></span><br><span class="line">    <span class="keyword">return</span> protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建带 Filter 链的 Invoker 对象</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> invoker Invoker 对象</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> key 获取 URL 参数名</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> group 分组</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> &lt;T&gt; 泛型</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> Invoker 对象</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">Invoker&lt;T&gt; <span class="title">buildInvokerChain</span><span class="params">(<span class="keyword">final</span> Invoker&lt;T&gt; invoker, String key, String group)</span> </span>&#123;</span><br><span class="line">    Invoker&lt;T&gt; last = invoker;</span><br><span class="line">    <span class="comment">// 获得匹配激活的过滤器数组</span></span><br><span class="line">    List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter<span class="class">.<span class="keyword">class</span>).<span class="title">getActivateExtension</span>(<span class="title">invoker</span>.<span class="title">getUrl</span>(), <span class="title">key</span>, <span class="title">group</span>)</span>;</span><br><span class="line">    <span class="comment">// 倒序循环 Filter,创建带 Filter 链的 Invoker 对象</span></span><br><span class="line">    <span class="keyword">if</span> (!filters.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = filters.size() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            <span class="keyword">final</span> Filter filter = filters.get(i);</span><br><span class="line">            <span class="keyword">final</span> Invoker&lt;T&gt; next = last;</span><br><span class="line">            last = <span class="keyword">new</span> Invoker&lt;T&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> Class&lt;T&gt; <span class="title">getInterface</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> invoker.getInterface();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> URL <span class="title">getUrl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> invoker.getUrl();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAvailable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> invoker.isAvailable();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> filter.invoke(next, invocation);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    invoker.destroy();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> invoker.toString();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> last;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ProtocolListenerWrapper.export()<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="comment">// 注册中心协议</span></span><br><span class="line">    <span class="keyword">if</span> (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123;</span><br><span class="line">        <span class="keyword">return</span> protocol.export(invoker);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 暴露服务,创建 Exporter 对象</span></span><br><span class="line">    Exporter&lt;T&gt; exporter = protocol.export(invoker);</span><br><span class="line">    <span class="comment">// 获得 ExporterListener 数组</span></span><br><span class="line">    List&lt;ExporterListener&gt; listeners = Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener<span class="class">.<span class="keyword">class</span>).<span class="title">getActivateExtension</span>(<span class="title">invoker</span>.<span class="title">getUrl</span>(), <span class="title">Constants</span>.<span class="title">EXPORTER_LISTENER_KEY</span>))</span>;</span><br><span class="line">    <span class="comment">// 创建带 ExporterListener 的 Exporter 对象</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ListenerExporterWrapper&lt;T&gt;(exporter, listeners);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>InjvmProtocol.export()<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> InjvmExporter&lt;T&gt;(invoker, invoker.getUrl().getServiceKey(), exporterMap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="使用本地暴露的原因"><a href="#使用本地暴露的原因" class="headerlink" title="使用本地暴露的原因"></a>使用本地暴露的原因</h3><p>本地调用使用了 injvm 协议,是一个伪协议,它不开启端口,不发起远程调用,只在 JVM 内直接关联,但执行 Dubbo 的 Filter 链.</p>
<h2 id="服务远程暴露"><a href="#服务远程暴露" class="headerlink" title="服务远程暴露"></a>服务远程暴露</h2><p>服务远程暴露的总体流程:</p>
<p>1.将 ref 封装为 Invoker</p>
<p>2.将 Invoker 转换为 Exporter</p>
<p>3.启动 Netty 服务端</p>
<p>4.注册 provider 到 zk</p>
<p>5.zk 订阅与通</p>
<p>6.返回 Exporter 实例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 服务远程暴露</span><br><span class="line">- 使用 ProxyFactory 将 ref 创建成 Invoker 对象(这部分逻辑和本地暴露类似)</span><br><span class="line">    - ProxyFactory$Adaptive.getInvoker()中</span><br><span class="line">        - extension.getInvoker(arg0, arg1, arg2);</span><br><span class="line">            - StubProxyFactoryWrapper.getInvoker()直接调用内部的JavassistProxyFactory.getInvoker()</span><br><span class="line">                - JavassistProxyFactory.getInvoker()方法中</span><br><span class="line">                - 1.根据传入的 proxy对象(如DemoServiceImpl)的类信息创建对它的包装对象Wrapper</span><br><span class="line">                - 2.根据proxy, type, url创建AbstractProxyInvoker对象,它的doInvoke()方法会调用wrapper类的invokeMethod()方法</span><br><span class="line">- 首先将AbstractProxyInvoker实例包装成DelegateProviderMetaDataInvoker实例</span><br><span class="line">- 使用 Protocol 暴露 Invoker 对象为 Exporter</span><br><span class="line">    - Protocol$Adaptive.export()中</span><br><span class="line">    - 1.此时从传入的invoker.url.protocol获取到的协议为&quot;registry&quot;,获取到的Protocol拓展点实现类为包裹了DubboProtocol 对象的 ProtocolFilterWrapper</span><br><span class="line">    - 2.extension.export(invoker)</span><br><span class="line">        - ProtocolFilterWrapper.export()这个类在Invoker基础上添加filter链</span><br><span class="line">            - 1.因为传入的协议时&quot;registry&quot;,向注册中心暴露服务</span><br><span class="line">                - ProtocolListenerWrapper.export()中</span><br><span class="line">                - 1.调用RegistryProtocol.export(),向注册中心注册</span><br><span class="line">                    - RegistryProtocol.export()中</span><br><span class="line">                        - 1.doLocalExport()本地启动服务</span><br><span class="line">                            - RegistryProtocol.doLocalExport()中</span><br><span class="line">                            - 1.尝试从bounds缓存中获取exporter</span><br><span class="line">                            - 2.若1中获取不到则创建exporter并缓存</span><br><span class="line">                            - 3.根据invoker创建InvokerDelegete委托类,提供 获取 invoker 的方法</span><br><span class="line">                            - 4.调用Protocol$Adaptive.export()方法</span><br><span class="line">                                - Protocol$Adaptive.export()这次传入的协议是&quot;dubbo&quot;</span><br><span class="line">                                    - ProtocolFilterWrapper.export()中</span><br><span class="line">                                    - 1.buildInvokerChain()构建filter链</span><br><span class="line">                                    - 2.protocol.export()调用DubboProtocol.export()</span><br><span class="line">                                        - DubboProtocol.export()中</span><br><span class="line">                                        - 1.通过invoker创建DubboExporter</span><br><span class="line">                                        - &#x2F;&#x2F; 2.参见netty启动流程</span><br><span class="line">                            - 5.将4中返回的exporter包装成ExporterChangeableWrapper</span><br><span class="line">                        - 获取注册中心,如zk</span><br><span class="line">                            - 向注册中心注册自己</span><br><span class="line">                                - FailbackRegistry.register(url)</span><br></pre></td></tr></table></figure>
<p>ProtocolFilterWrapper.export()中<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="comment">// 注册中心</span></span><br><span class="line">    <span class="keyword">if</span> (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123;</span><br><span class="line">        <span class="keyword">return</span> protocol.export(invoker);<span class="comment">// 向注册中心发布服务的时候并不会组装 filter调用链</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 建立带有 Filter 过滤链的 Invoker,再暴露服务</span></span><br><span class="line">    <span class="keyword">return</span> protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(<span class="keyword">final</span> Invoker&lt;T&gt; originInvoker)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">    <span class="comment">// 暴露服务</span></span><br><span class="line">    <span class="comment">// export invoker</span></span><br><span class="line">    <span class="keyword">final</span> ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得注册中心 URL</span></span><br><span class="line">    URL registryUrl = getRegistryUrl(originInvoker);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得注册中心对象(启动zookeeper)</span></span><br><span class="line">    <span class="comment">// registry provider</span></span><br><span class="line">    <span class="keyword">final</span> Registry registry = getRegistry(originInvoker);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获得服务提供者 URL</span></span><br><span class="line">    <span class="keyword">final</span> URL registedProviderUrl = getRegistedProviderUrl(originInvoker);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//to judge to delay publish whether or not.判断是否延迟发布</span></span><br><span class="line">    <span class="keyword">boolean</span> register = registedProviderUrl.getParameter(<span class="string">"register"</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向注册中心订阅服务消费者</span></span><br><span class="line">    ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registedProviderUrl);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向注册中心注册服务提供者(自己)</span></span><br><span class="line">    <span class="keyword">if</span> (register) &#123;</span><br><span class="line">        register(registryUrl, registedProviderUrl);</span><br><span class="line">        ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(<span class="keyword">true</span>); <span class="comment">// 标记向本地注册表的注册服务提供者,已经注册</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用 OverrideListener 对象,订阅配置规则</span></span><br><span class="line">    <span class="comment">// Subscribe the override data</span></span><br><span class="line">    <span class="comment">// FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call the same service. Because the subscribed is cached key with the name of the service, it causes the subscription information to cover.</span></span><br><span class="line">    <span class="comment">// 创建订阅配置规则的 URL</span></span><br><span class="line">    <span class="keyword">final</span> URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);</span><br><span class="line">    <span class="comment">// 创建 OverrideListener 对象,并添加到 `overrideListeners` 中</span></span><br><span class="line">    <span class="keyword">final</span> OverrideListener overrideSubscribeListener = <span class="keyword">new</span> OverrideListener(overrideSubscribeUrl, originInvoker);</span><br><span class="line">    overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);</span><br><span class="line">    <span class="comment">// 向注册中心,发起订阅</span></span><br><span class="line">    registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);</span><br><span class="line">    <span class="comment">//Ensure that a new exporter instance is returned every time export</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DestroyableExporter&lt;T&gt;(exporter, originInvoker, overrideSubscribeUrl, registedProviderUrl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h2><p>ExchangeHandlerAdapter 定义了与客户端连接成功／断开连接／接受到客户端消息／响应消息,以及创造Invocation的方法<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ExchangeServer <span class="title">bind</span><span class="params">(URL url, ExchangeHandler handler)</span> <span class="keyword">throws</span> RemotingException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> HeaderExchangeServer(Transporters.bind(url, <span class="keyword">new</span> DecodeHandler(<span class="keyword">new</span> HeaderExchangeHandler(handler))));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>HeaderExchangeHandler: 基于消息头(Header)的信息交换服务器实现类</p>
<p>DecodeHandler: 解码处理器,处理接收到的消息</p>
<h3 id="Netty-启动流程"><a href="#Netty-启动流程" class="headerlink" title="Netty 启动流程"></a>Netty 启动流程</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- netty启动流程</span><br><span class="line">- openServer(url)启动通信服务器(如Netty)</span><br><span class="line">    - DubboProtocol.openServer()中</span><br><span class="line">        - DubboProtocol.createServer()中</span><br><span class="line">        - 1.创建ExchangeHandlerAdapter实例,作为请求处理器</span><br><span class="line">        - 2.Exchangers.bind(url,requestHandler)</span><br><span class="line">            - Exchangers.bind()中</span><br><span class="line">            - 1.根据url获取Exchanger,返回的是HeaderExchanger对象</span><br><span class="line">                - HeaderExchanger.bind()</span><br><span class="line">                    - HeaderExchanger.bind()方法中</span><br><span class="line">                    - 1. return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))))会对传入的ExchangeHandlerAdapter包装两层,然后使用Transporters.bind()创建NettyServer对象.</span><br><span class="line">                        - Transporters.bind()中</span><br><span class="line">                        - 1.返回Transporter的适配对象</span><br><span class="line">                        - 2.调用Transporter$Adaptive.bind()</span><br><span class="line">                            - netty4&#x2F;NettyTransporter.bind()通过new NettyServer(url, listener)创建nettyServer对象</span><br><span class="line">                                - NettyServer(url,handler)构造器中会通过ChannelHandlers会传入的DecodeHandler进行包装</span><br><span class="line">                                    - ChannelHandler.wrapInternal()方法中</span><br><span class="line">                                    - 1.获取Dispatcher的适配对象</span><br><span class="line">                                    - 2.调用Dispatcher.dispatch(handler, url)</span><br><span class="line">                                        - AllDispatcher.dispatch()中new AllChannelHandler(handler, url)</span><br><span class="line">                                            - AllChannelHandler调用父类构造方法WrappedChannelHandler</span><br><span class="line">                                                - WrappedChannelHandler()构造方法中</span><br><span class="line">                                                - 1.创建线程池</span><br><span class="line">                                    - 3.把2中的返回结果用HeartbeatHandler和MultiMessageHandler再包装</span><br><span class="line">                                - NettyServer.doOpen()</span><br><span class="line">                - 1.创建</span><br><span class="line">            - 2.exchanger.bind()</span><br><span class="line">    - ExchangeServer.createServer() 创建ExchangeServer</span><br></pre></td></tr></table></figure>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ZookeeperRegistry</span><span class="params">(URL url, ZookeeperTransporter zookeeperTransporter)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(url);</span><br><span class="line">    <span class="keyword">if</span> (url.isAnyHost()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"registry address == null"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获得 Zookeeper 根节点</span></span><br><span class="line">    String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); <span class="comment">// `url.parameters.group` 参数值</span></span><br><span class="line">    <span class="keyword">if</span> (!group.startsWith(Constants.PATH_SEPARATOR)) &#123;</span><br><span class="line">        group = Constants.PATH_SEPARATOR + group;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.root = group;</span><br><span class="line">    <span class="comment">// 创建 Zookeeper Client</span></span><br><span class="line">    zkClient = zookeeperTransporter.connect(url);</span><br><span class="line">    <span class="comment">// 添加 StateListener 对象.该监听器,在重连时,调用恢复方法.</span></span><br><span class="line">    zkClient.addStateListener(<span class="keyword">new</span> StateListener() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(<span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (state == RECONNECTED) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    recover();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    logger.error(e.getMessage(), e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AbstractRegistry: </p>
<ul>
<li>1.通用的注册,订阅,查询,通知等方法</li>
<li>2.读取和持久化注册数据到文件,以 properties 格式存储</li>
</ul>
<p>FailbackRegistry:<br>主要用来做失败重试操作(包括: 注册失败,反注册失败,订阅失败,反订阅失败,通知失败的重试);也提供了供 ZookeeperRegistry 使用的 zk 重连后的恢复工作的方法.</p>
<p>ZookeeperRegistry:<br>创建 zk 客户端,启动会话;并且调用 FailbackRegistry 实现 zk 重连后的恢复工作.</p>
<h3 id="注册到-zk-流程"><a href="#注册到-zk-流程" class="headerlink" title="注册到 zk 流程"></a>注册到 zk 流程</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 注册到zk流程</span><br><span class="line">- RegistryProtocol.export()</span><br><span class="line">- 1.获得注册中心 URL</span><br><span class="line">    - 就是把url改为zookeeper:&#x2F;&#x2F;协议开头</span><br><span class="line">- 2.获得注册中心对象(启动zookeeper),通过ZookeeperRegistryFactory实例创建并返回ZookeeperRegistry对象</span><br><span class="line">    - AbstractRegistryFactory.getRegistry(url)中</span><br><span class="line">    - 1.加锁 从缓存中获得 Registry 对象</span><br><span class="line">    - 2.若获取不到,则createRegistry(url)创建 Registry 对象并缓存</span><br><span class="line">        - ZookeeperRegistryFactory.createRegistry()中会new ZookeeperRegistry(url, zookeeperTransporter)创建ZookeeperRegistry实例</span><br><span class="line">- 3.获得服务提供者 URL</span><br><span class="line">- 4.向注册中心注册服务提供者</span><br><span class="line">    - RegistryProtocol.register(registedProviderUrl)</span><br><span class="line">    - 1.从registryFactory中获取registry</span><br><span class="line">    - 2.registry.register()</span><br><span class="line">        - ZookeeperRegistry.doRegister()</span><br><span class="line">        - 1.通过url得到zk路径,创建临时节点</span><br><span class="line">- 5.向注册中心发起订阅</span><br><span class="line">    当前的provider订阅了&#x2F;dubbo&#x2F;com.alibaba.dubbo.demo.DemoService&#x2F;configurators,当其下的子节点发生变化(url)时,通知到provider,使得providerUrl发生变化,则提供者需要重新暴露</span><br><span class="line">    - RegistryProtocol.export()</span><br><span class="line">        - FailbackRegistry.subscribe()</span><br><span class="line">            - ZookeeperRegistry.doSubscribe()</span><br><span class="line">            - 创建持久节点&#x2F;dubbo&#x2F;com.alibaba.dubbo.demo.DemoService&#x2F;configurators</span><br><span class="line">- 6.返回Exporter</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo 服务引用</title>
    <url>/2019/11/29/01no/dubbo/dubbo04-refer/</url>
    <content><![CDATA[<p><a href="https://dubbo.apache.org/zh-cn/docs/source_code_guide/refer-service.html" target="_blank" rel="noopener">官网</a></p>
<h1 id="客户端服务引用"><a href="#客户端服务引用" class="headerlink" title="客户端服务引用"></a>客户端服务引用</h1><h2 id="客户端服务引用-demo"><a href="#客户端服务引用-demo" class="headerlink" title="客户端服务引用 demo"></a>客户端服务引用 demo</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DemoService demoService = (DemoService) context.getBean(<span class="string">"demoService"</span>); <span class="comment">// get remote service proxy</span></span><br><span class="line">demoService.sayHello(<span class="string">"world"</span>);</span><br></pre></td></tr></table></figure>
<p>dubbo 在客户端动态的生成了一个该 Interface 类型的代理类.在这个代理类中封装了远程服务调用的组件.</p>
<h2 id="DemoService-创建"><a href="#DemoService-创建" class="headerlink" title="DemoService 创建"></a>DemoService 创建</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">group</span>=<span class="string">"g1"</span> <span class="attr">check</span>=<span class="string">"true"</span> <span class="attr">interface</span>=<span class="string">"com.alibaba.dubbo.demo.DemoService"</span></span></span><br><span class="line"><span class="tag">                     <span class="attr">client</span>=<span class="string">"netty4"</span> <span class="attr">timeout</span>=<span class="string">"10000"</span> <span class="attr">callbacks</span>=<span class="string">"1000"</span> <span class="attr">registry</span>=<span class="string">"zk01"</span> <span class="attr">filter</span>=<span class="string">"demo2"</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Spring 容器启动时,AbstractBeanFactory.isFactoryBean() 会判断 demoService 配置的 RootBeanDefinition 的 beanType 为<code>com.alibaba.dubbo.config.spring.ReferenceBean</code>,它是个 FactoryBean,Spring 容器会创建 ReferenceBean 这个 FactoryBean 实例.</p>
<h2 id="获取-DemoService"><a href="#获取-DemoService" class="headerlink" title="获取 DemoService"></a>获取 DemoService</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DemoService demoService = (DemoService) context.getBean(<span class="string">"demoService"</span>); <span class="comment">// get remote service proxy</span></span><br></pre></td></tr></table></figure>
<p>会调用 factoryBean.getObject() 方法,即调用 ReferenceBean.getObject() 创建 demoService 实例.</p>
<p><a href="https://github.com/apache/dubbo/pull/2754" target="_blank" rel="noopener">DUBBO-issue-2757</a> debug 时候遇到这个 bug 了,需要在 idea 里设置下.</p>
<p><code>在服务提供方,Invoker 用于调用服务提供类.在服务消费方,Invoker 用于执行远程调用.</code></p>
<h2 id="客户端服务引用流程"><a href="#客户端服务引用流程" class="headerlink" title="客户端服务引用流程"></a>客户端服务引用流程</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- refer</span><br><span class="line">- context.getBean(&quot;demoService&quot;)</span><br><span class="line">    - ReferenceBean.getObject():通过这个 FactoryBean 创建 demoService 实例</span><br><span class="line">        - ReferenceConfig.init(): 调用父类ReferenceConfig.init()</span><br><span class="line">            - ReferenceConfig.createProxy(map)创建DemoService代理对象</span><br><span class="line">            - 1.远程引用的逻辑</span><br><span class="line">            - 1.1.loadRegistries()加载注册中心URL数组</span><br><span class="line">            - 1.2.引用服务invoker &#x3D; refprotocol.refer(interfaceClass, urls.get(0))</span><br><span class="line">                - Protocol$Adaptive.refer()</span><br><span class="line">                    - ProtocolFilterWrapper.refer()</span><br><span class="line">                        - ProtocolListenerWrapper.refer()</span><br><span class="line">                            - RegistryProtocol.refer()</span><br><span class="line">                            - 1.获取注册中心的url</span><br><span class="line">                            - 2.获得注册中心registryFactory.getRegistry(url)</span><br><span class="line">                            - 3.执行服务引用doRefer(cluster, registry, type, url)</span><br><span class="line">                                - RegistryProtocol.doRefer()</span><br><span class="line">                                - 1.根据DemoService的type和url创建RegistryDirectory 对象,并设置注册中心</span><br><span class="line">                                - 2.向注册中心注册自己(服务消费者)registry.register()</span><br><span class="line">                                - 3.向注册中心订阅 服务提供者 + 路由规则 + 配置规则</span><br><span class="line">                                - 4.通过cluster创建Invoker对象cluster.join(directory)并返回Invoker</span><br><span class="line">            - 1.3.生成invoker的代理对象并返回 return (T) proxyFactory.getProxy(invoker)</span><br><span class="line">                - ProxyFactory$Adaptive().getProxy()</span><br><span class="line">                    - JavassistProxyFactory.getProxy(invoker, interfaces)</span><br><span class="line">                        - Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker))</span><br><span class="line">                            - new InvokerInvocationHandler(invoker) &#x2F;&#x2F; invoker为MockClusterInvoker实例</span><br></pre></td></tr></table></figure>
<h1 id="客户端服务调用"><a href="#客户端服务调用" class="headerlink" title="客户端服务调用"></a>客户端服务调用</h1><p>demoService.sayHello(“world”)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- consumer-call</span><br><span class="line">- demoService.sayHello(&quot;world&quot;)</span><br><span class="line">    - com.alibaba.dubbo.common.bytecode.proxy0.sayHello(name) &#x2F;&#x2F; 服务代理类</span><br><span class="line">        - InvokerInvocationHandler.invoke(proxy, method, args)</span><br><span class="line">        - 1.获取参数名和方法名</span><br><span class="line">        - 2.RPC调用invoker.invoke(new RpcInvocation(method, args)).recreate()</span><br><span class="line">            - 1.将method和参数封装成RpcInvocation对象</span><br><span class="line">            - 2.MockClusterInvoker.invoke(invocation)</span><br><span class="line">                - result &#x3D; this.invoker.invoke(invocation)调用FailoverClusterInvoker.invoke(),先走父类AbstractClusterInvoker.invoke()</span><br><span class="line">                    - 1.通过 directory 获得所有服务提供者 Invoker 集合RegistryDirectory.list(Invocation invocation)</span><br><span class="line">                        - AbstractClusterInvoker.list(invocation)</span><br><span class="line">                            - 1.AbstractDirectory.list(invocation)</span><br><span class="line">                                - RegistryDirectory.doList(invocation)</span><br><span class="line">                                - 1.从localMethodInvokerMap中根据methodName获取所有匹配的invokers</span><br><span class="line">                            - 2.根据routers,调用router.route()筛选invokers</span><br><span class="line">                                - MockInvokersSelector.route()</span><br><span class="line">                                    - 对于普通invoker集合,调用MockInvokersSelector.getNormalInvokers(invokers)</span><br><span class="line">                                        - 不包含 MockInvoker 的情况下，直接返回 &#96;invokers&#96; 集合</span><br><span class="line">                            - 3.获取loadBalance,默认是RandomLoadBalance实例</span><br><span class="line">                            - 4.doInvoke(invocation, invokers, loadbalance)执行调用</span><br><span class="line">                                - FailoverClusterInvoker.doInvoke()中</span><br><span class="line">                                - 1.获取最大可调用次数: 最大可重试次数 + 1</span><br><span class="line">                                - 2.select(loadbalance, invocation, copyinvokers, invoked)根据负载均衡机制从 copyinvokers 中选择一个Invoker</span><br><span class="line">                                    - AbstractClusterInvoker.doselect()</span><br><span class="line">                                    - 1.若只有一个invoker直接选择</span><br><span class="line">                                    - 2.如果只有两个Invoker,轮循取</span><br><span class="line">                                    - 3.其余loadbalance.select(invokers, getUrl(), invocation)使用loadbalance获取invoker对象</span><br><span class="line">                                        - &#x2F;&#x2F; doSelect()具体的loadbalance算法实现</span><br><span class="line">                                - 3.将选中的invoker添加到invoked(保存已经调用过的invokers)中,并设置到context里</span><br><span class="line">                                - 4.发起RPC调用并返回result,invoker.invoke(invocation)</span><br><span class="line">                                    - invokerWrapper.invoke(invocation)</span><br><span class="line">                                        - ProtocolFilterWrapper$1.invoke()后面会调用filter链</span><br><span class="line">                            - 5.调用成功就直接返回result了,失败则根据重试次数和策略重新选中invoker调用</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat Debug</title>
    <url>/2019/11/29/01no/tomcat/tomcat01_debug/</url>
    <content><![CDATA[<h1 id="tomcat-debug"><a href="#tomcat-debug" class="headerlink" title="tomcat debug"></a>tomcat debug</h1><p>方式1. tomcat远程debug,这种方式正常用于sit或者灰度环境调试问题使用,当然localhost也能这样debug.<br>在startup.bat中配置<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET CATALINA_OPTS&#x3D;-server -Xdebug -Xnoagent -Djava.compiler&#x3D;NONE -Xrunjdwp:transport&#x3D;dt_socket,server&#x3D;y,suspend&#x3D;n,address&#x3D;19999</span><br></pre></td></tr></table></figure></p>
<p>方式2. 在idea中启动tomcat debug,需要添加tomcat的jar依赖.这种方式用于本地看tomcat源码或者定位本地起的项目中tomcat部分的问题时可以使用.<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.tomcat<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tomcat-catalina<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.0.82<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.tomcat<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>tomcat-coyote<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.0.82<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>方式3. 直接启动,看源码用.<br>运行 org.apache.catalina.startup.Bootstrap 即可,默认配置会运行webapps下的工程</p>
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo SPI 机制</title>
    <url>/2019/11/27/01no/dubbo/dubbo02-spi/</url>
    <content><![CDATA[<h1 id="SPI机制"><a href="#SPI机制" class="headerlink" title="SPI机制"></a>SPI机制</h1><h2 id="SPI-作用"><a href="#SPI-作用" class="headerlink" title="SPI 作用"></a>SPI 作用</h2><p>SPI 全称为 Service Provider Interface,是一种服务发现机制.</p>
<p>SPI 的本质是将接口实现类的全限定名配置在文件中,并由服务加载器读取配置文件,加载实现类.</p>
<p>这样可以在运行时,动态为接口替换实现类.正因此特性,我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能.</p>
<p>Dubbo里面有很多个组件,每个组件在框架中都是以接口的形式抽象出来.具体的实现又分很多种,在程序执行时根据用户的配置来按需取接口的实现类.</p>
<h2 id="Dubbo-实现的-SPI-与-JDK-自带的-SPI-的区别"><a href="#Dubbo-实现的-SPI-与-JDK-自带的-SPI-的区别" class="headerlink" title="Dubbo 实现的 SPI 与 JDK 自带的 SPI 的区别"></a>Dubbo 实现的 SPI 与 JDK 自带的 SPI 的区别</h2><p>摘自官网</p>
<ul>
<li><p>JDK 标准的 SPI 会一次性实例化扩展点所有实现,如果有扩展实现初始化很耗时,但如果没用上也加载,会很浪费资源.</p>
</li>
<li><p>如果扩展点加载失败,连扩展点的名称都拿不到了.<br>比如: JDK 标准的 ScriptEngine,通过 getName() 获取脚本类型的名称,但如果 RubyScriptEngine 因为所依赖的 jruby.jar 不存在,导致 RubyScriptEngine 类加载失败,这个失败原因被吃掉了,和 ruby 对应不起来,当用户执行 ruby 脚本时,会报不支持 ruby,而不是真正失败的原因.</p>
</li>
<li><p>增加了对扩展点 IoC 和 AOP 的支持,一个扩展点可以直接 setter 注入其它扩展点.</p>
</li>
<li><p>JDK 的 SPI 要用 for 循环,然后 if 判断才能获取到指定的 SPI 对象,Dubbo 用指定的 key 就可以获取.</p>
</li>
<li><p>JDK 的 SPI 不支持默认值,Dubbo 增加了默认值的设计.</p>
</li>
</ul>
<h2 id="SPI-配置和使用"><a href="#SPI-配置和使用" class="headerlink" title="SPI 配置和使用"></a>SPI 配置和使用</h2><p>只有在接口打了 @SPI 注解的接口类才会去查找扩展点实现.</p>
<p>会依次从这几个文件中读取扩展点<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">META-INF&#x2F;Dubbo&#x2F;internal&#x2F;   &#x2F;&#x2F; Dubbo内部实现的各种扩展都放在了这个目录了</span><br><span class="line">META-INF&#x2F;Dubbo&#x2F;</span><br><span class="line">META-INF&#x2F;services&#x2F;</span><br></pre></td></tr></table></figure></p>
<p>比如</p>
<ol>
<li><p>Protocol 接口,接口上打了 @SPI 注解,默认拓展点名字为 Dubbo</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SPI</span>(<span class="string">"Dubbo"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Protocol</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查找 Dubbo-rpc-default 模块下 META-INF/Dubbo/internal/com.alibaba.Dubbo.rpc.Protocol 中的配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Dubbo&#x3D;com.alibaba.Dubbo.rpc.protocol.Dubbo.DubboProtocol</span><br></pre></td></tr></table></figure>
</li>
<li><p>会用 ExtensionLoader 类加载实现<br>Dubbo=com.alibaba.Dubbo.rpc.protocol.Dubbo.DubboProtocol</p>
</li>
<li><p>获取拓展类对象的代码示例</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 通过 ExtensionLoader.getExtensionLoader() 方法获取一个 ExtensionLoader 实例</span></span><br><span class="line">ExtensionLoader&lt;Protocol&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Protocol<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后再通过 ExtensionLoader.getExtension() 方法获取拓展类对象</span></span><br><span class="line">Protocol dubboProtocol = extensionLoader.getExtension(<span class="string">"Dubbo"</span>);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Dubbo-拓展点加载机制相关注解和组件"><a href="#Dubbo-拓展点加载机制相关注解和组件" class="headerlink" title="Dubbo 拓展点加载机制相关注解和组件"></a>Dubbo 拓展点加载机制相关注解和组件</h2><p>@SPI</p>
<p>@Adaptive</p>
<p>@Activate</p>
<h3 id="SPI-注解"><a href="#SPI-注解" class="headerlink" title="@SPI 注解"></a>@SPI 注解</h3><p>@SPI注解作用于扩展点的接口上,<code>表明该接口是一个扩展点</code>.可以被 Dubbo 的 ExtentionLoader 加载,如果没有此 ExtensionLoader 调用会异常.</p>
<h3 id="Adaptive-注解"><a href="#Adaptive-注解" class="headerlink" title="@Adaptive 注解"></a>@Adaptive 注解</h3><ol>
<li><p>在类上加 @Adaptive 注解的类,会创建对应类型的 Adaptive 类 缓存起来.代码里搜了一下,有 AdaptiveExtensionFactory, AdaptiveCompiler 这两个类上打了 @Adaptive 注解.</p>
</li>
<li><p>在方法上加 @Adaptive 注解,会先动态生成适配类的 Java 代码(可以打断点在 ExtensionLoader.createAdaptiveExtensionClassCode() 中看到生成的类),再默认用 Javassist 生成动态编译的 Adaptive 字节码.</p>
</li>
</ol>
<p>ExtensionLoader.loadFile() 时: 会判断类名是否含有 @Adaptive 注解.若有,则将此类作为适配类 缓存起来. (如果一个接口的所有实现类都没有类上打上这个注解的情况,则会用 Javassist 生成一个 Adaptive 类)</p>
<h3 id="Activate-注解"><a href="#Activate-注解" class="headerlink" title="@Activate 注解"></a>@Activate 注解</h3><p>可以被框架中自动激活加载扩展,这个注解用于配置扩展被自动激活的加载条件.</p>
<p>用户通过 group 和 value 配置激活条件.被 @Activate 注解的扩展点在满足某种条件时会被激活,它一般用来配合 filter,声明他们的使用场景.</p>
<h3 id="Wrapper"><a href="#Wrapper" class="headerlink" title="Wrapper"></a>Wrapper</h3><p>Wrapper 类同样实现了扩展点接口,但是 Wrapper 不是扩展点的真正实现.它的用途主要是用于从 ExtensionLoader 返回扩展点时,包装在真正的扩展点实现外层.即从 ExtensionLoader 中返回的实际上是 Wrapper 类的实例,Wrapper 持有了实际的扩展点实现类.</p>
<p>扩展点的 Wrapper 类可以有多个,也可以根据需要新增.</p>
<p>通过 Wrapper 类可以把所有扩展点公共逻辑移至 Wrapper 中.新加的 Wrapper 在所有的扩展点上添加了逻辑,有些类似 AOP,即 Wrapper 代理了扩展点.</p>
<h3 id="ExtensionLoader"><a href="#ExtensionLoader" class="headerlink" title="ExtensionLoader"></a>ExtensionLoader</h3><p>ExtensionLoader 是扩展点载入器,用于载入 Dubbo 中的各种可配置组件,比如: 动态代理方式(ProxyFactory),负载均衡策略(LoadBalance),RCP协议(Protocol),拦截器(Filter),容器类型(Container),集群方式(Cluster)和注册中心类型(RegistryFactory)等.</p>
<h1 id="获取-ExtensionLoader-流程"><a href="#获取-ExtensionLoader-流程" class="headerlink" title="获取 ExtensionLoader 流程"></a>获取 ExtensionLoader 流程</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ExtensionLoader&lt;Protocol&gt; loader &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class)</span><br><span class="line">    根据拓展点的接口,获得拓展加载器.如根据Protocol接口获取它对应的ExtensionLoader</span><br><span class="line">    - ExtensionLoader.getExtensionLoader(Class&lt;T&gt; type)中</span><br><span class="line">    - 1.type必须是接口</span><br><span class="line">    - 2.type上包含@SPI注解</span><br><span class="line">    - 3.根据type尝试从EXTENSION_LOADERS缓存中获取ExtensionLoader</span><br><span class="line">    - 4.在3中获取不到,则new ExtensionLoader&lt;T&gt;(type)创建并缓存起来</span><br><span class="line">        - ExtensionLoader(Class&lt;?&gt; type)构造器中,若传入的type不是ExtensionFactory类型,则会获取ExtensionFactory的adaptiveExtension赋值到当前ExtensionLoader对象的objectFactory属性中,这个objectFactory类似于IoC容器,用于向拓展对象注入依赖的属性.</span><br><span class="line">            - &#x2F;&#x2F; 参见objectFactory创建的逻辑</span><br><span class="line">    - 5.返回ExtensionLoader</span><br></pre></td></tr></table></figure>
<h1 id="获取-AdaptiveExtension-流程"><a href="#获取-AdaptiveExtension-流程" class="headerlink" title="获取 AdaptiveExtension 流程"></a>获取 AdaptiveExtension 流程</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Protocol adaptiveExtension &#x3D; loader.getAdaptiveExtension()</span><br><span class="line">    注解在接口的方法上,SPI机制可以根据接口动态地生成自适应类 xxx$Adaptive,并实例化这个类并返回</span><br><span class="line">    - ExtensionLoader.getAdaptiveExtension()中</span><br><span class="line">    - 1.先尝试从cachedAdaptiveInstance缓存中获取adaptive对象</span><br><span class="line">    - 2.在1中获取不到,则createAdaptiveExtension()创建adaptive对象并缓存起来</span><br><span class="line">        - ExtensionLoader.createAdaptiveExtension()中</span><br><span class="line">        - 1.(T) getAdaptiveExtensionClass().newInstance()</span><br><span class="line">            获取adaptive拓展类</span><br><span class="line">            - ExtensionLoader.getAdaptiveExtensionClass()中</span><br><span class="line">            - 1.getExtensionClasses()</span><br><span class="line">                获取所有拓展实现类</span><br><span class="line">                - ExtensionLoader.getExtensionClasses()中</span><br><span class="line">                - 1.尝试从cachedClasses中获取拓展实现类数组</span><br><span class="line">                - 2.获取不到则classes &#x3D; loadExtensionClasses()从配置文件中加载拓展实现类列表并缓存</span><br><span class="line">                    - ExtensionLoader.loadExtensionClasses()中</span><br><span class="line">                    - 1.从接口,如Protocol接口上获取@SPI注解的value属性值,如 &#96;@SPI(&quot;dubbo&quot;),value&#96; 就是 dubbo,作为默认拓展名</span><br><span class="line">                    - 2.分别从META-INF&#x2F;dubbo&#x2F;internal&#x2F;,META-INF&#x2F;dubbo&#x2F;,META-INF&#x2F;services&#x2F;路径下读取配置文件,加载拓展实现类列表</span><br><span class="line">                        - ExtensionLoader.loadFile()中</span><br><span class="line">                        - 1.根据文件名用类加载器获取urls数组</span><br><span class="line">                        - 2.遍历urls数组,用流一行行读取配置文件</span><br><span class="line">                        - 3.1.根据配置的类名创建Class对象</span><br><span class="line">                        - 3.2.判断class上是否含有@Adaptive注解.若有,缓存到cachedAdaptiveClass中</span><br><span class="line">                        - 3.3.若实现类中没有@Adaptive注解</span><br><span class="line">                        - 3.3.1.判断实现类是否存在入参为接口的构造器(比如ProtocolFilterWrapper类是否还有入参为Protocol接口的构造器,public ProtocolFilterWrapper(Protocol protocol),若有的话说明它是Wrapper类),添加到wrappers中</span><br><span class="line">                        - 3.3.2.既不是适配对象(@Adaptive),也不是wrapped的对象,那就是扩展点的具体实现对象,可以有多个.缓存到cachedNames和extensionClasses中,分别为class -&gt; name 的映射 和 name -&gt; class 的映射</span><br><span class="line">            - 2.在1中,若配置的类上有@Adaptive注解,则缓存到cachedAdaptiveClass中.此处取到直接返回cachedAdaptiveClass.若没有adaptive类,则走下面生成adaptive类</span><br><span class="line">            - 3.createAdaptiveExtensionClass()</span><br><span class="line">                自动生成自适应拓展的代码实现,并编译后返回该类</span><br><span class="line">                - ExtensionLoader.createAdaptiveExtensionClass()中</span><br><span class="line">                - 1.createAdaptiveExtensionClassCode()</span><br><span class="line">                    生成Adaptive类的代码code</span><br><span class="line">                - 2.利用dubbo的SPI扩展机制获取Compiler的适配类,此处为AdaptiveCompiler对象</span><br><span class="line">                - 3.compiler.compile(code, classLoader)编译上面生成的adaptive代码</span><br><span class="line">                    - AdaptiveCompiler.compile()中</span><br><span class="line">                    - 1.compiler &#x3D; loader.getDefaultExtension()获得默认的 Compiler 拓展对象</span><br><span class="line">                    - 2.compiler.compile(code, classLoader)编译类</span><br><span class="line">                        - AbstractCompiler.compile()</span><br><span class="line">                            - JavassistCompiler.doCompile()</span><br><span class="line">                - 4.返回编译后的class</span><br><span class="line">        - 2.injectExtension()</span><br><span class="line">            注入依赖</span><br><span class="line">            - &#x2F;&#x2F; 参见SPI IOC 流程</span><br><span class="line">        - 3.创建 Wrapper 拓展对象</span><br><span class="line">            - &#x2F;&#x2F; 参见SPI AOP流程</span><br><span class="line">    - 3.返回adaptive对象</span><br></pre></td></tr></table></figure>
<h1 id="根据name获取拓展点对象的流程"><a href="#根据name获取拓展点对象的流程" class="headerlink" title="根据name获取拓展点对象的流程"></a>根据name获取拓展点对象的流程</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Protocol dubboProtocol &#x3D; loader.getExtension(&quot;dubbo&quot;);</span><br><span class="line">      返回指定名字的扩展对象</span><br><span class="line">    - ExtensionLoader.getExtension(name)中</span><br><span class="line">    - 1.从cachedInstances获取对应的拓展对象</span><br><span class="line">    - 2.若获取不到,创建Holder对象,并缓存</span><br><span class="line">    - 3.通过instance &#x3D; createExtension(name)填充holder.value属性</span><br><span class="line">        - 1.之前的从配置文件中加载拓展类的逻辑</span><br><span class="line">        - 2.缓存到EXTENSION_INSTANCES中</span><br><span class="line">        - 3.注入依赖的属性injectExtension(instance)</span><br><span class="line">            - ExtensionLoader.injectExtension()中</span><br><span class="line">            - 1.遍历class中的所有方法找到setter方法</span><br><span class="line">            - 2.对于每一个setter方法&#x2F;&#x2F; 参见SPI IOC流程</span><br></pre></td></tr></table></figure>
<h1 id="objectFactory-创建的逻辑"><a href="#objectFactory-创建的逻辑" class="headerlink" title="objectFactory 创建的逻辑"></a>objectFactory 创建的逻辑</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- objectFactory(即AdaptiveExtensionFactory)创建的逻辑</span><br><span class="line">    - 在ExtensionLoader的构造方法中会判断当前传入的对象类型</span><br><span class="line">    - 1.如果type是ExtensionFactory类型,则objectFactory设为null</span><br><span class="line">    - 2.type不是ExtensionFactory类型,则会创建ExtensionFactory objectFactory用于后面给 拓展对象 注入依赖的属性</span><br><span class="line">        - 1.从配置文件中获取adaptive类的逻辑</span><br><span class="line">        - 2.AdaptiveExtensionFactory构造器中</span><br><span class="line">        - 获取ExtensionFactory的ExtensionLoader,用loader获取支持的extensions,此处为SPIExtensionFactory和SpringExtensionFactory</span><br></pre></td></tr></table></figure>
<h1 id="SPI-IOC-流程"><a href="#SPI-IOC-流程" class="headerlink" title="SPI IOC 流程"></a>SPI IOC 流程</h1><p>ExtensionLoader.injectExtension()这个方法中,会通过IOC机制注入拓展点对象的依赖.<br><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/dubbo/2019-11-28-11-03-56.png" alt="ExtensionLoader.injectExtension()被调用的地方"><br>查看调用发现,在创建拓展对象 和 创建自适应拓展对象 时,都会调用该方法完成依赖注入.</p>
<p>原理就是:<br>遍历当前对象的所有方法,找出setter方法,获取参数名和参数类型.通过 ExtensionFactory 去完成依赖注入.<br>ExtensionFactory 在之前 ExtensionLoader 创建时使用的是 AdaptiveExtensionFactory 的实现.<br>AdaptiveExtensionFactory 会调用 SPIExtensionFactory 去获取依赖的拓展对象.<br>SPIExtensionFactory 给当前拓展点对象注入的均是 adaptiveExtension,这样在运行期可以动态切换依赖的具体实现.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- AdaptiveExtensionFactory注入依赖的流程</span><br><span class="line">    - 当有实例调用injectExtension(instance)要注入依赖时,会遍历这个对象里的所有方法,找出setter方法,如 setXxx(X xxx) 则传入参数类型 和 参数名</span><br><span class="line">    - AdaptiveExtensionFactory.getExtension(type, name)中</span><br><span class="line">        - 1.遍历SPIExtensionFactory和SpringExtensionFactory</span><br><span class="line">        - 2.factory.getExtension(type, name)获取该属性的extension</span><br><span class="line">            - SPIExtensionFactory.getExtension(type, name)中</span><br><span class="line">            - 1.类型必须是接口且有@SPI注解,才会通过ExtensionLoader加载adaptiveExtension拓展,否则返回null</span><br><span class="line">    - 如果有adaptiveExtension拓展,则反射调用setter方法注入</span><br></pre></td></tr></table></figure>
<p>SpiExtensionFactory.getExtension(type, name)代码如下:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">getExtension</span><span class="params">(Class&lt;T&gt; type, String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI<span class="class">.<span class="keyword">class</span>)) </span>&#123; <span class="comment">// 接口类型 且 有@SPI注解</span></span><br><span class="line">        <span class="comment">// 加载拓展接口对应的 ExtensionLoader 对象</span></span><br><span class="line">        ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type);</span><br><span class="line">        <span class="comment">// 加载拓展对象</span></span><br><span class="line">        <span class="keyword">if</span> (!loader.getSupportedExtensions().isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> loader.getAdaptiveExtension();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="SPI-AOP-流程"><a href="#SPI-AOP-流程" class="headerlink" title="SPI AOP 流程"></a>SPI AOP 流程</h1><p>在 ExtensionLoader.createExtension(name) 方法中,根据 name 获取到拓展点实现类 并 通过 injectExtension() 完成依赖注入后,会创建 Wrapper 对象.<br>就是获取当前对象的所有wrapper(这些wapper是在读取配置文件时判断有参数为对应的接口类型的构造器 来添加的),然后调用有参构造器一层一层的通过injectExtension()包装起来.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- SPI AOP流程</span><br><span class="line">    - 1.遍历从配置文件中加载的wrapperClasses</span><br><span class="line">    - 2.1.使用带参的构造器创建Wrapper对象</span><br><span class="line">    - 2.2.使用wrapper对象调用injectExtension()返回instance</span><br><span class="line">    - 2.3.每遍历一次,就将wapper对象嵌套了一层</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- SPI @Activate缓存到cachedActivates流程</span><br><span class="line">    - ExtensionLoader.loadFile()里判断类上有Activate注解,则添加到缓存中.</span><br></pre></td></tr></table></figure>
<p>ExtensionLoader.createExtension(name) 代码如下:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> T <span class="title">createExtension</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1.获得拓展名对应的拓展实现类</span></span><br><span class="line">    Class&lt;?&gt; clazz = getExtensionClasses().get(name);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.注入依赖的属性</span></span><br><span class="line">    injectExtension(instance);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.创建 Wrapper 拓展对象</span></span><br><span class="line">    Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses;</span><br><span class="line">    <span class="keyword">if</span> (wrapperClasses != <span class="keyword">null</span> &amp;&amp; !wrapperClasses.isEmpty()) &#123;<span class="comment">// 先实例化扩展点的实现,再判断此时是否有此扩展点的包装类缓存,有的话利用wrapper增强这个扩展点实现的功能</span></span><br><span class="line">        <span class="keyword">for</span> (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123;</span><br><span class="line">            <span class="comment">// 包装</span></span><br><span class="line">            instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); <span class="comment">// 包装后又赋值给 instance,所以最终 Wrapper 是一层层嵌套的</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="SPI-Activate流程"><a href="#SPI-Activate流程" class="headerlink" title="SPI @Activate流程"></a>SPI @Activate流程</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- SPI @Activate流程</span><br><span class="line">    - ExtensionLoader.getActivateExtension(url, values, group)</span><br><span class="line">    - 1.通过getExtensionClasses()获得拓展实现类列表</span><br><span class="line">    - 2.遍历cachedActivates</span><br><span class="line">    - 2.1.isMatchGroup()判断activate对象的group配置是否和传入的group匹配</span><br><span class="line">    - 2.2.若上一步匹配,则通过getExtension(name)获得拓展对象</span><br><span class="line">    - 2.3.判断传入的names是否匹配,isActive(activate, url)通过activate.value值判断是否激活</span><br><span class="line">    - 2.4.若上面条件都满足,添加到list里,并通过ActivateComparator给activate列表排序</span><br><span class="line">        - ActivateComparator.compare()排序逻辑</span><br><span class="line">        - 1.获取比较的两个类上的Activate注解,通过before或after属性进行排序</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Get activate extensions.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 获得符合自动激活条件的拓展对象数组</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;T&gt; <span class="title">getActivateExtension</span><span class="params">(URL url, String[] values, String group)</span> </span>&#123;</span><br><span class="line">    List&lt;T&gt; exts = <span class="keyword">new</span> ArrayList&lt;T&gt;();</span><br><span class="line">    List&lt;String&gt; names = values == <span class="keyword">null</span> ? <span class="keyword">new</span> ArrayList&lt;String&gt;(<span class="number">0</span>) : Arrays.asList(values);</span><br><span class="line">    <span class="keyword">if</span> (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) &#123;</span><br><span class="line">        <span class="comment">// 获得拓展实现类列表</span></span><br><span class="line">        getExtensionClasses();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Activate&gt; entry : cachedActivates.entrySet()) &#123; <span class="comment">// 遍历 cachedActivates</span></span><br><span class="line">            String name = entry.getKey();</span><br><span class="line">            Activate activate = entry.getValue();</span><br><span class="line">            <span class="keyword">if</span> (isMatchGroup(group, activate.group())) &#123; <span class="comment">// 匹配分组</span></span><br><span class="line">                <span class="comment">// 获得拓展对象</span></span><br><span class="line">                T ext = getExtension(name);</span><br><span class="line">                <span class="keyword">if</span> (!names.contains(name)</span><br><span class="line">                        &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)</span><br><span class="line">                        &amp;&amp; isActive(activate, url)) &#123; <span class="comment">// 判断是否激活</span></span><br><span class="line">                    exts.add(ext);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 排序</span></span><br><span class="line">        Collections.sort(exts, ActivateComparator.COMPARATOR);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">return</span> exts;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo整理</title>
    <url>/2019/11/26/01no/dubbo/dubbo01-overview/</url>
    <content><![CDATA[<p>整理自官网,对整体理解Dubbo很有作用.</p>
<h1 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h1><p>Apache Dubbo 是一款高性能,轻量级的Java RPC框架.</p>
<h1 id="三大核心能力"><a href="#三大核心能力" class="headerlink" title="三大核心能力"></a>三大核心能力</h1><p>面向接口的远程方法调用</p>
<p>智能容错和负载均衡</p>
<p>以及服务自动注册和发现</p>
<h1 id="健壮性"><a href="#健壮性" class="headerlink" title="健壮性"></a>健壮性</h1><p>监控中心宕掉不影响使用,只是丢失部分采样数据.</p>
<p>数据库宕掉后,注册中心仍能通过缓存提供服务列表查询,但不能注册新服务.</p>
<p>注册中心对等集群,任意一台宕掉后,将自动切换到另一台.</p>
<p><code>注册中心全部宕掉后,服务提供者 和 服务消费者 仍能通过本地缓存通讯</code>.</p>
<p>服务提供者无状态,任意一台宕掉后,不影响使用.</p>
<p>服务提供者全部宕掉后,服务消费者应用将无法使用,并<code>无限次重连等待服务提供者恢复</code>.</p>
<h1 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h1><p>注册中心为对等集群,可动态增加机器部署实例,所有客户端将自动发现新的注册中心.</p>
<p>服务提供者无状态,可动态增加机器部署实例,注册中心将推送新的服务提供者信息给消费者.</p>
<h1 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h1><ul>
<li><p>Dubbo协议<br><code>采用NIO复用单一长连接,并使用线程池并发处理请求,减少握手和加大并发效率,性能较好</code>(推荐使用)<br>在大文件传输时,单一连接会成为瓶颈<br>可用于生产环境</p>
</li>
<li><p>Rmi协议<br>可与原生RMI互操作,基于TCP协议<br>偶尔会连接失败,需重建Stub    可用于生产环境</p>
</li>
<li><p>Hessian协议<br>可与原生Hessian互操作,基于HTTP协议<br>需hessian.jar支持,http短连接的开销大    可用于生产环境</p>
</li>
</ul>
<h1 id="nio框架"><a href="#nio框架" class="headerlink" title="nio框架"></a>nio框架</h1><ul>
<li><p>Netty Transporter<br>JBoss 的 NIO 框架,性能较好(推荐使用)<br>一次请求派发两种事件,需屏蔽无用事件.</p>
</li>
<li><p>Mina Transporter<br>老牌NIO框架,稳定<br>待发送消息队列派发不及时,大压力下,会出现FullGC.</p>
</li>
</ul>
<h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><ul>
<li><p>Hessian Serialization<br>Stable    性能较好,多语言支持(推荐使用)<br>Hessian的各版本兼容性不好,可能和应用使用的Hessian冲突,Dubbo内嵌了hessian3.2.1的源码<br>可用于生产环境</p>
</li>
<li><p>Dubbo Serialization<br>Tested<br>通过不传送POJO的类元信息,在大量POJO传输时,性能较好<br>当参数对象增加字段时,需外部文件声明    试用</p>
</li>
<li><p>Json Serialization<br>纯文本,可跨语言解析,缺省采用FastJson解析<br>性能较差    试用</p>
</li>
<li><p>Java Serialization<br>Java原生支持    性能较差<br>可用于生产环境</p>
</li>
</ul>
<h1 id="生成代理类"><a href="#生成代理类" class="headerlink" title="生成代理类"></a>生成代理类</h1><ul>
<li><p>Javassist ProxyFactory<br>通过字节码生成代替反射,性能比较好(推荐使用)<br>依赖于javassist.jar包,占用JVM的Perm内存,Perm可能要设大一些:java -XX:PermSize=128m<br>可用于生产环境</p>
</li>
<li><p>Jdk ProxyFactory<br>JDK原生支持    性能较差    可用于生产环境</p>
</li>
</ul>
<h1 id="容错机制"><a href="#容错机制" class="headerlink" title="容错机制"></a>容错机制</h1><ul>
<li><p>Failover Cluster<br>失败自动切换,当出现失败,重试其它服务器,通常用于读操作(推荐使用)<br>重试会带来更长延迟</p>
</li>
<li><p>Failfast Cluster<br>快速失败,只发起一次调用,失败立即报错,通常用于非幂等性的写操作    如果有机器正在重启,可能会出现调用失败    可用于生产环境</p>
</li>
<li><p>Failsafe Cluster<br>失败安全,出现异常时,直接忽略,通常用于写入审计日志等操作<br>调用信息丢失<br>可用于生产环境    Monitor</p>
</li>
<li><p>Failback Cluster<br>失败自动恢复,后台记录失败请求,定时重发,通常用于消息通知操作<br>不可靠,重启丢失<br>可用于生产环境    Registry</p>
</li>
<li><p>Forking Cluster<br>并行调用多个服务器,只要一个成功即返回,通常用于实时性要求较高的读操作<br>需要浪费更多服务资源<br>可用于生产环境</p>
</li>
<li><p>Broadcast Cluster<br>广播调用所有提供者,逐个调用,任意一台报错则报错,通常用于更新提供方本地状态<br>速度慢,任意一台报错则报错<br>可用于生产环境</p>
</li>
</ul>
<h1 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h1><ul>
<li><p>Random LoadBalance<br>随机,按权重设置随机概率(推荐使用)<br>在一个截面上碰撞的概率高,重试时,可能出现瞬间压力不均</p>
</li>
<li><p>RoundRobin LoadBalance<br>轮询,按公约后的权重设置轮询比率<br>存在慢的机器累积请求问题,极端情况可能产生雪崩</p>
</li>
<li><p>LeastActive LoadBalance<br>最少活跃调用数,相同活跃数的随机,活跃数指调用前后计数差,使慢的机器收到更少请求<br>不支持权重,在容量规划时,不能通过权重把压力导向一台机器压测容量</p>
</li>
<li><p>ConsistentHash LoadBalance<br>一致性Hash,相同参数的请求总是发到同一提供者,当某一台提供者挂时,原本发往该提供者的请求,基于虚拟节点,平摊到其它提供者,不会引起剧烈变动<br>压力分摊不均</p>
</li>
</ul>
<h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1><p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/thread-model.html" target="_blank" rel="noopener">线程模型</a></p>
<p>IO线程自行处理:<br>如果事件处理的逻辑能迅速完成,并且不会发起新的 IO 请求,比如只是在内存中记个标识,则直接在 IO 线程上处理更快,因为减少了线程池调度.</p>
<p>派发到线程池处理:<br>但如果事件处理逻辑较慢,或者需要发起新的 IO 请求,比如需要查询数据库,则必须派发到线程池,否则 IO 线程阻塞,将导致不能接收其它请求.</p>
<p>如果用 IO 线程处理事件,又在事件处理过程中发起新的 IO 请求,比如在连接事件中发起登录请求,会报”可能引发死锁”异常,但不会真死锁.</p>
<h1 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h1><p>业务层: Service</p>
<p>RPC层: Config, Proxy, Registry, Cluster, Monitor, Protocol</p>
<p>Remote层: Exchange, Transport, Serialize</p>
<ul>
<li><p>Service:<br>业务层.包括业务代码的接口与实现.</p>
</li>
<li><p>config 配置层:<br>对外配置接口,以 ServiceConfig(暴露的服务配置), ReferenceConfig(引用的服务配置) 为中心,可以直接初始化配置类,也可以通过 spring 解析配置生成配置类.该层管理整个dubbo的配置.</p>
</li>
<li><p>proxy 服务代理层:<br>服务代理层.在Dubbo中,无论 服务提供者 还是 服务消费者,框架都会生成一个代理类,整个过程对上层透明.<br>当调用一个远程接口时,看起来就像调用一个本地接口一样.<br>代理层会自动做远程调用并返回结果,即让业务层对远程调用完全无感知.<br>服务接口透明代理,生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心,扩展接口为 ProxyFactory</p>
</li>
<li><p>registry 注册中心层:<br>负责 Dubbo 框架的服务注册与发现.当有新的服务加入或旧服务下线时,注册中心都会感知并通知给所有订阅方.以服务 URL 为中心,扩展接口为 RegistryFactory, Registry, RegistryService</p>
</li>
<li><p>cluster 路由层:<br>封装多个提供者的路由及负载均衡,并桥接注册中心,以 Invoker 为中心,扩展接口为 Cluster, Directory, Router, LoadBalance.<br>该层主要负责:<br>远程调用失败时的容错策略(如失败重试,快速失败);<br>选择具体调用节点时的负载均衡策略(如随机,一致性Hash等);<br>特殊调用路径的路由策略(如某个消费者只会调用某个IP的生产者)</p>
</li>
<li><p>monitor 监控层:<br>RPC 调用次数和调用时间监控,以 Statistics 为中心,扩展接口为 MonitorFactory, Monitor, MonitorService</p>
</li>
<li><p>protocol 远程调用层:<br>封装 RPC 调用具体过程.,以 Invocation, Result 为中心,扩展接口为 Protocol, Invoker, Exporter.<br>是服务域,它是 Invoker 暴露和引用的主功能入口,它负责 Invoker 的生命周期管理.<br>Protocol 是核心层,也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用,然后在 Invoker 的主过程上 Filter 拦截点.<br>Invoker 是 Dubbo 的核心模型,框架中所有其他模型都向它靠拢,或者转换成它,它代表一个 可执行体.<br>允许向它发起 invoke 调用,它可能是执行一个本地的接口实现,也可能是一个远程的实现,还可能是一个集群实现.</p>
</li>
<li><p>exchange 信息交换层:<br>建立 Request-Response 模型,封装请求响应模式,同步转异步,以 Request, Response 为中心,扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</p>
</li>
<li><p>transport 网络传输层:<br>抽象 mina 和 netty 为统一接口,以 Message 为中心,扩展接口为 Channel, Transporter, Client, Server, Codec</p>
</li>
<li><p>serialize 数据序列化层:<br>若数据要通过网络进行发送,则需要先做序列化,变成二进制流.<br>序列化层负责管理整个框架网络传输时的 序列化/反序列化 工作.<br>可复用的一些工具,扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool</p>
</li>
</ul>
<h1 id="分层关系说明"><a href="#分层关系说明" class="headerlink" title="分层关系说明"></a>分层关系说明</h1><p>在 RPC 中,Protocol 是核心层,也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用,然后在 Invoker 的主过程上 Filter 拦截点.</p>
<p>Consumer 和 Provider 是抽象概念,只是想让看图者更直观的了解哪些类分属于客户端与服务器端,不用 Client 和 Server 的原因是 Dubbo 在很多场景下都使用 Provider, Consumer, Registry, Monitor 划分逻辑拓普节点,保持统一概念.</p>
<p>而 Cluster 是外围概念,所以 Cluster 的目的是将多个 Invoker 伪装成一个 Invoker,这样其它人只要关注 Protocol 层 Invoker 即可,加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响,因为只有一个提<br>供者时,是不需要 Cluster 的.</p>
<p>Proxy 层封装了所有接口的透明化代理,而在其它层都以 Invoker 为中心,只有到了暴露给用户使用时,才用 Proxy 将 Invoker 转成接口,或将接口实现转成 Invoker,也就是去掉 Proxy 层 RPC 是可以 Run 的,只是不那么透明,不那么看起来像调本地服务一样调远程服务.</p>
<p>而 Remoting 实现是 Dubbo 协议的实现,如果你选择 RMI 协议,整个 Remoting 都不会用上,Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层,Transport 层只负责单向消息传输,是对 Mina, Netty, Grizzly 的抽象,它也可以扩展 UDP 传输,而 Exchange 层是在传输层之上封装了 Request-Response 语义.</p>
<p>Registry 和 Monitor 实际上不算一层,而是一个独立的节点,只是为了全局概览,用层的方式画在一起.</p>
<h1 id="包"><a href="#包" class="headerlink" title="包"></a>包</h1><ul>
<li><p>dubbo-common<br>公共逻辑模块:包括 Util 类和通用模型.<br>serialize 层放在 common 模块中,以便更大程度复用.</p>
</li>
<li><p>dubbo-remoting<br>远程通讯模块:相当于 Dubbo 协议的实现,如果 RPC 用 RMI协议则不需要使用此包.<br>transport 层和 exchange 层都放在 remoting 模块中,为 rpc 调用的通讯基础.<br><code>Remoting 实现是 Dubbo 协议的实现</code>,如果你选择 RMI 协议,整个 Remoting 都不会用上,<code>Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层</code>,<br><code>Transport 层只负责单向消息传输</code>,是对 Mina, Netty, Grizzly 的抽象,它也可以扩展 UDP 传输,而 <code>Exchange 层是在传输层之上封装了 Request-Response 语义</code>.</p>
</li>
<li><p>dubbo-rpc<br>远程调用模块:抽象各种协议,以及动态代理,只包含一对一的调用,不关心集群的管理.<br>protocol 层和 proxy 层都放在 rpc 模块中,这两层是 rpc 的核心,在不需要集群也就是只有一个提供者时,可以只使用这两层完成 rpc 调用.</p>
</li>
<li><p>dubbo-cluster<br>集群模块:将多个服务提供方伪装为一个提供方,包括:负载均衡, 容错,路由等,集群的地址列表可以是静态配置的,也可以是由注册中心下发.</p>
</li>
<li><p>dubbo-registry<br>注册中心模块:基于注册中心下发地址的集群方式,以及对各种注册中心的抽象.</p>
</li>
<li><p>dubbo-monitor<br>监控模块:统计服务调用次数,调用时间的,调用链跟踪的服务.</p>
</li>
<li><p>dubbo-config<br>配置模块:是 Dubbo 对外的 API,用户通过 Config 使用Dubbo,隐藏 Dubbo 所有细节.</p>
</li>
<li><p>dubbo-container<br>容器模块:是一个 Standlone 的容器,以简单的 Main 加载 Spring 启动,因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性,没必要用 Web 容器去加载服务.<br>整体上按照分层结构进行分包,与分层的不同点在于:<br>container 为服务容器,用于部署运行服务,没有在层中画出.<br>protocol 层和 proxy 层都放在 rpc 模块中,这两层是 rpc 的核心,在不需要集群也就是只有一个提供者时,可以只使用这两层完成 rpc 调用.<br>transport 层和 exchange 层都放在 remoting 模块中,为 rpc 调用的通讯基础.<br>serialize 层放在 common 模块中,以便更大程度复用.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>git配置shadowsocks</title>
    <url>/2019/11/23/03tool/git/git%E9%85%8D%E7%BD%AEshadowsocks/</url>
    <content><![CDATA[<h3 id="git-配置-shadowsocks"><a href="#git-配置-shadowsocks" class="headerlink" title="git 配置 shadowsocks"></a>git 配置 shadowsocks</h3><p>有时候从github里clone代码速度很慢,尤其是项目很大的时候,配置代理会快很多.<br>git config –global http.postBuffer 524288000</p>
<p>git config –global http.proxy socks5://127.0.0.1:10800<br>其中10800为 shadowsocks 服务器-&gt;编辑服务器 中配置的代理端口</p>
<p>git取消代理<br>git config –global –unset http.proxy</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper事务日志，快照</title>
    <url>/2019/05/07/01no/zk/zk06_snapshot_txnlog/</url>
    <content><![CDATA[<h2 id="ZKDataBase结构"><a href="#ZKDataBase结构" class="headerlink" title="ZKDataBase结构"></a>ZKDataBase结构</h2><p>ZKDataBase(zk内存数据库)<br>    – sessionWithTimeouts(zk所有会话  会话超时时间记录器)<br>    – DataTree存储<br>    – 事务日志</p>
<p>ZKDatabase会定时向磁盘dump快照数据,<br>在zk启动时通过磁盘上的事务日志 和 快照文件 恢复 一个完整的内存数据库</p>
<h2 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h2><p>dataLogDir</p>
<p>文件大小都是64MB</p>
<p>文件名 log.xxx<br>xxx为事务id : zxid, 且 <code>为写入该事务文件第一条事务记录的zxid</code>.</p>
<p>zxid由两部分组成: 高32位 为 当前leader周期(epoch), 低32位 为 真正的操作序列号.</p>
<p>LogFormatter 可以查看该文件</p>
<h3 id="事务日志操作"><a href="#事务日志操作" class="headerlink" title="事务日志操作"></a>事务日志操作</h3><ol>
<li><p>滚动日志<br>FileTxnLog.rollLog()<br>将当前日志文件 滚动为新文件.<br>其实就是将 logStream置为null,那么要写入日志时就会新创建一个日志文件用于写入.</p>
</li>
<li><p>写事务日志<br>FileTxnLog.append(TxnHeader hdr, Record txn)</p>
</li>
</ol>
<p>若logStream == null, 代表要新创建一个事务日志文件.则根据根据事务头里的 zxid创建事务文件名.<br>创建事务日志文件头信息(魔数,版本,dbId),序列化成fileheader,刷新到磁盘.</p>
<p>填充文件.</p>
<p>将 事务头 和 事务数据 序列化成 Byte Buffer,生成一个验证算法,将序列化的事务记录写入OutputArchive.</p>
<h3 id="事务日志写入时机"><a href="#事务日志写入时机" class="headerlink" title="事务日志写入时机"></a>事务日志写入时机</h3><p>SyncRequestProcessor.run()里面调用</p>
<h3 id="事务日志文件的磁盘空间预分配"><a href="#事务日志文件的磁盘空间预分配" class="headerlink" title="事务日志文件的磁盘空间预分配"></a>事务日志文件的磁盘空间预分配</h3><p>事务日志文件大小默认均为64MB,文件大小是预分配的,用”0”填充的,每个事务日志都会及时记录到里面,相当于修改这部分文件.</p>
<p>这样做的好处:</p>
<p>对于客户端的每一次事务操作,zk都会将其写入事务日志文件中.</p>
<p>事务日志的写入性能直接决定了zk事务请求的响应.</p>
<p>事务写入近似可以被看做是一个磁盘I/O的过程.</p>
<p>文件的不断追加写入操作会触发底层磁盘I/O为文件开辟新的磁盘块,即磁盘seek.</p>
<p>为了避免磁盘Seek的频率,提高磁盘I/O效率.zk创建事务日志的时候就会进行文件空间预分配,默认64MB.</p>
<p>一旦已分配的文件空间不足4kb,会再次预分配,以避免随着每次事务的写入过程中文件大小增长带来的seek开销,直至创建新的事务日志.</p>
<p>事务日志”预分配”的大小可以通过系统属性 <code>zookeeper.preAllocSize</code> 来设置.</p>
<p>根据序列化产生的字节数组来计算Checksum,保证事务文件的完整性 和 准确性.</p>
<p>写入流 -&gt; 最后将流刷盘.</p>
<h2 id="snapshot"><a href="#snapshot" class="headerlink" title="snapshot"></a>snapshot</h2><p>snapshot 用于记录zk服务器上某个时刻的<code>全量内存数据</code>,并将其写入到指定的磁盘文件中.</p>
<p>dataDir<br>文件名 snapshot.xxxx<br>每个快照数据文件中的所有内容都是有效的,不会预分配.</p>
<p>SnapshotFormatter 可以查看该文件,该类仅输出每个数据节点的元信息,不输出节点数据内容.</p>
<p>事务操作,zk会记录到事务日志,并且将数据变更应用到内存数据库中.</p>
<p>zk会在进行若干次事务日志记录后,将内存数据库的全量数据 Dump 到本地文件中,即 数据快照.<br>可<code>配置zk在snapCount次事务日志记录后</code>进行一个数据快照.</p>
<h3 id="何时进行快照"><a href="#何时进行快照" class="headerlink" title="何时进行快照"></a>何时进行快照</h3><p>逻辑在 SyncRequestProcessor 类中.<br>logCount &gt; (snapCount / 2 + randRool)<br>如 snapCount 默认配置为<code>10,0000</code> ,zk会在 5,0000 - 10,0000 次事务后进行一次数据快照. </p>
<p>随机数避免集群中所有机器在同一时刻进行数据快照.</p>
<p>snapshot 操作单独在一个异步线程处理,将所有<code>DataTree</code>和<code>会话信息</code>保存到本地磁盘中.</p>
<p>根据当前已提交的 最大ZXID 来生成数据快照文件名.</p>
<p>数据序列化:<br>文件头: 魔数, 版本号, dbid<br>会话信息, DataTree, Checksum</p>
<h2 id="初始化时将-snapshot-和-txnlog-应用到内存数据库"><a href="#初始化时将-snapshot-和-txnlog-应用到内存数据库" class="headerlink" title="初始化时将 snapshot 和 txnlog 应用到内存数据库"></a>初始化时将 snapshot 和 txnlog 应用到内存数据库</h2><p>zk 启动时,会根据 snapshot 和 txnlog 恢复内存数据库.</p>
<p>默认会获取磁盘上最新的100个快照文件,但是时逐个解析的,只有最新的文件校验不通过时,才会解析之前的(相当于 <code>使用最新并可用的那个快照文件</code>).</p>
<p>根据快照文件名 获取 zxid 即 zxid_for_snap.</p>
<p>处理事务日志.<code>从事务日志中获取所有比 zxid_for_snap 大的事务操作</code>.</p>
<p>将事务应用到 ZKDatabase 和 sessionWithTimeouts 中.</p>
<p>zk每应用一个事务日志,会回调 PlayBackListener 监听器,将这个事务操作转换成Proposal,保存到 ZKDatabase.committedLog 中,以便启动选举出 leader 后 follower 同步 leader 的数据.</p>
<p>zxid : zookeeper事务id<br>epoch : 标识当前leader周期,每次选举产生一个新的leader服务器后,都会生产一个新的epoch.</p>
<h2 id="snapshot-txnlog-如何保证全量数据"><a href="#snapshot-txnlog-如何保证全量数据" class="headerlink" title="snapshot + txnlog 如何保证全量数据"></a>snapshot + txnlog 如何保证全量数据</h2><p>一个全量的内存数据库.它包含</p>
<ol>
<li>一个最新的可用的快照(假设它的文件名为zxid_for_snap)</li>
<li>事务id大于等于该 zxid_for_snap 的所有事务日志</li>
<li>事务id小于该 zxid_for_snap 的那个最新的事务日志(比如在往这个事务文件里写事务日志,写着写着进行了快照操作,但是由于这个事务日志还没写满,所以会接着往这里面写事务日志)</li>
</ol>
<h2 id="配置项-zookeeper-snapCount"><a href="#配置项-zookeeper-snapCount" class="headerlink" title="配置项 zookeeper.snapCount"></a>配置项 zookeeper.snapCount</h2><p>zookeeper.snapCount 必须 &gt;= 2,若小于2会被置为2,默认不配置则取 10,0000</p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper应用</title>
    <url>/2019/05/07/01no/zk/zk07_useage/</url>
    <content><![CDATA[<h2 id="dubbo中zk的应用"><a href="#dubbo中zk的应用" class="headerlink" title="dubbo中zk的应用"></a>dubbo中zk的应用</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">在zk中创建的节点路径</span><br><span class="line">dubbo</span><br><span class="line">    com.alibaba.demo.DemoService [服务名,service]</span><br><span class="line">        configurators</span><br><span class="line">        consumers [类型,type,生产者消费者]</span><br><span class="line">            ...</span><br><span class="line">        providers</span><br><span class="line">            ... [url]</span><br><span class="line">        routers</span><br></pre></td></tr></table></figure>
<p>其中接口(service)下会有四个子节点providers, consumers, routers, configurators</p>
<p>其中dubbo、接口、providers都是持久化节点，只有url是临时节点。当会话消失(服务器断开与zookeeper的连接)，对应的临时节点会被删除。</p>
<p>dubbo-registry-zookeeper模块中, ZookeeperRegistry 类继承自 FailbackRegistry.<br>构造方法中通过 ZookeeperTransporter.connect(url)连接到zookeeper.</p>
<p>1.服务提供者进行服务暴露时,会注册到注册中心注册自己<br>2.父类 FailbackRegistry 失败重试<br>3.服务消费者进行服务引用时,会注册自己并且订阅 所有服务提供者.消费者会订阅接口下的 providers 的所有子节点。一旦 providers 下的子节点发生改变，就会通知消息给消费者。</p>
<p>父类 FailbackRegistry 支持失败重试<br>起一个定时任务,遍历 失败发起注册失败的 URL 集合,向zk注册(创建节点)</p>
<p>dubbo-remoting-zookeeper模块中,提供zk传输的支持<br>ZookeeperTransporter提供了 ZkClient 和 Curator 两种实现.</p>
<p>消费者引用服务 或 提供者暴露服务时,会往zookeeper上注册节点<br>主要做了以下几步： </p>
<ol>
<li>记录注册注册地址 </li>
<li>注册节点到zookeeper上 </li>
<li>捕捉错误信息，出错则记录下来，等待定期器去重新执行</li>
</ol>
<h3 id="发布"><a href="#发布" class="headerlink" title="发布"></a>发布</h3><p>provider注册<br>RegistryProtocol.export()中<br>1.获得注册中心对象,启动并连接zk</p>
<p>2.向注册中心订阅服务消费者</p>
<p>3.向注册中心注册服务提供者(自己),其实就是在zk中创建该提供者的持久化节点 /dubbo/com.alibaba.dubbo.demo.DemoService/providers/…<br>然后注册监听器</p>
<p>AbstractRegistry构造方法中<br>加载本地配置文件 dubbo-registry-demo-provider-127.0.0.1:2181.cache</p>
<p>FallbackRegistry构造方法中<br>创建重试定时任务并启动</p>
<p>ZookeeperRegistry构造方法中<br>连接zk<br>zkClient.addStateListener().该监听器在重连时,调用 recover() 恢复方法</p>
<h3 id="订阅"><a href="#订阅" class="headerlink" title="订阅"></a>订阅</h3><p>消费者订阅 和 生产者发布 类似</p>
<h3 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h3><p>notify()时会将zk节点信息写入到缓存,根据配置的策略选择直接保存文件还是用1个线程异步保存文件.</p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper Processor</title>
    <url>/2019/03/08/01no/zk/zk05_processor/</url>
    <content><![CDATA[<h3 id="processors"><a href="#processors" class="headerlink" title="processors"></a>processors</h3><ul>
<li><p>PrepRequestProcessor<br>通常是请求处理链的第一个处理器.<br>识别客户端请求是否是事务请求.对于事务请求,做预处理,诸如 创建请求事务头,事务体,会话检查,ACL检查 和 版本检查 等.</p>
</li>
<li><p>ProposalRequestProcessor<br>leader 服务器的<code>事务投票处理器</code>,也是 leader 服务器事务处理流程的发起者.<br>对于 非事务请求,它会直接将请求流转到 CommitProcessor 处理器,不再做其他处理.<br>对于 事务请求,除了将请求交给CommitProcessor处理器外,还会根据请求类型创建对应的 Proposal 提议,并 发给所有 Follower 来发起一次集群内的事务投票.它还会将事务请求交给 SyncRequestProcessor 进行事务日志的记录.</p>
</li>
<li><p>SyncRequestProcessor<br>事务日志记录处理器,将事务请求记录到事务日志文件中,同时还会触发zk进行数据快照.<br>发送Sync请求的处理器.将请求记录到磁盘.它批量处理有效执行io的请求.在将日志同步到磁盘之前,请求不会传递到下一个 Processor.<br>维护了一个处理请求的队列,其用于存放请求;<br>维护了一个处理快照的线程,用于处理快照;<br>维护了一个等待被刷新到磁盘的请求队列.<br>将事务性请求刷新到磁盘,并且对请求进行快照处理.</p>
</li>
<li><p>AckRequestProcessor<br>leader 独有的处理器,它负责在 SyncRequestProcessor 处理器完成事务日志记录后,向 Proposal 的投票收集器发送 ACK 反馈,以通知投票收集器当前服务器已经完成了对该 Proposal 的事务日志记录.<br>将前一阶段的请求作为 ACK 转发给 Leader.</p>
</li>
<li><p>CommitProcessor<br>事务提交处理器.<br>对于非事务请求,该处理器直接将其交给下一个处理器进行处理.<br>对于事务请求,它会等待集群内 针对 Proposal 的投票,直到该 Proposal 可被提交.</p>
</li>
<li><p>ToBeAppliedRequestProcessor<br>维护 toBeApplied 队列,专门存储那些已经被 CommitProcessor 处理过的可被提交的 Proposal.<br>它将这些请求逐个交付给 FinalRequestProcessor 处理器进行处理,等待 FinalRequestProcessor 处理器处理完后,再将其从toBeApplied 队列中移除.<br>下个处理器必须是 FinalRequestProcessor 并且 FinalRequestProcessor 必须同步处理请求.</p>
</li>
<li><p>FinalRequestProcessor<br>通常是请求处理链的最后一个处理器.<br>创建客户端请求的响应;针对事务请求,它还会负责<code>将事务应用到内存数据库</code>中.</p>
</li>
<li><p>FollowerRequestProcessor<br>它是 follower 的第一个请求处理器.用于识别当前请求是否是事务请求.<br>若是事务请求,转发给 leader 服务器.leader 在收到这个事务请求后,就会将其提交到请求处理器链,按照正常事务请求进行处理.</p>
</li>
<li><p>ObserverRequestProcessor<br>同 FollowerRequestProcessor 一样,将事务请求转发给 Leader.</p>
</li>
<li><p>SendAckRequestProcessor<br>follower 独有,发送 ACK 请求的处理器.<br>在 follower 完成事务日志记录后,会向 leader 服务器发送 ACK 消息表面自身完成了事务日志的记录工作.<br>它和 leader 的 AckRequestProcessor 的区别:<br>AckRequestProcessor 处理器和 leader 服务器在同一个服务器上,它的 ACK 反馈仅仅是一个本地操作.<br>SendAckRequestProcessor 处理器在 follower 服务器上,需要通过 ACK 消息向 leader 服务器进行反馈.</p>
</li>
</ul>
<h3 id="processor链对事务请求的处理"><a href="#processor链对事务请求的处理" class="headerlink" title="processor链对事务请求的处理"></a>processor链对事务请求的处理</h3><h4 id="PrepRequestProcessor"><a href="#PrepRequestProcessor" class="headerlink" title="PrepRequestProcessor"></a>PrepRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- PrepRequestProcessor </span><br><span class="line">    - 作用</span><br><span class="line">        - 通常是请求处理链的第一个处理器。 </span><br><span class="line">        - 识别客户端请求是否是事务请求. 对于事务请求,做预处理,诸如 创建请求事务头,事务体,会话检查,ACL检查 和 版本检查 等.</span><br><span class="line">    - run()逻辑</span><br><span class="line">        - pRequest(request);中 判断请求类型. 对于事务请求,不同类型请求对应不同操作. 比如create请求</span><br><span class="line">        - CreateRequest createRequest &#x3D; new CreateRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, createRequest, true);</span><br><span class="line">            - pRequest2Txn()中 new TxnHeader() 创建请求事务头,后续的processors都是基于该请求头来识别当前请求是否是事务请求</span><br><span class="line">            - zks.sessionTracker.checkSession(request.sessionId, request.getOwner());&#x2F;&#x2F; session检查</span><br><span class="line">            - 请求数据反序列化到CreateRequest对象中</span><br><span class="line">            - 添加到zks.outstandingChanges中 &#x2F;&#x2F; TODO finalRequestProcessor中会用到 addChangeRecord(parentRecord); addChangeRecord(new ChangeRecord(request.hdr.getZxid(), path, s, 0, listACL));</span><br><span class="line">        - nextProcessor.processRequest(request); 交由下个processor处理</span><br><span class="line">            - ProposalRequestProcessor.processRequest() &#x2F;&#x2F; 参见ProposalRequestProcessor.processRequest()逻辑</span><br></pre></td></tr></table></figure>
<h4 id="ProposalRequestProcessor"><a href="#ProposalRequestProcessor" class="headerlink" title="ProposalRequestProcessor"></a>ProposalRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ProposalRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - leader服务器的&#96;事务投票处理器&#96;,也是leader服务器事务处理流程的发起者. </span><br><span class="line">        - 对于 非事务请求,它会直接将请求流转到CommitProcessor处理器,不再做其他处理. </span><br><span class="line">        - 对于 事务请求,除了将请求交给CommitProcessor处理器外,还会根据请求类型创建对应的Proposal提议,并发给所有Follower来发起一次集群内的事务投票.它还会将事务请求交给SyncRequestProcessor进行事务日志的记录.</span><br><span class="line"></span><br><span class="line">    - ProposalRequestProcessor.processRequest()中</span><br><span class="line">        - nextProcessor.processRequest(request); 1.将请求交给下个处理器进行处理,下个处理器是commitProcessor,走COMMIT流程</span><br><span class="line">            - commitProcessor.processRequest()中 queuedRequests.add(request); 将请求 添加到 请求队列</span><br><span class="line">                - leader的commitProcessor处理</span><br><span class="line">        - 若是事务请求</span><br><span class="line">            - zks.getLeader().propose(request); 2.若是事务请求,发proposal包,发起PROPOSAL流程</span><br><span class="line">                - leader.propose()中 outstandingProposals.put(lastProposed, p); 将事务请求放入outstandingProposals,它用于保存 zxid 和 proposal的映射</span><br><span class="line">                - 发送Leader.PROPOSAL包  sendPacket(pp);</span><br><span class="line">                    - leader.sendPacket()中 遍历所有LearnerHandler,依次调用,将proposal包存入待发送队列 f.queuePacket(qp);</span><br><span class="line">                        - learnerHandler.queuePacket()中 queuedPackets.add(p) 将包存入队列</span><br><span class="line">                            - learnerHandler线程</span><br><span class="line">                                - learnerHandler.run()里 512行 新启一个线程 发送queuedPackets队列中的packets</span><br><span class="line">                                    -  sendPackets();&#x2F;&#x2F; 发送queuedPackets队列中的packets  if (p.getType() &#x3D;&#x3D; Leader.PROPOSAL) &#123;    syncLimitCheck.updateProposal(p.getZxid(), System.nanoTime()); &#125;</span><br><span class="line">                                    - oa.writeRecord(p, &quot;packet&quot;); 发送packet</span><br><span class="line">                                        - Follower.processPacket()接收该Proposal包</span><br><span class="line">                                            - Follower.processPacket()中</span><br><span class="line">                                            - 反序列化请求数据</span><br><span class="line">                                            - fzk.logRequest(hdr, txn);</span><br><span class="line">                                                - FollowerZookeeperServer.logRequest()中 pendingTxns.add(request);请求入pendingTxns队列 &#x2F;&#x2F; TODO 这个入队后面干嘛了</span><br><span class="line">                                                - syncProcessor.processRequest(request);</span><br><span class="line">                                                    - SyncRequestProcessor.processRequest()中 queuedRequests.add(request); 请求入队列</span><br><span class="line">                                                        - follower将poposal中的请求持久化 &#x2F;&#x2F; 后续见SyncRequestProcessor.run()逻辑</span><br></pre></td></tr></table></figure>
<h4 id="syncProcessor"><a href="#syncProcessor" class="headerlink" title="syncProcessor"></a>syncProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- syncProcessor.processRequest(request); 3.若是事务请求,交给 syncProcessor处理器记录事务日志,走SYNC流程</span><br><span class="line">    - 这里是leader服务器进行事务持久化操作, follower服务器会通过上面2中的proposal流程最终触发follower自己的事务持久化操作 即事务持久化在所有follower和leader上都会进行</span><br><span class="line">        - 事务持久化完成后会发ack给leader</span><br></pre></td></tr></table></figure>
<h4 id="SyncRequestProcessor"><a href="#SyncRequestProcessor" class="headerlink" title="SyncRequestProcessor"></a>SyncRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- SyncRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - 事务日志记录处理器, 将事务请求记录到事务日志文件中,同时还会触发zk进行数据快照.</span><br><span class="line">        - 发送Sync请求的处理器。将请求记录到磁盘。它批量处理有效执行io的请求。在将日志同步到磁盘之前，请求不会传递到下一个RequestProcessor. </span><br><span class="line">    - 成员变量</span><br><span class="line">        - 维护了一个处理请求的队列queuedRequests，其用于存放请求</span><br><span class="line">        - 维护了一个处理快照的线程 snapInProcess，用于处理快照</span><br><span class="line">        - 维护了一个等待被刷新到磁盘的请求队列 toFlush </span><br><span class="line"></span><br><span class="line">    - SyncRequestProcessor.processRequest()逻辑</span><br><span class="line">        - queuedRequests.add(request); 事务请求入队列 private final LinkedBlockingQueue&lt;Request&gt; queuedRequests &#x3D;         new LinkedBlockingQueue&lt;Request&gt;();&#x2F;&#x2F; 请求队列</span><br><span class="line"></span><br><span class="line">    - SyncRequestProcessor.run()逻辑</span><br><span class="line">        - 初始化事务日志记录计数logCount,用于判断记录 n次事务日志后 是否需要进行 snapshot</span><br><span class="line">        - 初始化设置滚动日志的随机数randRoll,该随机数用于防止所有servers在同一时刻进行snapshot操作</span><br><span class="line">        - while循环</span><br><span class="line">            - si &#x3D; queuedRequests.poll(); 从队列中取出请求.</span><br><span class="line">                - 若请求队列中的请求取完了,刷盘</span><br><span class="line">                    - flush(toFlush);</span><br><span class="line">                        - SyncRequestProcessor.flush()中 zks.getZKDatabase().commit();刷盘</span><br><span class="line">                        - 刷盘结束后发ack,循环取出所有toFlush的nextProcessor. 并调用nextProcessor.processRequest()方法</span><br><span class="line">                            - 1.leader调AckRequestProcessor,省去通信了 AckRequestProcessor.processRequest()中 leader.processAck(self.getId(), request.zxid, null);&#x2F;&#x2F; ack给leader</span><br><span class="line">                                - &#x2F;&#x2F; 参见AckRequestProcessor.processRequest()逻辑</span><br><span class="line">                            - 2.follower调SendAckRequestProcessor</span><br><span class="line">                                - &#x2F;&#x2F; 参见SendAckRequestProcessor逻辑</span><br><span class="line">                - 若取出来的请求不为空</span><br><span class="line">                    - (zks.getZKDatabase().append(si))  将请求添加至事务日志文件</span><br><span class="line">                        - ZKDatabase.append()中 return this.snapLog.append(si);</span><br><span class="line">                            - FileTxnSnapLog.append()中 return txnLog.append(si.hdr, si.txn);</span><br><span class="line">                                - FileTxnLog.append()中 logStream.flush(); &#x2F;&#x2F; 刷新到磁盘 返回true</span><br><span class="line">                    - 如果事务日志记录次数达到了snapCount &#x2F; 2 + randRoll次,新起线程进行snapshot操作,并重置logCount计数</span><br><span class="line">                    - toFlush.add(si); 将请求添加至 toFlush队列</span><br><span class="line">                    - toFlush队列大小 大于1000，直接刷新到磁盘</span><br></pre></td></tr></table></figure>
<h4 id="AckRequestProcessor"><a href="#AckRequestProcessor" class="headerlink" title="AckRequestProcessor"></a>AckRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- AckRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - leader独有的处理器,它负责在SyncRequestProcessor处理器完成事务日志记录后,向Proposal的投票收集器发送ACK反馈,以通知投票收集器当前服务器已经完成了对该Proposal的事务日志记录.</span><br><span class="line"></span><br><span class="line">    - AckRequestProcessor.processRequest()逻辑</span><br><span class="line">        - 1.leader调AckRequestProcessor,省去通信了 AckRequestProcessor.processRequest()中 leader.processAck(self.getId(), request.zxid, null);&#x2F;&#x2F; ack给leader</span><br></pre></td></tr></table></figure>
<h4 id="SendAckRequestProcessor"><a href="#SendAckRequestProcessor" class="headerlink" title="SendAckRequestProcessor"></a>SendAckRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- SendAckRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - follower使用,用于follower将proposal中的request持久化后发ack给leader</span><br><span class="line"></span><br><span class="line">    - SendAckRequestProcessor.processRequest()逻辑</span><br><span class="line">        - SendAckRequestProcessor.processRequest()中 创建Leader.ACK包并发送 learner.writePacket(qp, false);</span><br><span class="line">            - LearnerHandler线程</span><br><span class="line">                - LearnerHandler.run()中 当Follower收到PROPOSAL并写到磁盘后会发送ACK给Leader case Leader.ACK:  leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());</span><br><span class="line">                    - leader.processAck()中  处理ack包</span><br><span class="line">                    - 1.根据zxid取出proposal Proposal p &#x3D; outstandingProposals.get(zxid);</span><br><span class="line">                    - p.ackSet.add(sid); 2.保存follower发来的ack的sid到该proposal对象中</span><br><span class="line">                    - 判断self.getQuorumVerifier().containsQuorum(p.ackSet) 3.判断当接收到的对于 proposal包的ack是否超过一半</span><br><span class="line">                        - QuorumMaj.containsQuorum()中 验证所给集合大小是否超过半数 return (set.size() &gt; half);</span><br><span class="line">                    - 4.若此处leader接收到的对于该proposal包的ack数超过了一半</span><br><span class="line">                        - outstandingProposals.remove(zxid); 1.移除proposal</span><br><span class="line">                        - toBeApplied.add(p); 2.将proposal添加到toBeApplied队列</span><br><span class="line">                            - 这个toBeApplied队列中的元素会在Leader.ToBeAppliedRequestProcessor.processRequest()中取出来 &#x2F;&#x2F; 参见ToBeAppliedRequestProcessor.processRequest()逻辑</span><br><span class="line">                        - commit(zxid); 3.创建Leader.COMMIT包并发给所有follower</span><br><span class="line">                            - leader.commit()中 遍历所有LearnerHandler,将所有Leader.COMMIT包加入queuedPackets队列. 用于给followers发.</span><br><span class="line">                                - ...</span><br><span class="line">                                    - learnerHandler线程里,取出COMMIT包发给follower learnerHandler.sendPackets()里 会取queuedPackets队列中的所有packets并发送</span><br><span class="line">                                        - ...</span><br><span class="line">                                            - follower.processPacket()中,接收到COMMIT包后并处理.COMMIT包里只包含zxid信息,因为其他信息已经在之前的proposal包里包含了.  若是COMMIT包,调fzk.commit(qp.getZxid()); case Leader.COMMIT: fzk.commit(qp.getZxid()); break;</span><br><span class="line">                                                - FollowerZookeeperServer.commit(long zxid)中 取出COMMIT包交由commitProcessor处理</span><br><span class="line">                                                - long firstElementZxid &#x3D; pendingTxns.element().zxid; 1.从待处理的事务队列pendingTxns中取出来第一个元素,判断它和commit包中的zxid是否一致</span><br><span class="line">                                                - 2.从队列中移除后,交由follower的commitProcessor进行处理 Request request &#x3D; pendingTxns.remove(); commitProcessor.commit(request);</span><br><span class="line">                                                    - &#x2F;&#x2F; 参见commitProcessor.commit(request);逻辑</span><br><span class="line">                        - inform(p); 4.创建Leader.INFORM包,发送给所有observers</span><br><span class="line">                            - 由于observer服务器未参加之前的提议投票, 因此observer服务器尚未保存任何关于该提议的消息, 所有在广播commit消息时,需要区别对待, leader会向其发送INFORM消息,该消息体重包含了当前提议的内容.</span><br><span class="line">                        - zk.commitProcessor.commit(p.request);&#x2F;&#x2F; commit</span><br><span class="line">                            - 调用leader的commitProcessor.commit()方法</span><br></pre></td></tr></table></figure>
<h4 id="CommitProcessor"><a href="#CommitProcessor" class="headerlink" title="CommitProcessor"></a>CommitProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- CommitProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - 事务提交处理器. </span><br><span class="line">        - 对于非事务请求,该处理器直接将其交给下一个处理器进行处理. </span><br><span class="line">        - 对于事务请求,它会等待集群内 针对Proposal的投票 直到该Proposal可被提交. </span><br><span class="line">        - 利用它,每个服务器都能很好的控制对事务请求的顺序处理. </span><br><span class="line">        - 其实就是对于事务请求,commitProcessor会保证它这个事务请求必须经过proposal包和commit包之后,才会将它放入toProcess队列交给下个processor进行处理</span><br><span class="line">    - 变量</span><br><span class="line">        - queuedRequests</span><br><span class="line">            - queuedRequests 中的请求是在proposalRequestProcessor.processRequest()中加入进来的. 这些请求当时还没有进行proposal和commit包的处理</span><br><span class="line">        - committedRequests</span><br><span class="line">            - committedRequests中的请求时在执行完proposal和commit包后加入进来的</span><br><span class="line">        - toProcess</span><br><span class="line">            - queuedRequests队列中 所有非事务请求添加到 toProcess队列,用于交给下个processor处理</span><br><span class="line">        - nextPending</span><br><span class="line">            - queuedRequests队列中 下一个等待处理的事务请求</span><br><span class="line"></span><br><span class="line">    - commitProcessor.processRequest()逻辑</span><br><span class="line">        - 请求入queuedRequests队列. leader 和 所有 follower 在 ProposalRequestProcessor 中 都会调用该方法.  queuedRequests 中的请求是在 proposalRequestProcessor.processRequest()中加入进来的.这些请求当时还没有进行 proposal 和 commit包的处理  queuedRequests.add(request);&#x2F;&#x2F; 将请求 添加到 请求队列 notifyAll();</span><br><span class="line"></span><br><span class="line">    - commitProcessor.commit(request)逻辑</span><br><span class="line">        - 当leader完成了proposal过半,给followers发commit包之后,自己也会走commit逻辑. follower收到commit包也会走自己的commit逻辑.</span><br><span class="line">        - 完成proposal和commit包的请求入committedRequests队列 committedRequests.add(request); notifyAll();</span><br><span class="line"></span><br><span class="line">    - commitProcessor.run()逻辑</span><br><span class="line">        - 1.依次调用toProcess队列中每个request的nextProcessor,并清空队列</span><br><span class="line">            - &#x2F;&#x2F; 参见Leader.ToBeAppliedRequestProcessor.processRequest() nextProcessor.processRequest(toProcess.get(i));</span><br><span class="line">        - 2.queuedRequests队列已经取完了,或nextPending已经设置值了 (其实就是在queuedRequest队列中已经找到了一个需要处理的事务请求)</span><br><span class="line">            - 此时若committedRequests为空(即还没收到要commit的请求), 线程wait(),跳出此次循环</span><br><span class="line">            - 2.2 若有commit请求</span><br><span class="line">                - 取出commit请求  Request r &#x3D; committedRequests.remove(); 并和nextPending比较,二者应该一致. 赋值事务头,加入toProcess队列 toProcess.add(nextPending);</span><br><span class="line">        - 3.只要nextPending有值,就不走4的逻辑</span><br><span class="line">        - 4.遍历queuedRequests队列,从里面取出第一个事务请求给nextPending赋值</span><br></pre></td></tr></table></figure>
<h4 id="ToBeAppliedRequestProcessor"><a href="#ToBeAppliedRequestProcessor" class="headerlink" title="ToBeAppliedRequestProcessor"></a>ToBeAppliedRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ToBeAppliedRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - 维护toBeApplied队列,专门存储那些已经被CommitProcessor处理过的可被提交的Proposal</span><br><span class="line">        - 它将这些请求逐个交付给FinalRequestProcessor处理器进行处理,等待FinalRequestProcessor处理器处理完后,再将其从toBeApplied队列中移除. </span><br><span class="line">        - 下个处理器必须是FinalRequestProcessor并且FinalRequestProcessor必须同步处理请求。</span><br><span class="line">    - 变量</span><br><span class="line">        - toBeApplied队列</span><br><span class="line">            - 元素放入:leader接收到的对于该proposal包的ack数超过了一半时便会放入</span><br><span class="line">            - 元素取出:ToBeAppliedRequestProcessor.processRequest()取出交给finalRequestProcessor进行处理</span><br><span class="line"></span><br><span class="line">    - Leader.ToBeAppliedRequestProcessor.processRequest()</span><br><span class="line">        - 取出请求,调next,并移除 next.processRequest(request); toBeApplied.remove();</span><br><span class="line">            - &#x2F;&#x2F; 参见FinalRequestProcessor.processRequest()逻辑</span><br></pre></td></tr></table></figure>
<h4 id="FinalRequestProcessor"><a href="#FinalRequestProcessor" class="headerlink" title="FinalRequestProcessor"></a>FinalRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- FinalRequestProcessor</span><br><span class="line">    - 作用</span><br><span class="line">        - 通常是请求处理链的最后一个处理器。 </span><br><span class="line">        - 创建客户端请求的响应;针对事务请求,它还会负责将事务应用到内存数据库中.</span><br><span class="line">        </span><br><span class="line">    - FinalRequestProcessor.processRequest()</span><br><span class="line">        - 1.遍历zks.outstandingChanges(提交的事务请求),zxid比request.zxid小的请求都给干掉.</span><br><span class="line">        - 2.若是事务请求应用到内存数据库 if (request.hdr !&#x3D; null)  rc &#x3D; zks.processTxn(hdr, txn);</span><br><span class="line">            - rc &#x3D; getZKDatabase().processTxn(hdr, txn);</span><br><span class="line">                - 事务写到内存  return dataTree.processTxn(hdr, txn);</span><br><span class="line">        - zks.getZKDatabase().addCommittedProposal(request); 3.事务请求保存到 committedLog</span><br><span class="line">        - 4.根据请求code,创建response响应客户端  rsp &#x3D; new CreateResponse(rc.path); cnxn.sendResponse(hdr, rsp, &quot;response&quot;);</span><br><span class="line">            - &#x2F;&#x2F; 事务请求结束</span><br></pre></td></tr></table></figure>
<h4 id="FollowerRequestProcessor"><a href="#FollowerRequestProcessor" class="headerlink" title="FollowerRequestProcessor"></a>FollowerRequestProcessor</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- FollowerRequestProcessor</span><br><span class="line">    - 它是follower的第一个请求处理器.用于识别当前请求是否是事务请求. </span><br><span class="line">    - 若是事务请求,转发给leader服务器.leader在收到这个事务请求后,就会将其提交到请求处理器链,按照正常事务请求进行处理.</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper选举流程</title>
    <url>/2019/02/18/01no/zk/zk03_vote/</url>
    <content><![CDATA[<h3 id="leader选举相关线程"><a href="#leader选举相关线程" class="headerlink" title="leader选举相关线程"></a>leader选举相关线程</h3><p>QuorumCnxManager : 管理者,包含发送 和 接收 队列.持有 listener.</p>
<p>QuorumCnxManager.Listener : 监听 并 建立 server 之间的连接.</p>
<p>FastLeaderElection.Messenger.SendWorker<br>消息生产者.循环 从发送队列 queueSendMap 中取消息(出队)并发送出去.并将该消息存入 lastMessageSent 中.</p>
<p>FastLeaderElection.Messenger.RecvWorker<br>消息消费者.循环 接收线程从底层 Socket 收到报文后放到 recvQueue 队列中,等待 Messenger 调用 pollRecvQueue 方法获取消息.</p>
<h3 id="leader选举流程"><a href="#leader选举流程" class="headerlink" title="leader选举流程"></a>leader选举流程</h3><p>启动时选举<br>选举算法的创建之前先创建 QuorumCnxManager,它通过 TCP 协议来进行 leader 选举.<br>每一对server之间都会保持一个TCP链接.<br><code>zookeeper服务之间都是配置myid大的作为客户端连接,myid小的作为服务器端</code>.<br>创建server端的发送线程和接收线程.</p>
<p>投票默认先投自己,投票信息包括(sid,zxid,echo),将投票信息入待发送队列,等待sendWorker线程将投票发送给所有其他server.</p>
<p>下面一直循环操作,直到选出Leader为止.<br>从接收队列中取出接收到的投票,校验投票信息中的sid和所投票的leader.</p>
<p>将接收到的投票 和 自己的投票 pk.<br>比较优先级 <code>epoch &gt; zxid &gt; sid</code>.<br>判断投票消息里的 epoch 周期是不是比当前的大,如果大则消息中id对应的服务器就是leader.<br>若epoch相等则判断zxid,如果消息里的zxid大,则消息中id对应的服务器就是leader.<br>若前面两个都相等那就比较服务器id,若大,则其就是leader.</p>
<p>更新自己的投票,再向集群中所有机器发出去.</p>
<p>每次投票后,当前服务器都会统计本轮接收到的所有投票(recvset中投票一致数),若有过半机器接收到了相同的投票信息,则认为选出了leader.</p>
<p>变更状态,following 或 leading.</p>
<p>leader挂了选举<br>其余非Observer服务器都会将自己状态变更为 LOOKING,进入leader选举流程.</p>
<h3 id="QuorumPeer-线程逻辑"><a href="#QuorumPeer-线程逻辑" class="headerlink" title="QuorumPeer 线程逻辑"></a>QuorumPeer 线程逻辑</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- QuorumPeer线程run()逻辑 用来进行选举，以及选举后进入各角色，角色被打破重新再进行选举</span><br><span class="line">    - 无限循环判断状态 while (running)</span><br><span class="line">        - 若是LOOKING状态 选举模式，启动FastLeaderElection. 进行选举,并设置投票. 选举策略,默认为FastLeaderElection. setCurrentVote(makeLEStrategy().lookForLeader()); 结束选举后,确定各个server的状态,下一轮循环时,则会走下面的各个角色的启动逻辑</span><br><span class="line">            - FastLeaderElection.lookForLeader()中 开始新一轮leader选举。每当我们的QuorumPeer将其状态更改为LOOKING时， 都会调用此方法，并向所有其他server发送通知。 </span><br><span class="line">            - HashMap&lt;Long, Vote&gt; recvset recvset用于记录当前服务器在本轮次的Leader选举中收到的所有外部投票  HashMap&lt;Long, Vote&gt; outofelection  更新逻辑时钟.每进行一轮选举,都需要更新逻辑时钟 logicalclock.incrementAndGet();  更新选票(选自己,sid, zxid, epoch) updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch());  向其他服务器发送自己的选票 sendNotifications();</span><br><span class="line">            - loop:如果是竞选状态则一直循环(本服务器状态为LOOKING并且还未选出leader), 直到选举出结果</span><br><span class="line">                - 若未接收到其他服务器发送的选票 if(n &#x3D;&#x3D; null) &#123;&#125;</span><br><span class="line">                    - if(manager.haveDelivered())&#123;&#x2F;&#x2F; manager已经发送了所有选票消息(发送队列已经为空)     sendNotifications();&#x2F;&#x2F; 向所有其他服务器发送消息 &#125;</span><br><span class="line">                        - FastLeaderElection.sendNotifications()中 遍历所有sid(投票参与者集合),分别创建 投票信息. 将创建的所有投票信息存入投票发送队列,用于保存待发送的选票. (一个投票信息 会创建sid个消息,用于发送给所有的server) sendqueue.offer(notmsg);</span><br><span class="line">                    - else &#123;&#x2F;&#x2F; 还未发送完所有投票消息   manager.connectAll();&#x2F;&#x2F; 连接其他每个服务器 &#125;</span><br><span class="line">                        - QuorumCnxManager.connectAll()中 final ConcurrentHashMap&lt;Long, ArrayBlockingQueue&lt;ByteBuffer&gt;&gt; queueSendMap; &#x2F;&#x2F; sid -&gt; buffer queue,消息发送队列，用于保存那些待发送的消息，按照SID进行分组 遍历queueSendMap,分别connectOne(sid);</span><br><span class="line">                            - QuorumCnxManager.connectOne(sid) 尝试使用其electionAddr与id sid建立与服务器的连接。 本server作为客户端向sid的server发起链接请求. 若两个server间未建立连接(即ConcurrentHashMap&lt;Long, SendWorker&gt; senderWorkerMap查不到), 则建立socket连接(默认同步)</span><br><span class="line">                - 校验投票信息中的sid和所投票的leader. 若投票者servers集合中 包含 接收到消息中的服务器id 和 n.leader(投票消息中的leader) else if (validVoter(n.sid) &amp;&amp; validVoter(n.leader)) &#123;&#125;</span><br><span class="line">                    - 判断给当前server发投票信息的sender的状态 若是FOLLOWING状态</span><br><span class="line">                        - 1.若选票中的推选者(sender)的选举周期 大于 当前的 逻辑时钟(说明是新一轮选举中的选票),则替换选票并发送消息</span><br><span class="line">                            - 更新(重新设置)自身的逻辑时钟,清空投票信息.</span><br><span class="line">                            - 若能选出较优的leader [1],更新选票结果.否则使用自己的投票信息</span><br><span class="line">                                - [1].FastLeaderElection.totalOrderPredicate()中 比较优先级 epoch &gt; zxid &gt; sid 判断消息里的epoch周期是不是比当前的大,如果大则消息中id对应的服务器就是leader. 若epoch相等则判断zxid,如果消息里的zxid大,则消息中id对应的服务器就是leader. 若前面两个都相等那就比较服务器id,若大,则其就是leader.</span><br><span class="line">                        - 2.如果选举周期小于自身的逻辑时钟,说明对方在一个比较早的选举周期中,不作处理 else if (n.electionEpoch &lt; logicalclock.get()) </span><br><span class="line">                        - 3.两者时钟相等,调用totalOrderPredicate()判断是否需要更新当前服务器的选票,若更新了选票就广播给其他服务器 else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch,proposedLeader, proposedZxid, proposedEpoch)) &#123;   updateProposal(n.leader, n.zxid, n.peerEpoch);&#x2F;&#x2F; 更新选票   sendNotifications();&#x2F;&#x2F; 发送消息 &#125;</span><br><span class="line">                        - recvset用于记录 当前服务器 在 本轮次 的 Leader选举中收到的 所有 外部投票 recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch));</span><br><span class="line">                        - 若可以结束选举(判断投票一致数 是否足以结束选举,如大于1&#x2F;2)</span><br><span class="line">                            - 验证提议的leader是否有任何变化,默认等待20毫秒.若无变化则选举结束. (看看接收队列里还有没有新的选票).要是有新的 较优 的选票,则不能结束选举.</span><br><span class="line">                        - 一旦我们没有从接收队列中读取任何新的相关消息,即可结束选举</span><br><span class="line">                            - 设置自身状态 leader or follower or observer</span><br><span class="line">                            - 清空接收队列 recvqueue.clear(),返回投票</span><br><span class="line">                    - 若是OBSERVING状态</span><br><span class="line">                        - 不参与选举,do nothing</span><br><span class="line">                    - 若是FOLLOWING状态</span><br><span class="line">                        - 和下面的LEADING状态逻辑相同</span><br><span class="line">                    - 若是LEADING状态</span><br><span class="line">                        - 若推选者的逻辑时钟和当前server相等 if(n.electionEpoch &#x3D;&#x3D; logicalclock.get())</span><br><span class="line">                            - 将该服务器和选票信息放入recvset中</span><br><span class="line">                            - 判断是否完成了leader选举(投票数超过1&#x2F;2) if(ooePredicate(recvset, outofelection, n)) &#123;&#125;</span><br><span class="line">                                - 设置本server的状态(Leader或follower或observer)</span><br><span class="line">                                - 创建并返回最终投票信息</span><br><span class="line">                                - 清空recvqueue队列的选票</span><br><span class="line">        - 若是OBSERVING状态 启动Observer observer.observeLeader();</span><br><span class="line">        - 若是FOLLOWING状态 启动Follower. follower.followLeader();</span><br><span class="line">            - &#x2F;&#x2F; 参见follower启动逻辑</span><br><span class="line">        - 若是LEADING状态 启动Leader. Leader选举完成之后，Peer确认了自己是Leader的身份，在 QuromPeer的主线程中执行Leader的逻辑 setLeader(makeLeader(logFactory)); &#x2F;&#x2F; 创建Leader对象，并创建Server绑定在QuorumAddress上，用于和其他Follower之间相互通信 leader.lead();&#x2F;&#x2F; Leader的真正的逻辑</span><br><span class="line">            - &#x2F;&#x2F; 参见leader启动逻辑</span><br></pre></td></tr></table></figure>
<h3 id="QuorumCnxManager-线程逻辑"><a href="#QuorumCnxManager-线程逻辑" class="headerlink" title="QuorumCnxManager 线程逻辑"></a>QuorumCnxManager 线程逻辑</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- QuorumCnxManager</span><br><span class="line">    - 作用</span><br><span class="line">        - 选举相关连接管理器,包含发送 和 接收 队列.持有 listener. 使用TCP通信,负责各台服务器之间的底层Leader选举过程中的网络通信. QuorumCnxManager可以保证每对peer之间只有一个连接, 如果有server发起新的连接,则比较sid,sid大的保留连接,小的放弃连接(只能大的连接小的).</span><br><span class="line">    - 成员变量</span><br><span class="line">        - sid -&gt; SendWorker.每个SenderWorker消息发送器,都对应一台远程Zookeeper服务器,负责消息的发送,按照SID进行分组. ConcurrentHashMap&lt;Long, SendWorker&gt; senderWorkerMap;</span><br><span class="line">        - sid -&gt; buffer queue,消息发送队列,用于保存那些待发送的消息.按照SID进行分组 ConcurrentHashMap&lt;Long, ArrayBlockingQueue&lt;ByteBuffer&gt;&gt; queueSendMap;</span><br><span class="line">        - 最近发送过的消息,为每个SID保留最近发送过的一个消息 ConcurrentHashMap&lt;Long, ByteBuffer&gt; lastMessageSent;</span><br><span class="line">        - 所有收到的消息都放到recvQueue中 public final ArrayBlockingQueue&lt;Message&gt; recvQueue;</span><br></pre></td></tr></table></figure>
<h3 id="QuorumCnxManager-Listener-线程逻辑"><a href="#QuorumCnxManager-Listener-线程逻辑" class="headerlink" title="QuorumCnxManager.Listener 线程逻辑"></a>QuorumCnxManager.Listener 线程逻辑</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- QuorumCnxManager.Listener 监听 并 建立server之间的连接. 该线程监听端口.绑定地址开启ServerSocket服务, 用来侦听其他server连接,进行集群间选举,投票,数据同步</span><br><span class="line">    - run()逻辑</span><br><span class="line">        - 开启选举端口.循环 等待接收socket连接请求,处理接收连接.</span><br><span class="line">            - receiveConnection(client);&#x2F;&#x2F; 处理接收连接</span><br><span class="line">                - QuorumCnxManager.receiveConnection()中</span><br><span class="line">                    - QuorumCnxManager.handleConnection(sock, din)中 从socket中读取到sid信息, 1.若对方sid小于自己sid,立马关闭连接.自己做为client向对方请求建立连接. **注意zk服务之间都是配置myid大的作为客户端连接,myid小的作为服务器端* closeSocket(sock); connectOne(sid);&#x2F;&#x2F; 创建新连接</span><br><span class="line">                    - 2.若对方sid大于自己sid,则启动工作线程以接收数据， 创建server端的发送线程任务和接收线程任务, 并且启动任务准备发送和接收client端数据. SendWorker sw &#x3D; new SendWorker(sock, sid);&#x2F;&#x2F; 发送线程 RecvWorker rw &#x3D; new RecvWorker(sock, din, sid, sw);&#x2F;&#x2F; 接收线程  &#x2F;&#x2F; 启动 发送线程 和 接收线程 sw.start(); rw.start();  &#x2F;&#x2F; 参见sendWorker和recvWorker逻辑</span><br></pre></td></tr></table></figure>
<h3 id="FastLeaderElection-Messenger-SendWorker-线程逻辑"><a href="#FastLeaderElection-Messenger-SendWorker-线程逻辑" class="headerlink" title="FastLeaderElection.Messenger.SendWorker 线程逻辑"></a>FastLeaderElection.Messenger.SendWorker 线程逻辑</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- FastLeaderElection.Messenger.SendWorker 投票信息发送线程</span><br><span class="line">    - run()逻辑</span><br><span class="line">        - 循环 从发送队列queueSendMap中取消息(出队)并发送出去.并将该消息存入lastMessageSent中.</span><br></pre></td></tr></table></figure>
<h3 id="FastLeaderElection-Messenger-RecvWorker-线程逻辑"><a href="#FastLeaderElection-Messenger-RecvWorker-线程逻辑" class="headerlink" title="FastLeaderElection.Messenger.RecvWorker 线程逻辑"></a>FastLeaderElection.Messenger.RecvWorker 线程逻辑</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- FastLeaderElection.Messenger.RecvWorker 投票信息接收线程</span><br><span class="line">    - run()逻辑</span><br><span class="line">        - 循环 接收线程从底层Socket收到报文后放到recvQueue队列中,等待Messenger调用pollRecvQueue方法获取消息</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper启动流程</title>
    <url>/2019/01/18/01no/zk/zk02_start/</url>
    <content><![CDATA[<h3 id="zk启动流程"><a href="#zk启动流程" class="headerlink" title="zk启动流程"></a>zk启动流程</h3><ol>
<li>启动类为 QuorumPeerMain</li>
<li>解析 zoo.cfg 配置</li>
<li>创建并启动 DatadirCleanupManager 用于清理过期 snapshot 和 txnlog.</li>
<li>创建 QuorumPeer 实例并启动该线程,用于完成选举.</li>
<li>根据 snapshot 和 txnlog 恢复 内存数据库 ZKDatabase.</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 启动</span><br><span class="line">    - QuorumPeerMain.main()中 创建QuorumPeerMain对象 new QuorumPeerMain()  初始化 运行 main.initializeAndRun(args);</span><br><span class="line">        - main.initializeAndRun(args);中 1.通过QuorumPeerConfig.parse(),解析配置文件 QuorumPeerConfig.parse(args[0]);</span><br><span class="line">            - QuorumPeerConfig.parse(args[0]);中 解析zoo.cfg配置文件到QuorumPeerConfig对象中</span><br><span class="line">        - 2.启动定时清理服务任务,DatadirCleanupManager.start()用来清除过期的txtLog和snapshot文件 DatadirCleanupManager.start()</span><br><span class="line">            - DatadirCleanupManager.start()中 创建PurgeTask定时任务 TimerTask task &#x3D; new PurgeTask(dataLogDir, snapDir, snapRetainCount); timer.scheduleAtFixedRate(task, 0, TimeUnit.HOURS.toMillis(purgeInterval));</span><br><span class="line">        - 3.选择以集群模式或ZooKeeperServerMain.main()单机模式 来启动zookeeper runFromConfig(config);或ZooKeeperServerMain.main(args);</span><br><span class="line">            - runFromConfig(config)中 创建server连接工厂 ServerCnxnFactory cnxnFactory &#x3D; ServerCnxnFactory.createFactory();</span><br><span class="line">            - 根据QuorumPeerConfig配置,构建QuorumPeer任务对象 quorumPeer &#x3D; getQuorumPeer();</span><br><span class="line">            - 启动quorumPeer quorumPeer.start();</span><br><span class="line">                - quorumPeer.start()中 启动时先从磁盘-&gt;内存数据库中恢复数据 loadDataBase();</span><br><span class="line">                    - quorumPeer.loadDataBase()中 启动时先从磁盘-&gt;内存数据库中恢复数据 zkDb.loadDataBase();</span><br><span class="line">                        - ZKDatabase.loadDataBase()中  long zxid &#x3D; snapLog.restore(dataTree, sessionsWithTimeouts, commitProposalPlaybackListener);&#x2F;&#x2F; 恢复快照</span><br><span class="line">                            - FileTxnSnapLog.restore()中 从最后一个有效快照 反序列化 数据树，并返回反序列化的最后一个zxid snapLog.deserialize(dt, sessions);</span><br><span class="line">                                - FileSnap.deserialize()中 查找100个合法的snapshot文件 List&lt;File&gt; snapList &#x3D; findNValidSnapshots(100);  遍历读取指定的snapshot文件,反序列化 快照文件. 从文件名中解析出zxid</span><br><span class="line">                                    - &#x2F;&#x2F; TODO snapshot和txnlog配合的逻辑</span><br><span class="line">                            - 读取事务日志 return fastForwardFromEdits(dt, sessions, listener);</span><br><span class="line">                                - FileTxnSnapLog.fastForwardFromEdits()中 遍历事务日志 processTransaction(hdr,dt,sessions, itr.getTxn());</span><br><span class="line">                - 启动cnxnFactory(具体实现类如NIOServerCnxnFactory或NettyServerCnxnFactory等)， 这里主要是启动一个server，用来接收来自client的请求，绑定在配置文件中的clientPort端口 cnxnFactory.start(); </span><br><span class="line">                - 启动leader选举过程，因为server刚启动时是存在LOOKING状态，需要发一起一次选举过程来获取leader startLeaderElection();</span><br><span class="line">                    - quorumPeer.startLeaderElection()中 server刚启动的时候，server的状态初始化为LOOKING状态. 创建Vote对象(myid, zxid, epoch时钟) currentVote &#x3D; new Vote(myid, getLastLoggedZxid(), getCurrentEpoch());</span><br><span class="line">                    - 创建选举算法对象 this.electionAlg &#x3D; createElectionAlgorithm(electionType);</span><br><span class="line">                        - QuorumPeer.createElectionAlgorithm()中 初始化QuorumCnxManager,管理选举中和其他server的交互,选举时监听在专门的electionAddr(端口)上 qcm &#x3D; createCnxnManager(); </span><br><span class="line">                        - 启动Listener线程.绑定地址开启ServerSocket服务，用来侦听其他server连接， 进行集群间选举，投票， 数据同步。Server连接数有限，是基于bio的长连接。 QuorumCnxManager.Listener listener &#x3D; qcm.listener; listener.start(); &#x2F;&#x2F; 参见QuorumCnxManager.Listener线程逻辑 </span><br><span class="line">                        - 创建快速选举算法 对象 le &#x3D; new FastLeaderElection(this, qcm);</span><br><span class="line">                            - new FastLeaderElection(this, qcm)构造方法中 starter(self, manager);</span><br><span class="line">                                - 创建用于保存发送选票 和 接收选票的 队列,创建投票消息对象. FastLeaderElection.starter()中 选票发送队列，用于保存待发送的选票 sendqueue &#x3D; new LinkedBlockingQueue&lt;ToSend&gt;();  选票接收队列，用于保存接收到的外部投票 recvqueue &#x3D; new LinkedBlockingQueue&lt;Notification&gt;();</span><br><span class="line">                                - this.messenger &#x3D; new Messenger(manager);</span><br><span class="line">                                    - new Messenger(manager)中 创建消息处理对象Messenger, 它有 WorkerReceiver 和 WorkerSender 两个线程子类型对象组成, 用于操作上一步创建的sendqueue和recvqueue中的数据.  this.ws &#x3D; new WorkerSender(manager); 该线程 将要发送的消息出列 并且 入manager的队列  this.wr &#x3D; new WorkerReceiver(manager); </span><br><span class="line">                - 该类继承自ZooKeeperThread. 启动QuorumPeer线程 super.start(); &#x2F;&#x2F; 参见QuorumPeer线程逻辑</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper环境搭建</title>
    <url>/2019/01/17/01no/zk/zk01_build/</url>
    <content><![CDATA[<h2 id="zk-idea-代码阅读环境搭建"><a href="#zk-idea-代码阅读环境搭建" class="headerlink" title="zk idea 代码阅读环境搭建"></a>zk idea 代码阅读环境搭建</h2><p>采用最新的 zookeeper release 版本 3.4.13<br><a href="http://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">zk发行版下载地址</a></p>
<p>从 github 上 clone 该版本的代码.</p>
<h3 id="1-ant-构建-zk"><a href="#1-ant-构建-zk" class="headerlink" title="1. ant 构建 zk"></a>1. ant 构建 zk</h3><p>build.xml 搜索 ant-eclipse-1.0.bin.tar.bz2, 1290行修改<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">get</span> <span class="attr">src</span>=<span class="string">"http://ufpr.dl.sourceforge.net/project/ant-eclipse/ant-eclipse/1.0/ant-eclipse-1.0.bin.tar.bz2"</span></span></span><br><span class="line"><span class="tag"><span class="attr">dest</span>=<span class="string">"$&#123;src.dir&#125;/java/ant-eclipse-1.0.bin.tar.bz2"</span> <span class="attr">usetimestamp</span>=<span class="string">"false"</span> /&gt;</span></span><br></pre></td></tr></table></figure><br>执行 ant eclipse</p>
<h3 id="2-idea-导入这个-eclipse-项目即可"><a href="#2-idea-导入这个-eclipse-项目即可" class="headerlink" title="2. idea 导入这个 eclipse 项目即可"></a>2. idea 导入这个 eclipse 项目即可</h3><p>File -&gt; New -&gt; import project from exist source -&gt; 选eclipse</p>
<h3 id="3-zk-单机伪分布式集群搭建"><a href="#3-zk-单机伪分布式集群搭建" class="headerlink" title="3. zk 单机伪分布式集群搭建"></a>3. zk 单机伪分布式集群搭建</h3><ol>
<li>配置 zk.cfg 配置文件</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">## zk 单机多节点配置</span></span><br><span class="line"><span class="comment"># The number of milliseconds of each tick</span></span><br><span class="line"><span class="comment"># 默认值 3000ms,用于表示 zk 中最小时间单元很多时间间隔都是使用 ticketTime 的倍数来表示.</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The number of ticks that the initial </span></span><br><span class="line"><span class="comment"># synchronization phase can take</span></span><br><span class="line"><span class="comment"># 默认值 10,即表示 ticketTime 值的10倍.表示 leader 服务器等待 follower 启动 并 完成数据同步的最大时间.</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The number of ticks that can pass between </span></span><br><span class="line"><span class="comment"># sending a request and getting an acknowledgement</span></span><br><span class="line"><span class="comment"># 默认值 5,follower 服务器与 leader 之间进行心跳检测的最大延时时间</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the directory where the snapshot is stored.</span></span><br><span class="line"><span class="comment"># dataDir : zk 保存数据的目录.默认情况下,zk 将 事务日志文件 也保存在该目录下.</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">D:\\0zc\\my\\02-data-cluster\\Server_A</span></span><br><span class="line"><span class="comment"># 单独配置 保存事务日志 的目录</span></span><br><span class="line"><span class="attr">dataLogDir</span>=<span class="string">D:\\0zc\\my\\02zk-log-cluster\\Server_A</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the port at which the clients will connect</span></span><br><span class="line"><span class="comment"># clientPort : 客户端连接 zk 服务器 的端口,zk 会监听这个端口,接受客户端的访问请求.</span></span><br><span class="line"><span class="comment"># 若多个节点都部署在同一台机器上,clientPort不能重复.如配置成 Server_A 的 clientPort=2181, Server_B 的 clientPort=2182,依次递增</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># server.A=B:C:D;</span></span><br><span class="line"><span class="comment"># 其中 A 是一个myid数字,表示这个是第几号服务器</span></span><br><span class="line"><span class="comment"># B 是这个服务器的 ip 地址</span></span><br><span class="line"><span class="comment"># C 与 leader 间通信 与 数据同步 的端口</span></span><br><span class="line"><span class="comment"># D 用于选举通信的端口</span></span><br><span class="line"><span class="comment">#server.A=B       :C    :D</span></span><br><span class="line"><span class="meta">server.1</span>=<span class="string">localhost:33331:33341</span></span><br><span class="line"><span class="meta">server.2</span>=<span class="string">localhost:33332:33342</span></span><br><span class="line"><span class="meta">server.3</span>=<span class="string">localhost:33333:33343</span></span><br></pre></td></tr></table></figure>
<p>修改该配置文件,依次配置 Server_B 和 Server_C.</p>
<ol start="2">
<li><p>建立 myid 文件</p>
</li>
<li><p>idea中运行 zk Server<br>运行 QuorumPeerMain 类,启动时在 Run/Debug Configurations -&gt; Configuration -&gt; Program arguments 中 指定zk的配置文件,如<code>D:\soft\zookeeper-3.3.3-cluster\Server_A\zookeeper-3.3.3\conf\zoo.cfg</code><br>相当于把它作为集群中的 A 服务器节点,依次类推配置 Server_B 和 Server_C</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper数据同步流程</title>
    <url>/2019/01/17/01no/zk/zk04_sync/</url>
    <content><![CDATA[<h3 id="zk选举完后数据同步流程"><a href="#zk选举完后数据同步流程" class="headerlink" title="zk选举完后数据同步流程"></a>zk选举完后数据同步流程</h3><p><img src="https://gitee.com/flyingzc/MyImg/raw/master/img/zk/zk-sync.png" alt="zk数据同步"><br>Leader为每个Follower/observer都建立一个TCP长连接.</p>
<p>LearnerHandler,即learner服务器的管理者,负责follower/observer服务器和leader服务器之间的一系列网络通信.<br>包括数据同步,请求转发和Proposal提议的投票等.</p>
<p>leader.lead();<br>-&gt;<br>leader 从磁盘中恢复数据和session列表<br>Leader zk.loadData();<br>-&gt;<br>Leader 启动监听线程 LearnerCnxAcceptor, 等待新的followers的连接请求<br>-&gt;<br>follower 连接leader<br>Follower follower.followLeader();<br>-&gt;<br>LearnerCnxAcceptor 监听到follower的socket请求,为每个 follower 创建单独的 LearnerHandler 线程用于交互.<br>-&gt;<br>follower 发送 <code>FOLLOWERINFO</code> 包 给leader,包括新的zxid​和 sid<br>Follower registerWithLeader(Leader.FOLLOWERINFO);<br>-&gt;<br>LearnerHandler 等待接收 follower 发送的 FOLLOWERINFO 包,读取follower的选举周期 epoch,调用leader.getEpochToPropose(),同时Leader也阻塞在这个方法上.直到<code>过半机器共同决定出epoch</code><br>-&gt;<br>LearnerHandler 创建发送 <code>LEADERINFO</code> 包<br>-&gt;<br>Follower 等待 LEADINFO 包,获取Leader的Epoch和zxid值,并更新Follower的Epoch和zxid值,以Leader信息为准.<br>-&gt;<br>Follower 给 Leader 发 ACKEPOCH 包,告诉 Leader 这次 Follower 已经与 Leader 的 epoch 同步了.<br>-&gt;<br>LearnerHandler 等待follower响应的 ACKEPOCH 包.调用leader.waitForEpochAck().<br>同时Leader也阻塞在这个方法上.直到<code>过半机器接受了epoch,leader才会设置epoch</code><br>-&gt;<br>LearnerHandler 发送 <code>SNAP/DIFF/TRUNC</code> 包,用于follower完成数据同步.<br>再发送一个 <code>NEWLEADER</code> 包<br>-&gt;<br>Follower 处理SNAP/DIFF/TRUNC包.完成和 leader 的 数据同步.<br>syncWithLeader()</p>
<p>处理 NEWLEADER 包,说明之前的数据同步包处理完,发送 ACK 包.<br>writePacket(new QuorumPacket(Leader.ACK, newLeaderZxid, null, null), true);<br>-&gt;<br>leader 和 learnerHandler 等待在 waitForNewLeaderAck() 上直到<code>过半机器完成了数据同步并 ack</code>.<br>-&gt;<br>leader启动server<br>startZkServer()<br>-&gt;<br>LearnerHandler<br>等待leader server启动完成后,发送一个 UPTODATE 包给 follower<br>-&gt;<br>Follower<br>处理 Leader.UPTODATE 包,跳出循环.再回一个 ACK 给 leader,准备结束整个注册过程,然后调 zk.startup() 启动 follower.</p>
<h3 id="leader发的数据同步包"><a href="#leader发的数据同步包" class="headerlink" title="leader发的数据同步包"></a>leader发的数据同步包</h3><p>learnerHandler 线程中会根据 follower 状态选择发不同的数据同步包.</p>
<p>peerLastZxid : follower 最后处理的 zxid</p>
<p>minCommittedLog : leader committedLog 中最小的 zxid</p>
<p>maxCommittedLog : leader committedLog 中最大的 zxid</p>
<p>分四类</p>
<ul>
<li><p>要是 follower 的最大的 zxid 和 leader 内存中的最大的zxid 相同,发空的 DIFF 包.</p>
</li>
<li><p>直接差异化同步 (DIFF同步)<br>peerLastZxid 介于 minCommittedLog 和 maxCommittedLog 之间</p>
</li>
</ul>
<p>发 DIFF 包,通知 follower 进入 差异化数据同步阶段, leader 即将 把一些 proposal 同步给自己.<br>针对每个 proposal, leader 会再发 PROPOSAL 包 和 COMMIT 包.</p>
<p>同步完成后,leader 发 NEWLEADER 包, follower 反馈 ACK 表示完成了对 提议缓存队列中 proposal 的同步.</p>
<p>leader 进入 过半策略 等待阶段,等待有过半的 follower 完成了数据同步并 ack.</p>
<p>满足 过半策略 后, leader 向 所有完成数据同步的 follower 发 UPTODATE 包,表示集群已经有过半机器完成了数据同步,能对外提供服务了.</p>
<p>follower 收到 UPTODATE,终止同步流程,ACK 给 leader.</p>
<ul>
<li>先回滚再差异化同步 (TRUNC + DIFF同步)<br>比如 原 leader B 挂了.501, 502 被绝大部分机器应用了. leader B 要处理 503,写到本地事务日志中,发 proposal 之前挂了.</li>
</ul>
<p>新一轮选举 A 和 C 选举 产生了 leader A, echo 变更为 6.又提交了601, 602. B此时才再次启动,B 会开始和 leader A 同步数据.</p>
<p>leader A 发现 B 包含一条自己没有的事务记录 503, 则会让 B 进行事务回滚,回滚到 leader A 存在的,且最接近 peerLastZxid 的 ZXID, 即 B 会回滚到 502.</p>
<p>然后再 diff,同步 601 和 602 给 follower.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TRUNC 502 (回滚到 502, 则 B 包含了 501, 502,还缺少 601, 602)</span><br><span class="line">PROPOSAL 601</span><br><span class="line">COMMIT 601</span><br><span class="line"></span><br><span class="line">PROPOSAL 602</span><br><span class="line">COMMIT 602</span><br></pre></td></tr></table></figure>
<ul>
<li><p>仅回滚同步(TRUNC同步)<br>peerLastZxid 大于 maxCommittedLog<br>Leader 让 follower 回滚到 zxid 为 maxCommittedLog 的 事务操作.</p>
</li>
<li><p>全量同步(SNAP同步)<br>peerLastZxid 小于 minCommittedLog<br>或<br>leader没有提议缓存队列, peerLastZxid 不等于 lastProcessedZxid(leader恢复数据后得到的最大 zxid)</p>
</li>
</ul>
<p>发 SNAP 包, 然后将leader内存数据库序列化发给 follower,follower应用到内存.</p>
<h3 id="同步完成后逻辑"><a href="#同步完成后逻辑" class="headerlink" title="同步完成后逻辑"></a>同步完成后逻辑</h3><p>Leader 和 follower都会<br>设置各自的 processor 链,启动 processor 线程.</p>
<p>Leader<br>startZkServer()<br>    -&gt; setupRequestProcessors();// 设置processors链<br>    会启动 CommitProcessor 线程, PrepRequestProcessor线程,SyncRequestProcessor线程</p>
<p>Follower<br>startZkServer()<br>    -&gt; setupRequestProcessors();// 设置processors链<br>    会启动 CommitProcessor 线程, PrepRequestProcessor线程,SyncRequestProcessor线程</p>
<p>self.updateElectionVote(newEpoch);更新选举投票</p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
</search>
